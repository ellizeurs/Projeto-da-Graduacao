{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HPknRENn1W7I",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Instalação de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DpiNE7aY1aQX",
    "outputId": "a9fa0a3d-f8ac-4f7b-f6a0-55a0fb69a52c"
   },
   "outputs": [],
   "source": [
    "!pip install -U darts\n",
    "!pip install optuna\n",
    "!pip install openpyxl\n",
    "!pip install lxml\n",
    "!pip install ray\n",
    "!pip install pyswarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OtPQ8CiExCHh",
    "outputId": "1ce4f4a8-2056-4d10-a23b-5adfa6da1d94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed: classes\n",
      "Cloning into 'projeto-da-graduacao-classes'...\n",
      "remote: Enumerating objects: 281, done.\u001b[K\n",
      "remote: Counting objects: 100% (281/281), done.\u001b[K\n",
      "remote: Compressing objects: 100% (196/196), done.\u001b[K\n",
      "remote: Total 281 (delta 177), reused 186 (delta 82), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (281/281), 40.37 KiB | 1.34 MiB/s, done.\n",
      "Resolving deltas: 100% (177/177), done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "folders = ['projeto-da-graduacao-classes', 'classes']\n",
    "\n",
    "for folder in folders:\n",
    "  try:\n",
    "    shutil.rmtree(folder)\n",
    "    print('removed:', folder)\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "!git clone https://github.com/ellizeurs/projeto-da-graduacao-classes.git\n",
    "\n",
    "os.rename('projeto-da-graduacao-classes', 'classes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EEF3JA5y1dUB"
   },
   "source": [
    "# Importação de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "OZn1nyGr1g4_"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "import torch\n",
    "\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from darts.models import (\n",
    "    ARIMA,\n",
    "    FourTheta,\n",
    "    NLinearModel,\n",
    "    TFTModel,\n",
    "    NHiTSModel,\n",
    ")\n",
    "from darts.metrics import mape\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from classes.const import DATE_FORMAT_STRING, VAL_START, TEST_START\n",
    "from classes.functions import resample_month_series_in_week_series\n",
    "from classes.metrics import sle\n",
    "from classes import TimeSeries\n",
    "from classes.models.preprocessing import Detrend\n",
    "from classes.models.window import Takens\n",
    "from classes.models import (\n",
    "    NARX,\n",
    "    DA_RNN,\n",
    "    IDLN,\n",
    "    IMP,\n",
    "    MLP,\n",
    "    RandomWalkModel,\n",
    ")\n",
    "from classes.metrics import Hurst, UTheil\n",
    "from classes.functions import plot_series, plot_series_labels, plot_trend_line, eval_model\n",
    "\n",
    "import optuna\n",
    "\n",
    "from optuna.visualization import (\n",
    "    plot_optimization_history,\n",
    "    plot_contour,\n",
    "    plot_param_importances,\n",
    ")\n",
    "\n",
    "from pytorch_lightning.callbacks import Callback, EarlyStopping\n",
    "\n",
    "from pyswarm import pso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ohMxnZ1cA5w6"
   },
   "source": [
    "# Criando o dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "81-EOfJP2cLd"
   },
   "source": [
    "## Leitura da Tabela de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "zefsXienJnxs",
    "outputId": "4b4f755d-f803-4c1f-8ede-1c6877d1e60f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Norte</th>\n",
       "      <th>Nordeste</th>\n",
       "      <th>Centro-Oeste</th>\n",
       "      <th>Sul</th>\n",
       "      <th>Sudeste</th>\n",
       "      <th>Brasil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>6.58694</td>\n",
       "      <td>6.53524</td>\n",
       "      <td>6.63140</td>\n",
       "      <td>6.52017</td>\n",
       "      <td>6.42527</td>\n",
       "      <td>6.50281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-10</td>\n",
       "      <td>6.59247</td>\n",
       "      <td>6.54389</td>\n",
       "      <td>6.49987</td>\n",
       "      <td>6.49273</td>\n",
       "      <td>6.44492</td>\n",
       "      <td>6.49439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-17</td>\n",
       "      <td>6.59975</td>\n",
       "      <td>6.52692</td>\n",
       "      <td>6.63605</td>\n",
       "      <td>6.50669</td>\n",
       "      <td>6.48951</td>\n",
       "      <td>6.53165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-24</td>\n",
       "      <td>6.57902</td>\n",
       "      <td>6.53398</td>\n",
       "      <td>6.63996</td>\n",
       "      <td>6.48883</td>\n",
       "      <td>6.46100</td>\n",
       "      <td>6.5178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-31</td>\n",
       "      <td>6.71899</td>\n",
       "      <td>6.67343</td>\n",
       "      <td>6.69431</td>\n",
       "      <td>6.52320</td>\n",
       "      <td>6.50844</td>\n",
       "      <td>6.58144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2024-06-10</td>\n",
       "      <td>4.84877</td>\n",
       "      <td>5.03313</td>\n",
       "      <td>4.60784</td>\n",
       "      <td>4.62982</td>\n",
       "      <td>4.74864</td>\n",
       "      <td>4.75228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2024-06-17</td>\n",
       "      <td>4.98503</td>\n",
       "      <td>5.11313</td>\n",
       "      <td>4.90841</td>\n",
       "      <td>4.78222</td>\n",
       "      <td>4.94306</td>\n",
       "      <td>4.92817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>2024-06-24</td>\n",
       "      <td>5.00430</td>\n",
       "      <td>5.24851</td>\n",
       "      <td>4.90230</td>\n",
       "      <td>4.86621</td>\n",
       "      <td>4.97412</td>\n",
       "      <td>4.99009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>5.06412</td>\n",
       "      <td>5.19255</td>\n",
       "      <td>4.86046</td>\n",
       "      <td>4.81466</td>\n",
       "      <td>4.94753</td>\n",
       "      <td>4.95293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>2024-07-08</td>\n",
       "      <td>5.08719</td>\n",
       "      <td>5.24473</td>\n",
       "      <td>5.10050</td>\n",
       "      <td>4.89672</td>\n",
       "      <td>5.00301</td>\n",
       "      <td>5.04084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Data    Norte  Nordeste  Centro-Oeste      Sul  Sudeste   Brasil\n",
       "0   2022-01-03  6.58694   6.53524       6.63140  6.52017  6.42527  6.50281\n",
       "1   2022-01-10  6.59247   6.54389       6.49987  6.49273  6.44492  6.49439\n",
       "2   2022-01-17  6.59975   6.52692       6.63605  6.50669  6.48951  6.53165\n",
       "3   2022-01-24  6.57902   6.53398       6.63996  6.48883  6.46100   6.5178\n",
       "4   2022-01-31  6.71899   6.67343       6.69431  6.52320  6.50844  6.58144\n",
       "..         ...      ...       ...           ...      ...      ...      ...\n",
       "127 2024-06-10  4.84877   5.03313       4.60784  4.62982  4.74864  4.75228\n",
       "128 2024-06-17  4.98503   5.11313       4.90841  4.78222  4.94306  4.92817\n",
       "129 2024-06-24  5.00430   5.24851       4.90230  4.86621  4.97412  4.99009\n",
       "130 2024-07-01  5.06412   5.19255       4.86046  4.81466  4.94753  4.95293\n",
       "131 2024-07-08  5.08719   5.24473       5.10050  4.89672  5.00301  5.04084\n",
       "\n",
       "[132 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_biodiesel = pd.read_excel(\n",
    "    \"https://www.gov.br/anp/pt-br/assuntos/precos-e-defesa-da-concorrencia/precos/ppidp/precos-medios-ponderados-semanais-2013.xls\",\n",
    "    usecols=\"A:B, D:I\",\n",
    "    skiprows=8,\n",
    "    na_values=[\"***\"],\n",
    ")\n",
    "df_biodiesel = df_biodiesel.rename(\n",
    "    columns={df_biodiesel.columns[0]: \"Produto\", df_biodiesel.columns[1]: \"Data\", df_biodiesel.columns[7]: \"Brasil\"}\n",
    ")\n",
    "df_biodiesel = df_biodiesel.dropna(subset=[\"Data\"])\n",
    "df_biodiesel = df_biodiesel[df_biodiesel[\"Produto\"] == \"Biodiesel B-100 (R$/litro)\"]\n",
    "df_biodiesel = df_biodiesel.drop(\"Produto\", axis=1)\n",
    "df_biodiesel.reset_index(drop=True, inplace=True)\n",
    "df_biodiesel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "id": "GAW6NDCw3Bd8",
    "outputId": "3808870a-e3f8-4755-fe89-c3c68bd59f18"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Transformando o Dataframe em uma serie temporal do darts\n",
    "series_national = TimeSeries.from_dataframe(df_biodiesel, \"Data\", \"Brasil\")\n",
    "series_national_tx = series_national.ratio()\n",
    "series_north = TimeSeries.from_dataframe(df_biodiesel, \"Data\", \"Norte\")\n",
    "series_south = TimeSeries.from_dataframe(df_biodiesel, \"Data\", \"Sul\")\n",
    "series_southeast = TimeSeries.from_dataframe(df_biodiesel, \"Data\", \"Sudeste\")\n",
    "series_midwest = TimeSeries.from_dataframe(df_biodiesel, \"Data\", \"Centro-Oeste\")\n",
    "series_northeast = TimeSeries.from_dataframe(df_biodiesel, \"Data\", \"Nordeste\")\n",
    "\n",
    "plot_series(\n",
    "    [\n",
    "        series_national,\n",
    "        series_national_tx,\n",
    "        series_north,\n",
    "        series_south,\n",
    "        series_southeast,\n",
    "        series_midwest,\n",
    "        series_northeast,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Soybean Oil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1960-01-04</td>\n",
       "      <td>204.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1960-01-11</td>\n",
       "      <td>203.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1960-01-18</td>\n",
       "      <td>202.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1960-01-25</td>\n",
       "      <td>201.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1960-02-01</td>\n",
       "      <td>201.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3357</th>\n",
       "      <td>2024-05-06</td>\n",
       "      <td>988.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3358</th>\n",
       "      <td>2024-05-13</td>\n",
       "      <td>993.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3359</th>\n",
       "      <td>2024-05-20</td>\n",
       "      <td>999.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3360</th>\n",
       "      <td>2024-05-27</td>\n",
       "      <td>1005.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3361</th>\n",
       "      <td>2024-06-03</td>\n",
       "      <td>1010.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3362 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Data  Soybean Oil\n",
       "0    1960-01-04       204.00\n",
       "1    1960-01-11       203.25\n",
       "2    1960-01-18       202.50\n",
       "3    1960-01-25       201.75\n",
       "4    1960-02-01       201.00\n",
       "...         ...          ...\n",
       "3357 2024-05-06       988.00\n",
       "3358 2024-05-13       993.67\n",
       "3359 2024-05-20       999.34\n",
       "3360 2024-05-27      1005.01\n",
       "3361 2024-06-03      1010.68\n",
       "\n",
       "[3362 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_soybean_oil = pd.read_excel('https://thedocs.worldbank.org/en/doc/5d903e848db1d1b83e0ec8f744e55570-0350012021/related/CMO-Historical-Data-Monthly.xlsx', sheet_name=\"Monthly Prices\", skiprows = 6)\n",
    "df_soybean_oil = df_soybean_oil.rename(columns={df_soybean_oil.columns[0]: 'Month', 'SOYBEAN_OIL': 'Soybean Oil'})\n",
    "df_soybean_oil = df_soybean_oil[['Month', 'Soybean Oil']]\n",
    "df_soybean_oil['Month'] = df_soybean_oil['Month'].apply(lambda x: pd.to_datetime(x, format='%YM%m'))\n",
    "df_soybean_oil = resample_month_series_in_week_series(\"Monday\", [\"Soybean Oil\"], df_soybean_oil, \"Month\")\n",
    "df_soybean_oil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Transformando o Dataframe em uma serie temporal do darts\n",
    "soybean_oil = TimeSeries.from_dataframe(df_soybean_oil, \"Data\", \"Soybean Oil\")\n",
    "\n",
    "plot_series(\n",
    "    [\n",
    "        soybean_oil,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Soybean Oil Future</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1994-06-06</td>\n",
       "      <td>571.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1994-06-13</td>\n",
       "      <td>568.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1994-06-20</td>\n",
       "      <td>565.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1994-06-27</td>\n",
       "      <td>562.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1994-07-04</td>\n",
       "      <td>560.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552</th>\n",
       "      <td>2024-03-04</td>\n",
       "      <td>964.9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553</th>\n",
       "      <td>2024-03-11</td>\n",
       "      <td>963.3525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1554</th>\n",
       "      <td>2024-03-18</td>\n",
       "      <td>961.7550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1555</th>\n",
       "      <td>2024-03-25</td>\n",
       "      <td>960.1575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1556</th>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>958.5600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1557 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Data  Soybean Oil Future\n",
       "0    1994-06-06            571.0000\n",
       "1    1994-06-13            568.2500\n",
       "2    1994-06-20            565.5000\n",
       "3    1994-06-27            562.7500\n",
       "4    1994-07-04            560.0000\n",
       "...         ...                 ...\n",
       "1552 2024-03-04            964.9500\n",
       "1553 2024-03-11            963.3525\n",
       "1554 2024-03-18            961.7550\n",
       "1555 2024-03-25            960.1575\n",
       "1556 2024-04-01            958.5600\n",
       "\n",
       "[1557 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# URL da página da web que contém a tabela HTML com um atributo \"id\"\n",
    "url = 'https://www.indexmundi.com/commodities/?commodity=soybean-oil&months=360'\n",
    "\n",
    "# Use a função read_html para importar a tabela HTML com base no atributo \"id\"\n",
    "tabelas_html = pd.read_html(url, attrs={\"id\": \"gvPrices\"}, na_values=['-'])\n",
    "\n",
    "df_soybean_oil_future = tabelas_html[0]  # Pode ser necessário ajustar o índice se houver mais de uma tabela com o mesmo atributo \"id\"\n",
    "df_soybean_oil_future = df_soybean_oil_future.drop('Change', axis = 1)\n",
    "df_soybean_oil_future = df_soybean_oil_future.rename(columns={df_soybean_oil_future.columns[0]: 'Mês', df_soybean_oil_future.columns[1]: 'Soybean Oil Future'})\n",
    "df_soybean_oil_future['Mês'] = pd.to_datetime(df_soybean_oil_future['Mês'], format='%b %Y')\n",
    "df_soybean_oil_future = resample_month_series_in_week_series(\"Monday\", [\"Soybean Oil Future\"], df_soybean_oil_future, \"Mês\")\n",
    "df_soybean_oil_future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Transformando o Dataframe em uma serie temporal do darts\n",
    "soybean_oil_future = TimeSeries.from_dataframe(df_soybean_oil_future, \"Data\", \"Soybean Oil Future\")\n",
    "\n",
    "plot_series(\n",
    "    [\n",
    "        soybean_oil_future,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYnQCs-bIuSh"
   },
   "source": [
    "## Tratamento dos dados - Série Original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hPxfpzo_OPa_"
   },
   "source": [
    "### Visualização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "id": "CdW4iqU8OUE3",
    "outputId": "11e4f098-98c4-49e6-a907-c47f783a0c98"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_series(\n",
    "    [\n",
    "        series_national,\n",
    "        series_national_tx,\n",
    "        series_north,\n",
    "        series_south,\n",
    "        series_southeast,\n",
    "        series_midwest,\n",
    "        series_northeast,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5MQAaMpviipq"
   },
   "source": [
    "#### Verificação da Sazonalidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "QSyyPlsCZfyh",
    "outputId": "330e2768-cc41-4366-e855-8e292b2407dd"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "series_national.plot_acf()\n",
    "series_national_tx.plot_acf()\n",
    "series_north.plot_acf()\n",
    "series_south.plot_acf()\n",
    "series_southeast.plot_acf()\n",
    "series_midwest.plot_acf()\n",
    "series_northeast.plot_acf()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yOEbEbINpjxO"
   },
   "source": [
    "#### Verificação de Ciclos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "OjtYwGoTliXQ",
    "outputId": "fd293b76-9563-4672-9bc4-7ee92a23aa20"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAJICAYAAABWjrQoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAABifklEQVR4nO3deVxU9f7H8ffAsKO4ryCrldpmmi1uuRRli1hq3OymaGplWtbNlptp2apZWfdXqaV2i25lmUuallfr5lVbtKzMFgERzA13GGCEOb8/bOYywwzDEDAgr+fjMQ+Zc86c8xn4OvCez/meMRmGYQgAAAAA4FGAvwsAAAAAgLqO4AQAAAAAXhCcAAAAAMALghMAAAAAeEFwAgAAAAAvCE4AAAAA4AXBCQAAAAC8IDgBAAAAgBcEJwBAvfPaa69p3rx5/i4DANCAEJwAoJZMnz5dJpPJ32XUe++++64mT56sCy+8sNy6yy67TJdddpnj/q5du2QymbRo0aLaK9CDRYsWyWQyadeuXf4upcbExcVp1KhR/i4DAGoEwQlAg/fDDz9o6NChio2NVWhoqNq3b6/LL79cL730kr9L88mTTz6ppUuX+rsMhx49eshkMumVV16ptn1mZGTojjvu0OLFi9W1a9dq22999Nlnn8lkMrm9paam+rs8ADjtmP1dAAD408aNG9WvXz916NBBY8eOVZs2bZSTk6PNmzdrzpw5mjhxor9LrLQnn3xSQ4cOVUpKir9L0W+//aavv/5acXFxSk9P1+23314t+922bZsWLlyoK6+8slLbx8bGqrCwUEFBQdVy/Lpo0qRJ5bpvcXFxfqnll19+UUAA78kCOD0RnAA0aE888YSioqL09ddfq0mTJk7rDhw44J+iTgNvvfWWWrVqpdmzZ2vo0KHatWtXtfwxf/311/u0vclkUmho6J8+bl3Wu3dvDR061G/HNwxDRUVFCgsLU0hISLXtt6SkRDabTcHBwdW2TwD4M3hbCECDlpGRoS5dupQLTZLUqlUrx9cVzZUxmUyaPn2607INGzbowgsvVGhoqBITEzV37lyPNbz11lvq1q2bwsLC1KxZM6WmpionJ8dpm99++0033HCD2rRpo9DQUEVHRys1NVXHjh1z1FBQUKA33njDcbpW2bkme/bs0ejRo9W6dWuFhISoS5cuWrBggfdvUBW9/fbbGjp0qK655hpFRUXp7bffLreNfc7Xzp07NWrUKDVp0kRRUVFKS0uTxWJx2nbhwoXq37+/WrVqpZCQEHXu3LlSpwC6+7nt27dPaWlpio6OVkhIiNq2bavBgweXm3v08ccfq3fv3oqIiFCjRo109dVXa/v27ZV6/tu3b1f//v0VFham6OhoPf7447LZbG63/TPHqYxvv/1WV111lRo3bqzIyEgNGDBAmzdvdtrG0/w7d/Oy4uLidM0112jNmjXq3r27wsLCHOPb3Ryno0eP6u6771ZMTIxCQkKUlJSkZ555xun7Yf85Pfvss3rhhReUmJiokJAQ/fTTT9X2fQCAP4uOE4AGLTY2Vps2bdKPP/6os88+u1r2+cMPP+iKK65Qy5YtNX36dJWUlGjatGlq3bp1uW2feOIJTZ06VcOHD9ett96qgwcP6qWXXlKfPn307bffqkmTJrJarUpOTlZxcbEmTpyoNm3aaM+ePfroo4909OhRRUVF6c0339Stt96qHj16aNy4cZKkxMRESdL+/ft18cUXy2Qy6c4771TLli318ccfa8yYMTp+/Ljuvvvuannedl9++aV27typhQsXKjg4WNdff73S09P10EMPud1++PDhio+P11NPPaWtW7fqtddeU6tWrfTMM884tnn55Zd19tln67rrrpPZbNayZct0xx13yGazacKECT7Vd8MNN2j79u2aOHGi4uLidODAAX366afavXu3oyv25ptvauTIkUpOTtYzzzwji8WiV155Rb169dK3335bYfds37596tevn0pKSvTAAw8oIiJC8+bNU1hYWLlt/8xx7E6cOKG8vDynZc2aNVNAQIC2b9+u3r17q3HjxpoyZYqCgoI0d+5cXXbZZfr888910UUX+fKtc/jll1/0l7/8RePHj9fYsWN15plnut3OYrGob9++2rNnj8aPH68OHTpo48aNevDBB7V371698MILTtsvXLhQRUVFGjdunEJCQtSsWbMq1QcANcIAgAbsk08+MQIDA43AwEDjkksuMaZMmWKsWbPGsFqtTttlZWUZkoyFCxeW24ckY9q0aY77KSkpRmhoqJGdne1Y9tNPPxmBgYFG2ZfdXbt2GYGBgcYTTzzhtL8ffvjBMJvNjuXffvutIclYvHhxhc8lIiLCGDlyZLnlY8aMMdq2bWvk5eU5LU9NTTWioqIMi8VS4X59deeddxoxMTGGzWYzDOPU91iS8e233zptN23aNEOSMXr0aKflQ4YMMZo3b+60LD8/v9xxLr/8ciMhIcFpWd++fY2+ffs67rv+3I4cOWJIMmbNmuWx/hMnThhNmjQxxo4d67R83759RlRUVLnlru6++25DkvHll186lh04cMCIiooyJBlZWVnVcpz169cbktze7MdISUkxgoODjYyMDMfjfv/9d6NRo0ZGnz59HMvsPwtXCxcudNqfYRhGbGysIclYvXp1ue1jY2OdxuCMGTOMiIgI49dff3Xa7oEHHjACAwON3bt3G4bxv59T48aNjQMHDlT4vAHAXzhVD0CDdvnll2vTpk267rrrtG3bNs2cOVPJyclq3769li9f7vP+SktLtWbNGqWkpKhDhw6O5Z06dVJycrLTtkuWLJHNZtPw4cOVl5fnuLVp00YdO3bU+vXrJUlRUVGSpDVr1pQ7hc0bwzD0wQcf6Nprr5VhGE7HSU5O1rFjx7R161afn6cnJSUlevfdd3XjjTc6Tv2yn2KXnp7u9jG33Xab0/3evXvr0KFDOn78uGNZRESE0zGKiop05ZVXKjMz03G6YmWEhYUpODhYn332mY4cOeJ2m08//VRHjx7VX/7yF6fvV2BgoC666CLHz8WTVatW6eKLL1aPHj0cy1q2bKkRI0ZU63HsHnnkEX366adOtzZt2qi0tFSffPKJUlJSlJCQ4Ni+bdu2uummm7Rhwwan77Ev4uPjy41ndxYvXqzevXuradOmTs9x4MCBKi0t1X/+8x+n7W+44Qa1bNmySjUBQE3jVD0ADd6FF16oJUuWyGq1atu2bfrwww/1/PPPa+jQofruu+/UuXPnSu/r4MGDKiwsVMeOHcutO/PMM7Vq1SrH/d9++02GYbjdVpLjSnDx8fG655579Nxzzyk9PV29e/fWddddp5tvvtkRqiqq5+jRo5o3b57HD4yt6CIYhw8fltVqddwPCwur8JiffPKJDh48qB49emjnzp2O5f369dO//vUvPfPMM+WuulY2YEpS06ZNJUlHjhxR48aNJUnffPONHnvsMW3evFl5eXkyDMOx/bFjx7x+H+xCQkL0zDPP6N5771Xr1q118cUX65prrtEtt9yiNm3aSDr1c5FOBT537DV5kp2d7fYUONfT2f7scezOOeccDRw4sNzyffv2yWKxuD2NrlOnTrLZbMrJyVGXLl0qdZyy4uPjK7Xdb7/9pu+//95jGHIde5XdLwD4A8EJAP4QHBysCy+8UBdeeKHOOOMMpaWlafHixZo2bZrHD64tLS2t8vFsNptMJpM+/vhjBQYGllsfGRnp+Hr27NkaNWqUli1bpk8++USTJk3SU089pc2bNys6OrrCY0jSzTffrJEjR7rd5txzz/X4+Ouvv16ff/654/7IkSMr/DBZe1dp+PDhbtd//vnn6tevn9Myd89dkiMcZWVlqU+fPurSpYtmz56t2NhYBQcHa9myZXr66ac9XnTBk7vvvlvXXnutli5dqjVr1mjq1Kl66qmntG7dOnXt2tWxvzfffNMRpsoym6vnV2dtHacyfB3f7uZruWOz2XT55ZdrypQpbtefccYZVdovAPgDwQkA3Ojevbskae/evZL+1wU5evSo03bZ2dlO91u2bKmwsDBHN6GsX375xel+YmKiDMNQfHx8uT8g3TnnnHN0zjnn6OGHH9bGjRvVs2dPvfrqq3r88ccluf/jt2XLlmrUqJFKS0vddiW8mT17ttMpbe3atfO4bUFBgZYtW6Ybb7zR7eWxJ02apPT09HLByZvly5ersLBQS5cuVfv27Z2WV1ViYqLuvfde3Xvvvfrtt990/vnna/bs2XrrrbccF9Vo1apVlb5nsbGxlf75/5njeNOyZUuFh4eXO64k/fzzzwoICFBMTIwk5/Fd9gqTruPbV4mJicrPz6+R5wcAtY05TgAatPXr1zud9mVnP6XOfppT48aN1aJFi3JzMl5++WWn+4GBgUpOTtbSpUu1e/dux/IdO3ZozZo1Tttef/31CgwM1KOPPlquBsMwdOjQIUnS8ePHVVJS4rT+nHPOUUBAgIqLix3LIiIiygW7wMBA3XDDDfrggw/0448/lnueBw8eLLesrG7dumngwIGOW0WnLX744YcqKCjQhAkTNHTo0HK3a665Rh988IFTzZVhD4QnT550LDty5EiVLqdusVhUVFTktCwxMVGNGjVy1JWcnKzGjRvrySefdDqmnbfv2aBBg7R582Z99dVXTo9xneP1Z4/jTWBgoK644gotW7bM6XLi+/fv19tvv61evXo5Tge0h7iy49t+efs/Y/jw4dq0aVO5sS+dCmmu4xoA6jI6TgAatIkTJ8pisWjIkCE666yzZLVatXHjRr377ruKi4tTWlqaY9tbb71VTz/9tG699VZ1795d//nPf/Trr7+W2+ejjz6q1atXq3fv3rrjjjtUUlKil156SV26dNH333/v2C4xMVGPP/64HnzwQe3atUspKSlq1KiRsrKy9OGHH2rcuHH629/+pnXr1unOO+/UsGHDdMYZZ6ikpERvvvmmIxTZdevWTWvXrtVzzz2ndu3aKT4+XhdddJGefvpprV+/XhdddJHGjh2rzp076/Dhw9q6davWrl2rw4cPV8v3Mj09Xc2bN9ell17qdv11112n+fPna+XKlT59kO3ll1+uoKAgXXfddRo/frxOnDihefPmqV27dtq/f79PNf76668aMGCAhg8frs6dO8tsNuvDDz/U/v37lZqaKulUSH7llVf017/+VRdccIFSU1PVsmVL7d69WytXrlTPnj31j3/8w+MxpkyZojfffFNXXnml7rrrLsflyGNjY51+/n/2OJXx+OOP69NPP1WvXr10xx13yGw2a+7cuSouLtbMmTMd211xxRXq0KGDxowZo/vuu0+BgYFasGCBo56quu+++7R8+XJdc801GjVqlLp166aCggL98MMPev/997Vr1y61aNHiTz1HAKg1frueHwDUAR9//LExevRo46yzzjIiIyON4OBgIykpyZg4caKxf/9+p20tFosxZswYIyoqymjUqJExfPhw48CBA+UuR24YhvH5558b3bp1M4KDg42EhATj1Vdf9XjJ5w8++MDo1auXERERYURERBhnnXWWMWHCBOOXX34xDMMwMjMzjdGjRxuJiYlGaGio0axZM6Nfv37G2rVrnfbz888/G3369DHCwsIMSU6Xhd6/f78xYcIEIyYmxggKCjLatGljDBgwwJg3b161fB/3799vmM1m469//avHbSwWixEeHm4MGTLEMIz/XQL74MGDTtu5uwT20qVLjXPOOccIDQ01EhISjNmzZxsLFiwot523y5Hn5eUZEyZMMM466ywjIiLCiIqKMi666CLjvffeK1fv+vXrjeTkZCMqKsoIDQ01EhMTjVGjRhnffPON1+/H999/b/Tt29cIDQ012rdvb8yYMcN4/fXXy9X7Z45jvxy5t8vUb9261UhOTjYiIyON8PBwo1+/fsbGjRvLbbdlyxbjoosuMoKDg40OHToYzz33nMfLkV999dVuj+V6OXLDOHXZ9QcffNBISkoygoODjRYtWhiXXnqp8eyzzzou+2//OVV0mXgA8DeTYbg5RwUAAAAA4MAcJwAAAADwguAEAAAAAF4QnAAAAADAC4ITAAAAAHhBcAIAAAAALwhOAAAAAOAFwQkAAAAAvCA4AQAAAIAXBCcAAAAA8ILgBAAAAABeEJwAAAAAwAuCEwAAAAB4QXACAAAAAC8ITgAAAADgBcEJAAAAALwgOAEAAACAFwQnAAAAAPCC4AQAAAAAXhCcAAAAAMALghMAAAAAeEFwAgAAAAAvCE4AAAAA4AXBCQAAAAC8IDgBAOqNuLg4jRo1yqfH7Nq1SyaTSYsWLaqRmgAADQPBCQDgdxkZGRo/frwSEhIUGhqqxo0bq2fPnpozZ44KCwv9XR4AADL7uwAAQMO2cuVKDRs2TCEhIbrlllt09tlny2q1asOGDbrvvvu0fft2zZs3T5L0yy+/KCCA9/wAALWP4AQA8JusrCylpqYqNjZW69atU9u2bR3rJkyYoJ07d2rlypWOZSEhIf4oEwAATtUDAPjPzJkzlZ+fr9dff90pNNklJSXprrvuctx3N8fp6NGjmjx5suLi4hQSEqLo6GjdcsstysvLq/DY69atU+/evRUREaEmTZpo8ODB2rFjh9M2J06c0N133+3Yd6tWrXT55Zdr69atjm0sFot+/vlnr8cDANRvdJwAAH6zYsUKJSQk6NJLL63S4/Pz89W7d2/t2LFDo0eP1gUXXKC8vDwtX75cubm5atGihdvHrV27VldddZUSEhI0ffp0FRYW6qWXXlLPnj21detWxcXFSZJuu+02vf/++7rzzjvVuXNnHTp0SBs2bNCOHTt0wQUXSJK++uor9evXT9OmTdP06dOr9DwAAHUfwQkA4BfHjx/Xnj17NHjw4CrvY9asWfrxxx+1ZMkSDRkyxLH84YcflmEYHh933333qVmzZtq0aZOaNWsmSUpJSVHXrl01bdo0vfHGG5JOzb8aO3asZs+e7XjslClTqlwvAKD+IjgBAPzi+PHjkqRGjRpVeR8ffPCBzjvvPKfQZGcymdw+Zu/evfruu+80ZcoUR2iSpHPPPVeXX365Vq1a5VjWpEkTffnll/r999/Vrl07t/u77LLLKgxpAIDTA3OcAAB+0bhxY0mn5hFVVUZGhs4++2yfHpOdnS1JOvPMM8ut69Spk/Ly8lRQUCDp1BysH3/8UTExMerRo4emT5+uzMzMKtWan5+vffv2OW4HDx6s0n4AAP5BcAIA+EXjxo3Vrl07/fjjj/4uxaPhw4crMzNTL730ktq1a6dZs2apS5cu+vjjj33e17PPPqu2bds6bhdeeGENVAwAqCkEJwCA31xzzTXKyMjQpk2bqvT4xMREn4NXbGyspFOfCeXq559/VosWLRQREeFY1rZtW91xxx1aunSpsrKy1Lx5cz3xxBM+13rLLbfo008/ddzS09N93gcAwH8ITgAAv5kyZYoiIiJ06623av/+/eXWZ2RkaM6cOR4ff8MNN2jbtm368MMPy63zNO+obdu2Ov/88/XGG2/o6NGjjuU//vijPvnkEw0aNEiSVFpaqmPHjjk9tlWrVmrXrp2Ki4sdyyp7OfKEhAQNHDjQcevZs2eF2wMA6hYuDgEA8JvExES9/fbbuvHGG9WpUyfdcsstOvvss2W1WrVx40YtXry43Oc2lXXffffp/fff17BhwzR69Gh169ZNhw8f1vLly/Xqq6/qvPPOc/u4WbNm6aqrrtIll1yiMWPGOC5HHhUV5bik+IkTJxQdHa2hQ4fqvPPOU2RkpNauXauvv/7a6Sp7XI4cABoGghMAwK+uu+46ff/995o1a5aWLVumV155RSEhITr33HM1e/ZsjR071uNjIyMj9cUXX2jatGn68MMP9cYbb6hVq1YaMGCAoqOjPT5u4MCBWr16taZNm6ZHHnlEQUFB6tu3r5555hnFx8dLksLDw3XHHXfok08+0ZIlS2Sz2ZSUlKSXX35Zt99+e7V/HwAAdZvJ4BqqAAAAAFAh5jgBAAAAgBcEJwAAAADwguAEAAAAAF4QnAAAAADAC4ITAAAAAHhBcAIAAAAALwhOqLNsNpuysrJks9n8XQrqEcYNqoJxg6pg3KAqGDf1F8EJAAAAALwgOAEAAACAFwQnAAAAAPCC4AQAAAAAXhCcAAAAAMALghMAAAAAeEFwAgAAAAAvCE4AAAAA4AXBCQAAAAC8IDgBAAAAgBdmfx68d+/eTveLiop011136eabb5YkrVixQq+88ooKCgrUv39/PfTQQwoKCpIk5ebm6pFHHtEvv/yiuLg4TZs2TWeccUatPwcAAAAApz+/dpy++OILx23JkiUKCAhQv379JEk7d+7Uc889p1mzZmnlypXav3+/XnvtNcdjH3roIV100UVat26dhgwZovvuu08lJSX+eioAAAAATmN+7TiVtXr1ap1zzjlq3769437//v3VpUsXSdLo0aM1ffp03X777dq1a5eysrL02muvKTg4WEOHDtUbb7yh7777Tt27dy+3b6vVKqvV6rTMbDYrODi45p8Yqsxmszn9C1QG4wZVwbhBVTBuUBWMm7opIMB7P6nOBKdVq1Zp+PDhjvuZmZnq0aOH435SUpL27dsni8WirKwsdejQwSn4JCUlKSMjw21wWrhwoebPn++0bNiwYU7HQ92Vk5Pj7xJQDzFuUBWMG1QF4wZVwbipW+Lj471uUyeC02+//abdu3dr4MCBjmWFhYWKiIhw3I+MjJQkWSwWWSwWp3WSFBERocLCQrf7T0tL04gRI5yW0XGq+2w2m3JychQTE1OpdwEAiXGDqmHcoCoYN6gKxk39VSeC06pVq9S7d281atTIsSwsLEwFBQWO+/n5+ZKk8PBwhYeHO62TpIKCAoWFhbndf3BwMCGpHgsICOCFBT5j3KAqGDeoCsYNqoJxU//4/adls9m0evVqDRo0yGl5QkKCdu7c6bifkZGhNm3aKDw8XPHx8crJyXGat5SRkaHExMRaqxsAAABAw+H34PTVV1+ppKREl156qdPyK6+8UuvWrdOOHTuUn5+vBQsW6Oqrr5YkxcXFKS4uTosWLZLVatWSJUtkMpl0/vnn++EZAAAAADjd+T04rVq1SldccYXMZuezBpOSkjR58mTdc889GjRokFq2bKkxY8Y41j/xxBPavHmz+vXrp/fff18zZ84stw8AAAAAqA4mwzAMfxcBuGOz2ZSdna3Y2FjOAUalMW7gq8zMTN177706//zzNXXqVMYNKo3XG1QF46b+okUDAGjQTpw4oaVLlyowMNDfpQAA6jBiLgCgQbOf5l1aWurnSgAAdRnBCQDQoNk7TSUlJX6uBABQlxGcAAANmr3jZLPZ/FwJAKAuIzgBABo0e3Ci4wQAqAjBCQDQoDHHCQBQGQQnAECDxhwnAEBlEJwAAA0ac5wAAJVBcAIANGjMcQIAVAbBCQDQoDHHCQBQGQQnAECDZp/jRHACAFSE4AQAaNDoOAEAKoPgBABo0JjjBACoDIITAKBBCwgIkMlkouMEAKgQwQkA0OAFBgYSnAAAFSI4AQAaPLPZzKl6AIAKEZwAAA2e2Wym4wQAqBDBCQDQ4BGcAADeEJwAAA0ec5wAAN4QnAAADR5znAAA3hCcAAANntlsls1m83cZAIA6jOAEAGjw6DgBALwhOAEAGjzmOAEAvCE4AQAaPDpOAABvCE4AgAaPOU4AAG8ITgCABo+OEwDAG4ITAKDBs3ec6DoBADwhOAEAGrzAwEBJ4gIRAACPCE4AgAbPbDZLIjgBADwjOAEAGjx7cGKeEwDAE4ITAKDBIzgBALwhOAEAGryAgFO/DglOAABPCE4AgAaPOU4AAG8ITgCABo9T9QAA3hCcAAANHsEJAOANwQkA0ODZP8eJ4AQA8ITgBABo8JjjBADwhuAEAGjwOFUPAOANwQkA0OARnAAA3hCcAAANHnOcAADeEJwAAA0ec5wAAN4QnAAADR6n6gEAvCE4AQAaPIITAMAbghMAoMFjjhMAwBuCEwCgwaPjBADwhuAEAGjwuDgEAMAbghMAoMGj4wQA8IbgBABo8JjjBADwhuAEAGjw6DgBALwhOAEAGjzmOAEAvCE4AQAaPDpOAABv/B6c3njjDV199dXq06ePbrrpJhUUFEiSFi1apIEDB6p///6aM2eODMNwPGb79u1KTU1Vz549NW7cOO3du9df5QMATgPMcQIAeOPX4PTee+9p06ZNev311/X555/r0UcfVVBQkDZs2KDFixdr0aJFeu+997Rx40YtW7ZMkmS1WjVlyhSlpqZq3bp1Ou+88zR16lR/Pg0AQD1HxwkA4I3ZXwcuLS3VggUL9Nprr6lNmzaSpI4dO0qSVq1apSFDhig6OlqSdPPNN2vFihVKSUnRli1bFBQUpJSUFEnSmDFjNGDAAO3Zs0ft27d3eyyr1Sqr1eq0zGw2Kzg4uIaeHaqDzWZz+heoDMYNqiIg4NT7iCUlJYwdVBqvN6gKxk3dZP89UBG/BacDBw6oqKhIa9eu1dtvv63IyEj99a9/1ZAhQ5SVlaXk5GTHtklJScrIyJAkZWZmOgKWJIWGhio6OlqZmZkeg9PChQs1f/58p2XDhg3T8OHDa+CZobrl5OT4uwTUQ4wb+OLEiROSpIMHDyo7O9vP1aC+4fUGVcG4qVvi4+O9buPX4JSfn6/du3dr+fLlysnJ0e233664uDhZLBZFREQ4to2IiFBhYaEkqbCw0Gmdfb3FYvF4rLS0NI0YMcJpGR2nus9msyknJ0cxMTGVehcAkBg3qJqWLVtKkho1aqTY2Fg/V4P6gtcbVAXjpv7yW3AKCQmRJI0dO1ahoaHq2LGjrrjiCv33v/9VeHi44yIRklRQUKCwsDBJUlhYmNM6+/rw8HCPxwoODiYk1WMBAQG8sMBnjBv4wj7HyWazMW7gM15vUBWMm/rHbz+t2NhYBQUFyWQyOZbZv46Pj9fOnTsdyzMyMpSYmChJSkhIcFpXVFSk3NxcJSQk1FLlAIDTDZ/jBADwxm/BKSwsTAMGDNDrr78uq9WqrKwsffrpp+rZs6cGDRqkJUuWKDc3V4cOHVJ6eroGDRokSerWrZuKi4u1bNkyWa1WLViwQJ06dfI4vwkAAG+4qh4AwBu/naonSffff78ee+wxDRw4UE2aNNFtt92mrl27SpKGDh2qkSNHymazKSUlRYMHD5Z06rS7WbNmacaMGZo5c6Y6d+6sGTNm+PNpAADqOYITAMAbvwanRo0aadasWW7XpaWlKS0tze26Ll266J133qnJ0gAADQgfgAsA8IYZaQCABo85TgAAbwhOAIAGj1P1AADeEJwAAA0ewQkA4A3BCQDQ4DHHCQDgDcEJANDgMccJAOANwQkA0OBxqh4AwBuCEwCgwSM4AQC8ITgBABo85jgBALwhOAEAGjw6TgAAbwhOAIAGj4tDAAC8ITgBABo8Ok4AAG8ITgCABo85TgAAbwhOAIAGj44TAMAbghMAoMFjjhMAwBuCEwCgwaPjBADwhuAEAGjw7HOc6DgBADwhOAEAGjw6TgAAbwhOAIAGjzlOAABvCE4AgAaPjhMAwBuCEwCgweNznAAA3hCcAAANXkDAqV+HBCcAgCcEJwBAg2cymWQ2m5njBADwiOAEAIBOna5HxwkA4AnBCQAAnbpABMEJAOAJwQkAAJ2a50RwAgB4QnACAEBijhMAoEIEJwAAxBwnAEDFCE4AAIg5TgCAihGcAAAQc5wAABUjOAEAIOY4AQAqRnACAEDMcQIAVIzgBACAmOMEAKgYwQkAADHHCQBQMYITAAA61XGy2WwyDMPfpQAA6iCCEwAAOjXHSRIXiAAAuEVwAgBApzpOkjhdDwDgFsEJAACdmuMkEZwAAO4RnAAAEB0nAEDFCE4AAIg5TgCAihGcAAAQHScAQMUITgAAiDlOAICKEZwAABAdJwBAxQhOAACIOU4AgIoRnAAAEB0nAEDFCE4AAIg5TgCAihGcAAAQHScAQMUITgAAiDlOAICKEZwAABAdJwBAxQhOAADofx0nghMAwB2CEwAAIjgBACpGcAIAQMxxAgBUzO/Bady4cbr00kvVu3dv9e7dW5MmTXKsW7RokQYOHKj+/ftrzpw5MgzDsW779u1KTU1Vz549NW7cOO3du9cf5QMAThPMcQIAVMTvwUmSHn74YX3xxRf64osv9OKLL0qSNmzYoMWLF2vRokV67733tHHjRi1btkySZLVaNWXKFKWmpmrdunU677zzNHXqVH8+BQBAPcepegCAipj9XYAnq1at0pAhQxQdHS1Juvnmm7VixQqlpKRoy5YtCgoKUkpKiiRpzJgxGjBggPbs2aP27duX25fVapXVanVaZjabFRwcXOPPA1Vns9mc/gUqg3GDqrDZbI7gZLVaGT+oFF5vUBWMm7rJ/iHoFakTwem5557Tc889pzPOOEOTJ09Wx44dlZWVpeTkZMc2SUlJysjIkCRlZmaqY8eOjnWhoaGKjo5WZmam2+C0cOFCzZ8/32nZsGHDNHz48Bp6RqhOOTk5/i4B9RDjBr6yB6d9+/YpOzvbz9WgPuH1BlXBuKlb4uPjvW7j9+A0adIkJSQkKCAgQO+++64mTZqk999/XxaLRREREY7tIiIiVFhYKEkqLCx0Wmdfb7FY3B4jLS1NI0aMcFpGx6nus9lsysnJUUxMTKXeBQAkxg2qxmazOeY4NW3aVLGxsX6uCPUBrzeoCsZN/eX34HT22Wc7vh45cqSWL1+uH374QeHh4SooKHCsKygoUFhYmCQpLCzMaZ19fXh4uNtjBAcHE5LqsYCAAF5Y4DPGDXxl7zjZbDbGDnzC6w2qgnFT/9S5n5Z9AMXHx2vnzp2O5RkZGUpMTJQkJSQkOK0rKipSbm6uEhISardYAMBpg4tDAAAq4tfgdOLECW3evFlWq1UnT55Uenq6jh8/rrPPPluDBg3SkiVLlJubq0OHDik9PV2DBg2SJHXr1k3FxcVatmyZrFarFixYoE6dOrmd3wQAQGXwOU4AgIr49VS9kpIS/d///Z+ys7NlNpt1xhlnaM6cOYqMjFSvXr00dOhQjRw5UjabTSkpKRo8eLCkU6fezZo1SzNmzNDMmTPVuXNnzZgxw59PBQBQz/E5TgCAivg1ODVt2lRvvvmmx/VpaWlKS0tzu65Lly565513aqo0AEADw6l6AICK1Lk5TgAA+APBCQBQEYITAAAiOAEAKkZwAgBA/5vjxMUhAADuEJwAABAdJwBAxQhOAACI4AQAqBjBCQAAEZwAABUjOAEAIOY4AQAqRnACAEB0nAAAFSM4AQAgghMAoGIEJwAARHACAFSM4AQAgJjjBACoGMEJAADRcQIAVIzgBACACE4AgIoRnAAAEMEJAFAxghMAAGKOEwCgYgQnAABExwkAUDGCEwAA+l/HieAEAHCH4AQAgKSAgFO/EglOAAB3CE4AAIg5TgCAihGcAAAQc5wAABUjOAEAIOY4AQAqRnACAEDMcQIAVIzgBACAmOMEAKgYwQkAADHHCQBQMYITAABijhMAoGIEJwAAxBwnAEDFCE4AAIiOEwCgYgQnAAD0v44TF4cAALhDcAIAQJLJZJLZbKbjBABwi+AEAMAfAgMDCU4AALcITgAA/IGOEwDAE4ITAAB/MJvNzHECALhFcAIA4A90nAAAnhCcAAD4A3OcAACeEJwAAPgDHScAgCcEJwAA/sAcJwCAJwQnAAD+QMcJAOAJwQkAgD8wxwkA4AnBCQCAP9BxAgB4QnACAOAPzHECAHhCcAIA4A/24GQYhr9LAQDUMQQnAAD+EBgYKEl0nQAA5RCcAAD4g9lsliTmOQEAyiE4AQDwB3twouMEAHBFcAIA4A90nAAAnhCcAAD4g32OE8EJAOCK4AQAwB8ITgAATwhOAAD8gTlOAABPCE4AAPyBOU4AAE8ITgAA/IHgBADwhOAEAMAfmOMEAPCkysEpNzdXq1ev1mefffani/j+++914YUX6rXXXnMsW7RokQYOHKj+/ftrzpw5MgzDsW779u1KTU1Vz549NW7cOO3du/dP1wAAAB0nAIAnPgen0tJSzZgxQzfccIMeeeQR/fOf/9TKlSvVo0cPvfPOOz4XYLPZ9Nxzz6lz586OZRs2bNDixYu1aNEivffee9q4caOWLVsmSbJarZoyZYpSU1O1bt06nXfeeZo6darPxwUAwBUXhwAAeGL29QELFy7U8uXLnZb169dPjz/+uP7zn/8oNTXVp/0tWbJEZ599tvLz8x3LVq1apSFDhig6OlqSdPPNN2vFihVKSUnRli1bFBQUpJSUFEnSmDFjNGDAAO3Zs0ft27d3ewyr1Sqr1eq0zGw2Kzg42KdaUbtsNpvTv0BlMG5QFfbxYj9Vz2q1MobgFa83qArGTd0UEOC9n+RzcFqxYoXMZrOefvpp/e1vf5MkhYeHq3Xr1tq1a5dP+zp69Kj+9a9/adGiRZo9e7ZjeVZWlpKTkx33k5KSlJGRIUnKzMxUx44dHetCQ0MVHR2tzMxMj8Fp4cKFmj9/vtOyYcOGafjw4T7VC//Iycnxdwmohxg3qIqioiJJp8ZPs2bN/FwN6gteb1AVjJu6JT4+3us2PgenAwcOKD4+Xn379nVaHh4erv379/u0r5dffll/+ctf1KhRI6flFotFERERjvsREREqLCyUJBUWFjqts6+3WCwej5OWlqYRI0Y4LaPjVPfZbDbl5OQoJiamUu8CABLjBlVjHzdRUVGSpJYtWyo2NtbPVaGu4/UGVcG4qb98Dk5NmjTR77//rqNHjzqW7du3T7t27VLTpk0rvZ+ff/5ZP/30k+6///5y68LDw1VQUOC4X1BQoLCwMElSWFiY0zr7+vDwcI/HCg4OJiTVYwEBAbywwGeMG1RFUFCQJMkwDMYPKo3XG1QF46b+8Tk4XXzxxfroo48cc5kyMzM1YsQIlZSU6JJLLqn0frZu3ars7GwNGjRIkpSfn6/AwEDt2bNH8fHx2rlzp6OrlZGRocTERElSQkKC3n//fcd+ioqKlJubq4SEBF+fCgAATriqHgDAE5+D04QJE/TVV1/pwIEDkuTo/rRq1Uq33XZbpfdz/fXX64orrnDcnz17ttq1a6dRo0Zp27Zteuqpp5ScnKywsDClp6frxhtvlCR169ZNxcXFWrZsma666iotWLBAnTp18ji/CQCAyuJznAAAnvgcnFq0aKG3335b7777rn766SdJUufOnTV8+HA1adKk0vsJDQ1VaGio435ISIjCwsLUqFEj9erVS0OHDtXIkSNls9mUkpKiwYMHSzp12t2sWbM0Y8YMzZw5U507d9aMGTN8fRoAAJRDxwkA4InPwUmSoqKiNG7cuGotZPr06U7309LSlJaW5nbbLl26VOkzowAAqAif4wQA8KRSwcn1Ut4VGTt2bJWLAQDAn+g4AQA8qVRwmjdvnkwmU6V2SHACANRXzHECAHhS6VP1DMPwuk1lwxUAAHURHScAgCeVCk5ff/214+vvvvtOd999tyZPnqzLL79ckrR27Vo9++yzevbZZ2umSgAAagFznAAAnvj8qVszZ85Uq1atNHjwYIWHhys8PFzXXXed2rRpo+eee64magQAoFbQcQIAeOJzcMrOzlZubq42b97sWPbll18qNzdXOTk51VocAAC1iTlOAABPfL4ceceOHbV9+3ZNmjRJoaGhMplMKiwslHTq85wAAKivCE4AAE987jj9/e9/V8uWLWUYhgoLC2WxWGQYhlq0aKG///3vNVEjAAC1gjlOAABPqtRx+vDDD7V69WplZmZKkhISEnTllVcqJCSk2gsEAKC2MMcJAOCJz8FJkkJCQjR48ODqrgUAAL8iOAEAPPE5OD366KMe15lMJj3yyCN/qiAAAPyFOU4AAE98Dk4fffSR2w+6NQyD4AQAqNeY4wQA8MTn4NS1a1en4JSfn6+dO3fKZDLp/PPPr87aAACoVZyqBwDwxOfgNG/evHLLdu3apdGjR6t3797VUhQAAP5AcAIAeOLz5cjdiYuL0xlnnKF33323OnYHAIBfMMcJAOBJleY4lWWz2bR79259++23Cg0NrbbCAACobXScAACeVOmqep4uDnHBBRdUS1EAAPgDF4cAAHhSpc9xMgzD6X6zZs104YUXavLkydVSFAAA/kDHCQDgic/B6euvv66JOgAA8DvmOAEAPPH54hDz58/X8uXLyy3//vvvtWHDhmopCgAAf6DjBADwxOfgNG/ePC1durTc8ueff1733ntvddQEAIBfMMcJAOBJtVyOvKioSHl5eeXmPgEAUJ/QcQIAeFLpOU49evSQJJlMJv3444+O+2U1a9as+ioDAKCWMccJAOBJpYOTvZtkMpk8dpaGDBlSPVUBAOAHdJwAAJ5UOjhNmzZN0qnPcYqOjtaYMWMc60JDQxUXF6ekpKTqrxAAgFrCHCcAgCeVDk7XXHONJOmbb75RdHS04z4AAKcLOk4AAE8qFZz27dunoKAgNW/eXLfddptjmTtt2rSpvuoAAKhFzHECAHhSqeB07bXX6pxzztGCBQt03XXXedzOZDLpyy+/rLbiAACoTXScAACeVPpUPTsuOQ4AOF0xxwkA4EmlgtOrr76qiIgIx9cAAJyO6DgBADypVHDq1q2b268BADidMMcJAOBJpYLT/PnzK73DsWPHVrkYAAD8iY4TAMCTSgWnefPmyWQyVWqHBCcAQH3FHCcAgCeVCk5t2rSpdHACAKC+ouMEAPCkUsFpxYoVNV0HAAB+FxAQIIngBAAoz+fLkdtlZ2dr586dkqTExETFxcVVV00AAPiFyWRSYGAgwQkAUI7PwSk/P1+PPfaYPvvsM6flffv21SOPPKJGjRpVV20AANQ6s9nMHCcAQDkBvj7gySef1Pr162UYhtPt888/11NPPVUTNQIAUGvMZjMdJwBAOT53nL744guZTCaNHDlSycnJkqQ1a9Zo0aJF+uKLL6q9QAAAahPBCQDgjs/BKTw8XG3atNGECRMcy5KSkrR+/Xrl5+dXa3EAANQ25jgBANzx+VS966+/Xnl5eTpy5Ihj2eHDh5WXl6cbb7yxWosDAKC2MccJAOCOzx2n33//XVarVUOHDlW3bt0kSVu2bJFhGNq9e7ceffRRSaeuTPTII49Ub7UAANQwTtUDALjjc3BatWqVTCaTrFar48p6hmFIklauXOm4T3ACANRHZrNZRUVF/i4DAFDH+BycunbtKpPJVBO1AADgd8xxAgC443NwmjdvXk3UAQBAncCpegAAd3y+OAQAAKczLg4BAHDH545TXl6eXnjhBX3zzTc6fPiw0zqTyaQvv/yy2ooDAKC20XECALjjc3B67LHHtHnzZscFIQAAOJ0EBgaqtLTUcaEjAACkKgSn7777TmazWbfccovat2/PLxUAwGnFbD71q7G0tNTxNQAAPv9GiI6OltVq1W233VYT9QAA4FcEJwCAOz7/Rrj//vt111136cknn1Tv3r0VERHhtP6CCy6otuIAAKht9rBUUlKikJAQP1cDAKgrfA5OZrNZERERWrp0qZYuXeq0rioXh3jiiSf0n//8R0VFRWrTpo0mTJigPn36SJIWLVqkt956SzabTYMHD9akSZMcpwZu375dM2bMUE5Ojrp06aJHH31Ubdu29fXpAADgJDAwUJK4QAQAwInPlyN//PHHdfDgQRmG4fbmqxEjRmjFihX6/PPP9cgjj2jq1Kk6evSoNmzYoMWLF2vRokV67733tHHjRi1btkySZLVaNWXKFKWmpmrdunU677zzNHXqVJ+PDQCAq7IdJwAA7HzuOOXk5CgsLEyTJ09Wu3btHO/MVVVcXJzja5PJpJKSEh08eFCrVq3SkCFDFB0dLUm6+eabtWLFCqWkpGjLli0KCgpSSkqKJGnMmDEaMGCA9uzZo/bt25c7htVqldVqdVpmNpsVHBz8p2pHzbLZbE7/ApXBuEFVlB039t9rJ0+eZByhQrzeoCoYN3VTQID3fpLPwenCCy9UVlaWI7RUh6efflorVqxQcXGxevbsqaSkJGVlZSk5OdmxTVJSkjIyMiRJmZmZ6tixo2NdaGiooqOjlZmZ6TY4LVy4UPPnz3daNmzYMA0fPrzangNqTk5Ojr9LQD3EuEFV5OTk6OTJk5KkXbt2qbCw0M8VoT7g9QZVwbipW+Lj471u43Nw6tq1q7766itNmjRJPXv2LHdxiGuuucbXXeqBBx7Qfffdpy1btigjI0Mmk0kWi8Vp3xEREY5fYIWFheWOGxERIYvF4nb/aWlpGjFihNMyOk51n81mU05OjmJiYir1LgAgMW5QNWXHTWRkpCSpTZs26tChg58rQ13G6w2qgnFTf/kcnF566SWZTCZt3rxZmzdvdlpnMpmqFJykU5Nxe/TooX/961+KiYlReHi4CgoKHOsLCgoUFhYmSQoLC3NaZ18fHh7udt/BwcGEpHosICCAFxb4jHGDqggICFBQUJCkU3/cMIZQGbzeoCoYN/VPlX5ani4MUZWLQ7gqLS1Vbm6u4uPjtXPnTsfyjIwMJSYmSpISEhKc1hUVFSk3N1cJCQl/+vgAgIat7Oc4AQBg53PHafny5W6X79+/X1u3bvVpX/n5+dqwYYP69Omj4OBgffbZZ/rmm280YcIERUdH66mnnlJycrLCwsKUnp6uG2+8UZLUrVs3FRcXa9myZbrqqqu0YMECderUye38JgAAfMFV9QAA7vgcnMp+VlJxcbHWr1+vFStW6JtvvpEkjR492qf9ffjhh3r66adlGIZiYmL0+OOP68wzz9SZZ56poUOHauTIkbLZbEpJSdHgwYMlnTr1btasWZoxY4Zmzpypzp07a8aMGb4+FQAAyuFznAAA7vgcnCRp27Zt+uijj7R27VrHXCPDMBwfTltZkZGRmjt3rsf1aWlpSktLc7uuS5cueuedd3w6HgAA3tBxAgC4U+ngdODAAX300Uf66KOPlJubK0mOOU0mk0n33nuv+vXrVzNVAgBQS5jjBABwp9LB6dprr3W6AETHjh01aNAgzZs3T0VFRUpNTa2xIgEAqC10nAAA7lQ6ONlsNplMJnXu3FkPP/yw4wNoX3/99RorDgCA2sYcJwCAOz7PcdqxY4cmTZqkK6+8UoMGDaqJmgAA8Bs6TgAAdyr9OU6PPPKIunbtKknKy8tTenq6RowYofz8fEnSrl27aqRAAABqE3OcAADuVDo4XXvttZo7d66WLl2qW2+9VW3btnX6wNvhw4dr2LBhNVIkAAC1hY4TAMCdSgcnu3bt2mn8+PFatmyZXn31VV199dUKDQ2VYRjKzs6uiRoBAKg1BCcAgDtV+hwnu27duqlbt266//77tXbtWn300UfVVRcAAH7BxSEAAO78qeBkFxYWpmuvvVbXXnttdewOAAC/oeMEAHDH51P1AAA4nXFxCACAOwQnAADKoOMEAHCH4AQAQBnMcQIAuENwAgCgDDpOAAB3CE4AAJTBHCcAgDsEJwAAyqDjBABwh+AEAEAZzHECALhDcAIAoAw6TgAAdwhOAACUwRwnAIA7BCcAAMqg4wQAcIfgBABAGcxxAgC4Q3ACAKAMOk4AAHcITgAAlMEcJwCAOwQnAADKoOMEAHCH4AQAQBnMcQIAuENwAgCgDDpOAAB3CE4AAJTBHCcAgDsEJwAAyqDjBABwh+AEAEAZzHECALhDcAIAoAw6TgAAdwhOAACUwRwnAIA7BCcAAMqg4wQAcIfgBABAGcxxAgC4Q3ACAKAMOk4AAHcITgAAlEFwAgC4Q3ACAKAMLg4BAHCH4AQAQBl0nAAA7hCcAAAog4tDAADcITgBAFAGHScAgDsEJwAAymCOEwDAHYITAABl0HECALhDcAIAoAzmOAEA3CE4AQBQBsEJAOAOwQkAgDJMJpMCAwOZ4wQAcEJwAgDAhdlspuMEAHBCcAIAwEVgYCDBCQDghOAEAIALOk4AAFcEJwAAXJjNZuY4AQCcEJwAAHBBxwkA4IrgBACAC+Y4AQBcEZwAAHBBxwkA4IrgBACAC+Y4AQBc+TU4Wa1WPfroo7r66qvVt29fjRo1St9//71j/aJFizRw4ED1799fc+bMkWEYjnXbt29XamqqevbsqXHjxmnv3r3+eAoAgNMQHScAgCu/BqfS0lK1a9dOr7/+utavX6+//OUvmjx5siwWizZs2KDFixdr0aJFeu+997Rx40YtW7ZM0qnANWXKFKWmpmrdunU677zzNHXqVH8+FQDAaYQ5TgAAV2Z/HjwsLExjx4513E9OTtbzzz+v7OxsrVq1SkOGDFF0dLQk6eabb9aKFSuUkpKiLVu2KCgoSCkpKZKkMWPGaMCAAdqzZ4/at29f7jhWq1VWq9VpmdlsVnBwcM09OfxpNpvN6V+gMhg3qArXcWPvODGOUBFeb1AVjJu6KSDAez/Jr8HJ1e7du3X8+HHFxMQoKytLycnJjnVJSUnKyMiQJGVmZqpjx46OdaGhoYqOjlZmZqbb4LRw4ULNnz/fadmwYcM0fPjwGnomqE45OTn+LgH1EOMGVWEfNzabTaWlpdq1a5dMJpOfq0Jdx+sNqoJxU7fEx8d73abOBKeioiJNnTpVo0aNUmRkpCwWiyIiIhzrIyIiVFhYKEkqLCx0Wmdfb7FY3O47LS1NI0aMcFpGx6nus9lsysnJUUxMTKXeBQAkxg2qxnXchIeHS5JiYmIUGBjo5+pQV/F6g6pg3NRfdSI4lZSU6IEHHlBMTIzj1L3w8HAVFBQ4tikoKFBYWJikU6f4lV1nX2//RecqODiYkFSPBQQE8MICnzFuUBX2cWMPSzabTUFBQX6uCnUdrzeoCsZN/eP3n5bNZtPUqVNlMpk0ffp0xykR8fHx2rlzp2O7jIwMJSYmSpISEhKc1hUVFSk3N1cJCQm1WzwA4LRkNp96X5ELRAAA7PwenJ588kkdOnRITz/9tOMXlSQNGjRIS5YsUW5urg4dOqT09HQNGjRIktStWzcVFxdr2bJlslqtWrBggTp16uR2fhMAAL6y/z7is5wAAHZ+PVVv7969Wrp0qUJCQjRw4EDH8hdffFG9evXS0KFDNXLkSNlsNqWkpGjw4MGSTp16N2vWLM2YMUMzZ85U586dNWPGDH89DQDAaYaOEwDAlV+DU9u2bfXNN994XJ+Wlqa0tDS367p06aJ33nmnpkoDADRgBCcAgCu/n6oHAEBdY784BMEJAGBHcAIAwAUdJwCAK4ITAAAuuDgEAMAVwQkAABd0nAAArghOAAC4YI4TAMAVwQkAABd0nAAArghOAAC4YI4TAMAVwQkAABd0nAAArghOAAC4YI4TAMAVwQkAABd0nAAArghOAAC4YI4TAMAVwQkAABd0nAAArghOAAC4YI4TAMAVwQkAABd0nAAArghOAAC4YI4TAMAVwQkAABd0nAAArghOAAC4YI4TAMAVwQkAABd0nAAArghOAAC4YI4TAMAVwQkAABd0nAAArghOAAC4YI4TAMAVwQkAABd0nAAArghOAAC4YI4TAMAVwQkAABd0nAAArghOAAC4YI4TAMAVwQkAABd0nAAArghOAAC4IDgBAFwRnAAAcMHFIQAArghOAAC4oOMEAHBFcAIAwAUXhwAAuCI4AQDggo4TAMAVwQkAABfMcQIAuCI4AQDggo4TAMAVwQkAABfMcQIAuCI4AQDggo4TAMAVwQkAABfMcQIAuCI4AQDggo4TAMAVwQkAABfMcQIAuCI4AQDggo4TAMAVwQkAABfMcQIAuCI4AQDggo4TAMAVwQkAABfMcQIAuCI4AQDggo4TAMAVwQkAABfMcQIAuCI4AQDggo4TAMAVwQkAABfMcQIAuCI4AQDggo4TAMAVwQkAABfMcQIAuCI4AQDgglP1AACuCE4AALgwmUwKCAggOAEAHAhOAAC4YTabCU4AAAe/Bqf3339fI0aM0EUXXaS5c+c6rVuxYoUGDRqkvn376tFHH9XJkycd63JzczV69Gj17NlTI0aM0K+//lrbpQMATnMEJwBAWX4NTi1atNC4cePUv39/p+U7d+7Uc889p1mzZmnlypXav3+/XnvtNcf6hx56SBdddJHWrVunIUOG6L777uOXGwCgWpnNZi4OAQBwMPvz4Jdddpkk6b///a/T8tWrV6t///7q0qWLJGn06NGaPn26br/9du3atUtZWVl67bXXFBwcrKFDh+qNN97Qd999p+7du7s9jtVqldVqdVpmNpsVHBxc/U8K1cZmszn9C1QG4wZV4W7cBAYGqqSkhLEEj3i9QVUwbuqmgADv/SS/BidPMjMz1aNHD8f9pKQk7du3TxaLRVlZWerQoYNT6ElKSlJGRobH4LRw4ULNnz/fadmwYcM0fPjwmnkCqFY5OTn+LgH1EOMGVVF23AQEBKi4uFjZ2dl+rAj1Aa83qArGTd0SHx/vdZs6GZwKCwsVERHhuB8ZGSlJslgsslgsTuskKSIiQoWFhR73l5aWphEjRjgto+NU99lsNuXk5CgmJqZS7wIAEuMGVeNu3AQHB6u0tFSxsbF+rg51Fa83qArGTf1VJ4NTWFiYCgoKHPfz8/MlSeHh4QoPD3daJ0kFBQUKCwvzuL/g4GBCUj0WEBDACwt8xrhBVZQdN2azWVarlXEEr3i9QVUwbuqfOvnTSkhI0M6dOx33MzIy1KZNG4WHhys+Pl45OTlOc5YyMjKUmJjoj1IBAKcprqoHACjLr8GppKRExcXFstlsKi0tVXFxsUpLS3XllVdq3bp12rFjh/Lz87VgwQJdffXVkqS4uDjFxcVp0aJFslqtWrJkiUwmk84//3x/PhUAwGnGfnEIAAAkPwen119/XT179tTSpUu1YMEC9ezZU6tWrVJSUpImT56se+65R4MGDVLLli01ZswYx+OeeOIJbd68Wf369dP777+vmTNnymyuk2cdAgDqKTpOAICyTIZhGP4uAnDHZrMpOztbsbGxnAOMSmPcoCL//ve/9e2332rYsGFOF31wN27OOecc/fzzz04fwA6UxesNqoJxU3/x0wIANBhLlizRfffdp927d3vdNiQkxHFKOQAABCcAQIORmZkp6dRFiLzp0KGDJFUqZAEATn8EJwBAg5GZmamQkBC1bdvW67b2cGUPWwCAho3gBABoEGw2m3bt2qW4uLhKzSuwB6esrKyaLg0AUA8QnAAADcLvv/8uq9VaqdP0JDpOAABnBCcAQIPgy/ymstsRnAAAEsEJANBA+BqcYmNjZTKZCE4AAEkEJwBAA2EPQPHx8ZXaPiQkRO3btyc4AQAkEZwAAA2E/SIPle042bc9duyYjhw5UlNlAQDqCYITAKBB8LXjJDHPCQDwPwQnAECDkJmZqRYtWqhx48aVfgzBCQBgR3ACAJz2LBaL9u3b59NpehLBCQDwPwQnAMBpzz6/yZfT9MpuT3ACABCcAACnvapcGKLs9vbHAwAaLoITAOC05+tnONm1bt1aYWFhdJwAAAQnAMDpr6rByWQyKSEhQdnZ2SopKamJ0gAA9QTBCQBw2qtqcLI/pqSkRLm5udVdFgCgHiE4AQBOe5mZmTKbzYqOjvb5sVwgAgAgEZwAAKc5wzCUlZWlDh06yGw2+/x4LkkOAJAITgCA09yBAwdksViqdJqexJX1AACnEJwAAKe1PzO/qezj6DgBQMNGcAIAnNb+bHBijhMAQCI4AQBOc382OIWHh6t169YEJwBo4AhOAIDTmj3w2DtHVZGQkKC8vDydOHGiusoCANQzBCcAwGnNflGHqnacyj6WC0QAQMNFcAIAnNYyMzMVFRWlpk2bVnkfXCACAEBwAgCctoqLi5Wbm6uEhASZTKYq74fgBAAgOAEATlvZ2dkyDONPnaYnEZwAAAQnAMBprDouDFH28QQnAGi4CE4AgNNWdVwYQpLatWun4OBgLg4BAA0YwQkAcNr6s5/hZBcYGKi4uDhlZWXJZrNVR2kAgHqG4AQAOG1VV3Cy76O4uFh79+790/sCANQ/BCcAwGkrMzNTJpNJsbGxf3pfXCACABo2ghMA4LRkGIYyMzMVHR2t4ODgP70/LhABAA0bwQkAUK8dO3ZM99xzj3bs2OG0/MiRIzp+/Hi1nKYn/a/j5HqBiNLSUj3xxBP6+OOPq+U4AIC6ieAEAKjXnn/+eT3//PMaMGCAU6ipzvlNZfdTtuNkGIYmTJighx9+WGlpabJardVyLABA3UNwAgDUW1arVXPnzpUk7d27V8nJyTpw4ICk6g9O7k7Vmz59uuP4+/fv1wcffFAtxwIA1D0EJwBAvfXhhx9q3759GjVqlMaNG6fffvtNgwYN0okTJ6o9OEVFRal58+aO/f7f//2fHnvsMbVp08YRmP7xj39Uy7EAAHWP2d8FAABQVfagcuedd+r8889XXl6elixZoiFDhqh9+/aSqi84Sae6Tt98840WLVqkiRMnKioqSmvWrNG5556rSy+9VBs3btS3336rrl27VtsxAQB1Ax0nAEC9tG3bNm3YsEEXX3yxunXrpsDAQKWnp+uyyy7Tv//9b/3zn/+U9L9T7KqDPYSlpaUpODhYy5cv17nnnivpVHiTTnWiAACnH4ITAKBesgcUe2CRpNDQUC1dulTnn3++JCk8PFytWrWqtmPag1NAQIDeffdd9enTx7HuhhtuUOvWrZWenq7Dhw9X2zEBAHUDwQkAUO8cOXJEb731llq2bKmhQ4c6rYuKitLq1avVpUsXDRw4UCaTqdqOe9lllykiIkKvvfaaBg8e7LQuODhY48aNU1FRkRYsWFBtxwQA1A0EJwBAvbNo0SIVFhZq3LhxCgkJKbe+devW2rZtm5YuXVqtx01OTtaxY8eUlpbmdv348eMVGBioV155RaWlpdV6bACAfxGcAAD1is1m0//93/8pMDBQ48eP97hdYGBgtXabyu7Xk/bt2+v6669XZmamVq9eXe3HBgD4D8EJAFCvrFmzRhkZGRo8eLBiYmL8XU45EyZMkMSlyQHgdENwAgDUK+4uClGX9OnTR2effbZWr16tnTt3+rscAEA1ITgBAOqNjIwMrVq1Sp07d9Zll13m73LcMplMjlD38ssv+7kaAEB1ITgBAOoFq9Wqhx9+WIZh6M4776yR+UvVZcSIEYqKitKCBQv0448/+rscAEA1IDgBQD1ntVpVVFTk7zI8ys/P19q1a/Xoo4/qiiuuUEpKiv773//6tI+MjAz17NlT77zzjuLj43XzzTfXULXVIzIyUn/729907NgxXXjhhZo/f74Mw6j04w8fPqyHH35Yl1xyicaPH68333xTmZmZPu2jtp04ccLfJQBAjTIZdflVGA2azWZTdna2YmNjFRBAxkflNKRxk5WVpVdeeUWvv/66goKCtGDBAg0aNKjW67Bardq5c6cOHDiggwcPKi8vTwcPHtTevXv19ddf67vvvnN7ae7LL79cjz76qC655JIK9//uu+9q7NixOnHihK677jotXLhQzZo1q9bnUBPjxjAMvfHGG5owYYIsFotuvPFGzZs3T40bN/b4mCNHjui5557TnDlz3AaRtm3bqmfPnkpKSlLLli3VokULtWzZUi1btlRsbKxatmxZLbX7Ii8vT2PHjtXSpUuVnJysCRMmaNCgQRVeffB00ZBeb1B9GDf1F8EJdRYvLKiK033c2Gw2ffrpp/rHP/6hlStXyjAMRUREqLCwUDabTRMmTNDMmTMVHh5e6X3u379f33//vUpLS2Wz2Rz/GoahJk2aOP4wb968uQIDA3X8+HFt2rRJGzZs0BdffKEvv/zSY8fLZDKpS5cu6tWrl3r27KmePXvqp59+0rRp07RlyxZJpz4b6e9//7vOPPNMRUZGKiwsTCaTSRaLRXfffbfmz5+voKAgzZo1S5MmTaqRU/Rqctzs2LFDN954o3744QclJCTo3XffVffu3SVJJ0+eVEFBgY4ePaqFCxfqhRde0PHjx9WoUSPdddddGj9+vH799Vf997//1YYNG7Rp06YKOzsdO3ZU79691atXL/Xu3VuJiYmSTnX9Dh486Ai2J0+eVEBAgAIDAxUQEKCAgAC1aNFCF1xwgU/f39WrVystLU379u1T48aNdfz4cUlSXFycbr/9do0ZM0bNmzf/E9+9uu10f71BzWDc1F/1NjgdOXJE06dP15YtW9SqVSs98MAD6tGjh7/LQjXihQVVUV3jpri4WAEBAQoKCqrG6so7efKk9u7dq4CAALVq1UrBwcFO6202m3bs2KFNmzZp06ZNWr9+vbKysiRJZ511liZMmKBbbrlF33//vW6++WZlZ2erU6dOSk9PV9euXT0et7S0VJ988onmz5+vFStWqKSkxGutJpNJzZo105EjR2Sz2RzL4+Li1KNHD7Vt27ZcF+Tss89W06ZNy+3LMAx99NFHmj59urZu3eq0LiAgQJGRkZKk48ePKykpSe+88466devmtcaqqunXm8LCQt1zzz169dVXZTabFRUVpfz8fBUXFzttFxkZqbvuukv33HOP265aaWmptm/frj179jh19w4ePKgdO3bo66+/1smTJx3bN2nSRIWFheWO48mZZ56pW2+9VbfccotatWpV4fO5//779dJLL8lkMumBBx7Q9OnT9eWXX+of//iHlixZopKSEoWGhqpfv3665JJLdOmll6pHjx5q1KiR074Mw9CRI0d0+PBhtWrVqsKOXHUwDEMWi0Xh4eF/OoTzewpVwbipv+ptcHrggQcUHh6uKVOm6Msvv9Rjjz2mJUuWKCoqyt+l+SQ/P1+///67pFN/lNhvxcXFOnLkiON2+PBhnThxQmFhYYqMjHR7a9SokcLCwir1n9AwDB07dkx79+5VQUGB4x3HsreQkBAFBwcrJCTE6ebuF41hGDpx4oTy8vJ06NAhHT16VGazWaGhoQoJCVFoaKhCQ0MVGBgowzCcbiaTSWazWWazWUFBQQoKCpLZbNbJkye1a9cutWjRQiUlJY53SO3PtTp+6VXm+2S1WmWxWFRQUKATJ07o0KFDysvLc9wOHz6ssLAwNW3aVM2aNSt3a9q0qcc/vktLS5Wfn68TJ06U+7e4uFjBwcFOt6CgoHLLgoODFRoaqsjIyHJ/dNufg8Vi0dGjR3Xs2DHZbDand5nLfl32vmEYOnTokOOPMnc3+x9tJ0+eVLNmzdSqVSuvN5PJpEOHDjm+j4cOHdKRI0eUn5+v/Px8FRQUOP4t+7X936CgICUmJioxMVFJSUlKTExUhw4dVFBQoMOHDysvL09ZWVmOMePKZrOpuLhYxcXFKioqcvx77NgxHT16VEePHnX6IzMkJETR0dGOW0xMjNP99u3bO33fbTabLBaL8vPzdfTo0XLj5eDBg8rJyVFOTo52796twsJCp/oCAgLUpk0btWnTRiaTydGVKatPnz6688471b9/f6f/A8eOHdPEiRO1cuVKSdLdd9+t7t27O/4PhoSESJKWL1+uBQsWyGKxSDr1x/V1113neP0oOwaOHDlS7ufeokULR0ejV69eio6O9vh/yBvDMLRixQqlp6fr6NGjjnFg/3lfddVVmjNnTo3+MW0ymWSz2ZSTk6OYmJga/UNm8eLFevDBB2W1Wsu9hnft2lWTJk36Ux2awsJCff31145u4LZt29SoUSNHkLUH29DQUKfuos1m0w8//KCNGzc69tW/f3+NHj1a7dq1c/r/cvz4cU2fPl2///67GjVqpDfffFN9+vRxquP333/XvHnzNH/+/HJjPCYmRrGxsTpw4ID27t3rtoPWvn17xcTEqEOHDmrbtq2aN2+uFi1aOG7NmjVTo0aNFBkZ6fT6ahiG8vLylJub67jl5OQ43c/Ly3NsbzKZ1KRJEzVp0kRNmzZVeHi40/+XkJAQt6/fJpNJUVFRjnBrP3Xy+PHj2rlzpzIyMhz/7t+/3/G7OyIiwvFv2a/t/0ZFRal58+aO59u8eXM1atRIhw8f1oEDB7zeiouL1bx5c6eft6dbWFhYuTHget/+dWRkpKKiohQVFeXxFEybzaaioiIVFhbKYrGosLDQcbNarbJarTp58qTjJsnx+9z134r+1jh+/Ljj7yLX25EjRxQeHu40Vlq0aKEmTZo4vueV/Tvpz7JarY7f54WFhY7f3/a/cfbv36/27durtLRUJ0+edPzOsr8pVfZvQvv+ioqKnG6hoaGOcdKsWbMK3+gzDEMnT54s93NwvW8Yhlq1aqXWrVvLbDZ7fZ6GYaiwsNDxe7rs7+yyX5vNZjVt2tTplpCQUO6NlLquXgYni8Wi/v37a9myZWrdurUkady4cbrmmmt03XXXldve/h+2LLPZ7PaPzNqUn59f74IeAAAAUB327dvnl7mZ7lQmUHuPknXQ7t27FR4e7ghN0ql3ezIzM91uv3DhQs2fP99p2bBhwzR8+PAardMbm82m888/X999951f6wB8ERwc7Hh3q3Hjxk7vChYWFjq6SQUFBVXaf2hoqMLDwx23sLAwp3cIDcPQ4cOHlZ2d7fVKcu7eLTOZTI5Oqr1jFxISUuG7nMXFxdq/f7/27t3r9iIHvmrdurXatm3rcR6SzWbT4cOHdfLkSUfnyVd79+51nNLnTufOndWkSROf93u6qYfvHdYKwzC0efPmCrfxdlEPTwoKCnTkyBFH58sdm82mAwcO6Pfff6/0aYYVadKkidq2betxzJeWlur48eOOrprVanX8W1JSUu7/oH0OYEXatm2r9u3bO3UB7Gcw2G/27kzZU18rKyAgQM2aNVPz5s3VpEkTpz/6CgsLHV2Y/Px8n/cN1IYzzjhDR44ccZz94G/x8fFet6mXwamwsFARERFOyyIiInTs2DG326elpWnEiBFOy+pCx0mS29NwqpNhGCoqKlJBQYEKCwvVtGlTx9yBuq62Tp3B6YVxg6pg3KAqGDeoivo0bkpKSnTw4EGZTCZFRkYqPDy8ztdck+plcAoLCyv3bnZBQYHHd2/t7yo3VPbzeusr+9wbwBeMG1QF4wZVwbhBVdSHcRMcHKz27dv7u4w6o27/tDzo0KGDLBaLDhw44FiWkZGhhIQEP1YFAAAA4HRVL4NTeHi4+vbtq7lz56qoqEhffPGFdu7cqb59+/q7NAAAAACnoXoZnKRTlyM/ePCgBgwYoOeff15PPvkkV6gDAAAAUCPq5RwnSWratKlefPFFf5cBAAAAoAGotx0nAAAAAKgtBCcAAAAA8ILgBAAAAABeEJwAAAAAwAuCEwAAAAB4QXACAAAAAC8ITgAAAADgBcEJAAAAALwgOAEAAACAFwQnAAAAAPCC4AQAAAAAXhCcAAAAAMALghMAAAAAeEFwAgAAAAAvTIZhGP4uAgAAAADqMjpOAAAAAOAFwQkAAAAAvCA4AQAAAIAXBCcAAAAA8ILgBAAAAABeEJwAAAAAwAuCEwAAAAB4QXACAAAAAC8ITgAAAADgBcEJAAAAALwgOAEAAACAFwQn1Cnbt29XamqqevbsqXHjxmnv3r1eH7NmzRp1795dq1atqoUKURdVdtwcPnxYDz74oJKTk3XZZZfpjjvuUFZWVi1XC385cuSI7rrrLvXq1UvXX3+9vvrqK7fbFRUVaerUqerTp4+uvvpqrV69upYrRV1S2XHz/PPPa/DgwerTp49SU1P1xRdf1HKlqEsqO27sfv/9d/Xs2VMzZsyopQpRFQQn1BlWq1VTpkxRamqq1q1bp/POO09Tp06t8DGFhYV6/fXXlZCQUEtVoq7xZdxYLBadc845evvtt/Xvf/9bF198se69995arhj+8swzz6h58+Zau3at7rrrLj344IM6duxYue3mzp2ro0ePatWqVXr66af1zDPPaNeuXbVfMOqEyo6b8PBwvfjii/rss8/0t7/9TVOnTtWePXv8UDHqgsqOG7vnnntOZ555Zi1WiKogOKHO2LJli4KCgpSSkqKQkBCNGTNGO3bsqPAXz2uvvabBgwerSZMmtVco6hRfxk10dLRuuukmNW/eXIGBgUpNTVVOTo6OHj1a+4WjVlksFn322WcaP368QkND1bdvXyUmJurzzz8vt+2qVas0ZswYRUZG6pxzzlHfvn21Zs0aP1QNf/Nl3IwfP16xsbEKCAhQ9+7dlZCQoJ9//tkPVcPffBk3krRp0yYZhqGLLrqoliuFrwhOqDMyMzPVsWNHx/3Q0FBFR0crMzPT7fbZ2dnauHGjbrzxxtoqEXWQr+OmrG+//VbNmjUjeDcAu3fvVnh4uFq3bu1YlpSUVG6cHD9+XIcOHVJSUpLTdhkZGbVWK+qOyo4bV8ePH1dGRgZnQzRQvoybkydPas6cOZo8eXJtlogqIjihzigsLFRERITTsoiICFksFrfbz549WxMnTpTZbK6N8lBH+Tpu7I4ePaonn3xSEydOrMnyUEdUdpzY75fdNiIiQoWFhTVfJOqcqry+2Gw2Pfroo+rfv7/i4+NrukTUQb6Mm/T0dPXs2VPR0dG1VR7+BP7iRK0ZM2aMtm3b5nbd6NGjFRUVpYKCAqflBQUFCg8PL7f9Z599psDAQF166aU1UivqjuocN2XXT5o0SVdccYWuueaaaq0XdVNYWFilxon9fkFBgSIjIx1fh4WF1U6hqFMqO27Kevrpp5Wfn6+nnnqqpstDHVXZcXPgwAEtX75cb731Vm2Whz+B4IRa8/rrr1e4ftOmTXr//fcd94uKipSbm+v2VIctW7Zo69atSk5OliQdO3ZMv/76q3bv3q3bbruteguHX1XnuLGvnzx5ss466yxNmDChWmtF3dWhQwdZLBYdOHBArVq1kiRlZGTo6quvdtqucePGat68uXbu3Knzzz/fsV1iYmJtl4w6oLLjxm7OnDn6+eef9corryg4OLg2S0UdUtlx89NPP2n//v0aMmSIpFMdb5vNpr179+rll1+u9brhHafqoc7o1q2biouLtWzZMlmtVi1YsECdOnVS+/bty21722236YMPPlB6errS09PVuXNn3XHHHfrrX//qh8rhT76Mm5KSEk2ZMkUtWrTQAw884Idq4S/h4eHq27ev5s6dq6KiIn3xxRfauXOn+vbtW27bQYMGacGCBSooKNCPP/6ozz//3PEmDRoWX8bNa6+9pg0bNujFF18sd5oWGpbKjptLL71Uy5Ytc/wtc8MNN6hfv3568skn/VQ5vDEZhmH4uwjAbvv27ZoxY4ZycnLUuXNnPfbYY2rbtq0kOV5IHnrooXKPGzdunFJSUjRo0KBarRd1Q2XHzZYtWzR+/HiFhIQoIOB/7xstXrxYbdq08UvtqD1HjhzRtGnTtGXLFrVu3Vr333+/LrroIn388cdauHCh3nvvPUmnupKPP/64Pv/8czVu3FgTJ07UlVde6efq4S+VHTfdu3dXUFCQ07zbhx56SFdddZW/SocfVXbclDV37lwdOHDA60exwH8ITgAAAADgBafqAQAAAIAXBCcAAAAA8ILgBAAAAABeEJwAAAAAwAuCEwAAAAB4QXACAAAAAC8ITgAAAADgBcEJAIA/5OTkaO7cuVqzZo2/SwEA1DEEJwAAJJWUlOjhhx/Wf//7X02fPl0//PBDjRxn7ty56t69u6699toa2T8AoGaY/V0AAOD0M27cOG3dutXtumeffVaXXXZZ7RZUCQsWLFBgYKBefvllrVy5Uo888ojefvtthYWFVetxWrdurbPPPlstWrSo1v0CAGqWyTAMw99FAABOL/bgFBQUpDPPPNNp3aRJk3TBBReUe8zJkycVFBRUWyUCAOATOk4AgBrTokULLVq0yGnZN998o+7du0uSnn76af3zn//Ur7/+qr///e+69tprtWvXLr3yyivasmWL8vPzFR0drdTUVA0dOtSxj+PHj+vJJ5/UF198oSZNmigtLU2ffPKJtm7dqgsuuEDz5s2TJMdxpk2b5jg1zh7qrrnmGk2fPl2SlJ+fr1dffVWfffaZ8vLy1KxZMw0cOFB33HGHQkNDJUnTp0/XRx99pAsuuEADBw7Um2++qWPHjumCCy7Qww8/7NRB+uSTT/TOO+/ot99+k81mU4cOHXTXXXfp4osv1ty5czV//ny1bdtWK1askCSlp6dr5cqV2rdvnwoKCtSoUSN17dpVd955p2JjY6v/BwMA8BlznAAAfjN16lQdOHBA7dq1k8lk0u7duzVq1Cj9+9//lmEYio2NVXZ2tp5++mnNnz/f8bgZM2Zo7dq1Ki4uVmhoqObMmaMdO3ZUqYaTJ09q3Lhxeuedd3TkyBHFx8fr2LFjevvttzV58mS5npjx/fffa86cOQoKCpLFYtGGDRv0wgsvONa/9dZbeuihh/T9998rICBA0dHRysnJUWZmpscatm7dqpycHDVv3lxxcXE6ceKE1q9frzvuuEPFxcVVel4AgOpFxwkAUGP27t3r6PrYvfrqq46vBwwYoMcee0wBAQEqLS3V448/rvz8fCUmJuqNN95QaGio/vWvf2n27NlatGiRbrrpJh05ckTr16+XJI0cOVITJ07Url27dOONN1apxjVr1ujXX39VUFCQ/vWvf6lDhw769ddfddNNN+nrr7/W119/rR49eji2t9ls+uc//6kzzjhD9913n9avX6+vv/5aklRUVKS5c+dKks4991y9+OKLioyMlMVi0aFDhzzWMGHCBD3zzDMym0/9Wv7yyy81YcIE7d+/X9u2bXM6PgDAPwhOAIAa426OU1k33nijAgJOnfwQGBio7du3S5IyMjLUq1cvp22Li4v122+/6dixY45l/fv3lyTFxcWpY8eO+vnnn32u0X7MkydP6vrrry+3/ocffnAKLklJSTrjjDMkSfHx8Vq/fr0jFGVkZKiwsFCSNGzYMEVGRkqSwsPDFR4e7rGGvXv36oknntDOnTtlsViculwHDx70+TkBAKofwQkAUGM8zXGya9asmdvHNWnSRNHR0eWWBwYGVqmO0tJSx9f5+flut/EU8ho3bux03x6G/kw9ZeXm5upvf/ubTp48qYiICHXq1EklJSX69ddfJZ3qcAEA/I/gBADwG5PJ5HS/c+fOyszMVGRkpObMmaOoqChJ0tGjR/XVV1/pnHPOUW5urmP7zz77TF26dFF2drZ+++23cvtv1qyZDh8+rN27d0uSdu3apYyMjHLHlE4FlAceeEBnnXWWpFMdrg0bNvh0mlxiYqLCwsJUWFio999/X3369FFERIQKCwuVl5enmJiYco/55ZdfdPLkSUnSSy+9pHPPPVdr1qzR3//+90ofFwBQ8whOAIA6Y9SoUVq/fr1yc3N19dVXq0OHDjp+/LgOHjyoVq1a6YorrlB0dLT69eun9evXa+HChVq/fr3279+voKAgp86SJF144YVas2aN0tPTtX37dv3666/lLvaQnJyst99+W7/99ptuueUWxcXFqaSkRPv27ZPVatXy5cvVqFGjStUfGhqq8ePH64UXXtC2bdt09dVXq02bNtqzZ49uv/123XTTTeUek5iYqMDAQJWWlmrixIlq06ZNhfOhAAD+wVX1AAB1RlxcnBYuXKiBAwcqNDRUmZmZMgxDl1xyiW677TbHdlOnTtXAgQMVEhIii8WiiRMnOjpHZU2ePFm9evVSSEiIcnNzlZaWpvPPP99pm+DgYM2bN0+pqalq3bq1du/erRMnTqhTp0664447PJ5O6MnNN9+sJ554Queee65KSkqUk5Oj9u3bKyEhweNznjp1qtq3b6+SkhI1adJETzzxhE/HBADUPD4AFwBwWrB/PlPZz3ECAKC60HECAAAAAC8ITgAAAADgBafqAQAAAIAXdJwAAAAAwAuCEwAAAAB4QXACAAAAAC8ITgAAAADgBcEJAAAAALwgOAEAAACAFwQnAAAAAPCC4AQAAAAAXvw/EW3zNSnv2tEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "series_national.plot_fourier_analisys()\n",
    "series_national_tx.plot_fourier_analisys()\n",
    "series_north.plot_fourier_analisys()\n",
    "series_south.plot_fourier_analisys()\n",
    "series_southeast.plot_fourier_analisys()\n",
    "series_midwest.plot_fourier_analisys()\n",
    "series_northeast.plot_fourier_analisys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "04SecIwJPxTX"
   },
   "source": [
    "#### Coeficiente de Hurst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q3NmdIjOPzfn",
    "outputId": "9396e67c-ce98-4304-c17e-b5cae9fad9ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficiente de Hurst = 0.73 - Persistente\n"
     ]
    }
   ],
   "source": [
    "hurst = Hurst()\n",
    "\n",
    "H, HDescription = hurst.calculate(series_national)\n",
    "print(\"Coeficiente de Hurst = {:.2f} - {}\".format(H, HDescription))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz de Correlação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.99117946, 0.99902207, 0.99933316, 0.99674443,\n",
       "        0.99781922, 0.93759966, 0.93759966],\n",
       "       [0.99117946, 1.        , 0.98736418, 0.98824674, 0.9895263 ,\n",
       "        0.98806518, 0.91682587, 0.91682587],\n",
       "       [0.99902207, 0.98736418, 1.        , 0.99823866, 0.99529202,\n",
       "        0.99582853, 0.93995089, 0.93995089],\n",
       "       [0.99933316, 0.98824674, 0.99823866, 1.        , 0.99462224,\n",
       "        0.99685204, 0.93733252, 0.93733252],\n",
       "       [0.99674443, 0.9895263 , 0.99529202, 0.99462224, 1.        ,\n",
       "        0.99302146, 0.93926049, 0.93926049],\n",
       "       [0.99781922, 0.98806518, 0.99582853, 0.99685204, 0.99302146,\n",
       "        1.        , 0.93228786, 0.93228786],\n",
       "       [0.93759966, 0.91682587, 0.93995089, 0.93733252, 0.93926049,\n",
       "        0.93228786, 1.        , 1.        ],\n",
       "       [0.93759966, 0.91682587, 0.93995089, 0.93733252, 0.93926049,\n",
       "        0.93228786, 1.        , 1.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef([\n",
    "    series_national.slice(\n",
    "        max(series_national.start_time(),soybean_oil.start_time(),soybean_oil_future.start_time()), \n",
    "        min(series_national.end_time(),soybean_oil.end_time(),soybean_oil_future.end_time())\n",
    "    ).univariate_values(), \n",
    "    series_north.slice(\n",
    "        max(series_national.start_time(),soybean_oil.start_time(),soybean_oil_future.start_time()), \n",
    "        min(series_national.end_time(),soybean_oil.end_time(),soybean_oil_future.end_time())\n",
    "    ).univariate_values(), \n",
    "    series_south.slice(\n",
    "        max(series_national.start_time(),soybean_oil.start_time(),soybean_oil_future.start_time()), \n",
    "        min(series_national.end_time(),soybean_oil.end_time(),soybean_oil_future.end_time())\n",
    "    ).univariate_values(),\n",
    "    series_southeast.slice(\n",
    "        max(series_national.start_time(),soybean_oil.start_time(),soybean_oil_future.start_time()), \n",
    "        min(series_national.end_time(),soybean_oil.end_time(),soybean_oil_future.end_time())\n",
    "    ).univariate_values(),\n",
    "    series_midwest.slice(\n",
    "        max(series_national.start_time(),soybean_oil.start_time(),soybean_oil_future.start_time()), \n",
    "        min(series_national.end_time(),soybean_oil.end_time(),soybean_oil_future.end_time())\n",
    "    ).univariate_values(),\n",
    "    series_northeast.slice(\n",
    "        max(series_national.start_time(),soybean_oil.start_time(),soybean_oil_future.start_time()), \n",
    "        min(series_national.end_time(),soybean_oil.end_time(),soybean_oil_future.end_time())\n",
    "    ).univariate_values(),\n",
    "    soybean_oil.slice(\n",
    "        max(series_national.start_time(),soybean_oil.start_time(),soybean_oil_future.start_time()), \n",
    "        min(series_national.end_time(),soybean_oil.end_time(),soybean_oil_future.end_time())\n",
    "    ).univariate_values(),\n",
    "    soybean_oil_future.slice(\n",
    "        max(series_national.start_time(),soybean_oil.start_time(),soybean_oil_future.start_time()), \n",
    "        min(series_national.end_time(),soybean_oil.end_time(),soybean_oil_future.end_time())\n",
    "    ).univariate_values(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eqc-6hDQBDfZ"
   },
   "source": [
    "### Divisão dos Conjuntos de Treino, Validação e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TQBDn7HqC6_Z",
    "outputId": "dfa8472d-d411-4cd9-a8ff-cc0223b1bb63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinamento: 03/01/2022 - 23/01/2023\n",
      "Validação  : 30/01/2023 - 10/07/2023\n",
      "Teste      : 17/07/2023 - 08/07/2024\n"
     ]
    }
   ],
   "source": [
    "train_tx, val_tx, test_tx = series_national_tx.split(\n",
    "    [pd.Timestamp(VAL_START), pd.Timestamp(TEST_START)]\n",
    ")\n",
    "train, val, test = series_national.split(\n",
    "    [pd.Timestamp(VAL_START), pd.Timestamp(TEST_START)]\n",
    ")\n",
    "train_north, val_north, test_north = series_north.split(\n",
    "    [pd.Timestamp(VAL_START), pd.Timestamp(TEST_START)]\n",
    ")\n",
    "train_south, val_south, test_south = series_south.split(\n",
    "    [pd.Timestamp(VAL_START), pd.Timestamp(TEST_START)]\n",
    ")\n",
    "train_southeast, val_southeast, test_southeast = series_southeast.split(\n",
    "    [pd.Timestamp(VAL_START), pd.Timestamp(TEST_START)]\n",
    ")\n",
    "train_midwest, val_midwest, test_midwest = series_midwest.split(\n",
    "    [pd.Timestamp(VAL_START), pd.Timestamp(TEST_START)]\n",
    ")\n",
    "train_northeast, val_northeast, test_northeast = series_northeast.split(\n",
    "    [pd.Timestamp(VAL_START), pd.Timestamp(TEST_START)]\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Treinamento: {train.time_index[0].strftime(DATE_FORMAT_STRING)} - {train.time_index[- 1].strftime(DATE_FORMAT_STRING)}\"\n",
    ")\n",
    "print(\n",
    "    f\"Validação  : {val.time_index[0].strftime(DATE_FORMAT_STRING)} - {val.time_index[-1].strftime(DATE_FORMAT_STRING)}\"\n",
    ")\n",
    "print(\n",
    "    f\"Teste      : {test.time_index[0].strftime(DATE_FORMAT_STRING)} - {test.time_index[-1].strftime(DATE_FORMAT_STRING)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinamento: 04/01/1960 - 23/01/2023\n",
      "Validação  : 30/01/2023 - 10/07/2023\n",
      "Teste      : 17/07/2023 - 03/06/2024\n"
     ]
    }
   ],
   "source": [
    "train_soybean_oil, val_soybean_oil, test_soybean_oil = soybean_oil.split(\n",
    "    [pd.Timestamp(VAL_START), pd.Timestamp(TEST_START)]\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Treinamento: {train_soybean_oil.time_index[0].strftime(DATE_FORMAT_STRING)} - {train_soybean_oil.time_index[- 1].strftime(DATE_FORMAT_STRING)}\"\n",
    ")\n",
    "print(\n",
    "    f\"Validação  : {val_soybean_oil.time_index[0].strftime(DATE_FORMAT_STRING)} - {val_soybean_oil.time_index[-1].strftime(DATE_FORMAT_STRING)}\"\n",
    ")\n",
    "print(\n",
    "    f\"Teste      : {test_soybean_oil.time_index[0].strftime(DATE_FORMAT_STRING)} - {test_soybean_oil.time_index[-1].strftime(DATE_FORMAT_STRING)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinamento: 06/06/1994 - 23/01/2023\n",
      "Validação  : 30/01/2023 - 10/07/2023\n",
      "Teste      : 17/07/2023 - 01/04/2024\n"
     ]
    }
   ],
   "source": [
    "train_soybean_oil_future, val_soybean_oil_future, test_soybean_oil_future = soybean_oil_future.split(\n",
    "    [pd.Timestamp(VAL_START), pd.Timestamp(TEST_START)]\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Treinamento: {train_soybean_oil_future.time_index[0].strftime(DATE_FORMAT_STRING)} - {train_soybean_oil_future.time_index[- 1].strftime(DATE_FORMAT_STRING)}\"\n",
    ")\n",
    "print(\n",
    "    f\"Validação  : {val_soybean_oil_future.time_index[0].strftime(DATE_FORMAT_STRING)} - {val_soybean_oil_future.time_index[-1].strftime(DATE_FORMAT_STRING)}\"\n",
    ")\n",
    "print(\n",
    "    f\"Teste      : {test_soybean_oil_future.time_index[0].strftime(DATE_FORMAT_STRING)} - {test_soybean_oil_future.time_index[-1].strftime(DATE_FORMAT_STRING)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OCc6DwwwqvRW"
   },
   "source": [
    "### Aplicando o filtro de média móvel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "id": "BvYb1A0QqzuU",
    "outputId": "cd156d9b-78ec-453b-d577-3b718b10b60b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "series_national_filtered = series_national.filter()[0]\n",
    "series_national_tx_filtered = series_national_tx.filter()[0]\n",
    "series_north_filtered = series_north.filter()[0]\n",
    "series_south_filtered = series_south.filter()[0]\n",
    "series_southeast_filtered = series_southeast.filter()[0]\n",
    "series_midwest_filtered = series_midwest.filter()[0]\n",
    "series_northeast_filtered = series_northeast.filter()[0]\n",
    "\n",
    "plot_series(\n",
    "    [\n",
    "        series_national_filtered,\n",
    "        series_national_tx_filtered,\n",
    "        series_north_filtered,\n",
    "        series_south_filtered,\n",
    "        series_southeast_filtered,\n",
    "        series_midwest_filtered,\n",
    "        series_northeast_filtered,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31A9baGbBLRr"
   },
   "source": [
    "#### Divisão dos Conjuntos de Treino, Validação e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vzricOw9BOZY",
    "outputId": "bef09a46-f366-4523-d5cc-650a5a4570ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinamento: 03/01/2022 - 23/01/2023\n",
      "Validação  : 30/01/2023 - 10/07/2023\n",
      "Teste      : 17/07/2023 - 08/07/2024\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    train_tx_filtered,\n",
    "    val_tx_filtered,\n",
    "    test_tx_filtered,\n",
    ") = series_national_tx_filtered.split(\n",
    "    [pd.Timestamp(VAL_START), pd.Timestamp(TEST_START)]\n",
    ")\n",
    "train_filtered, val_filtered, test_filtered = series_national_filtered.split(\n",
    "    [pd.Timestamp(VAL_START), pd.Timestamp(TEST_START)]\n",
    ")\n",
    "(\n",
    "    train_north_filtered,\n",
    "    val_north_filtered,\n",
    "    test_north_filtered,\n",
    ") = series_north_filtered.split([pd.Timestamp(VAL_START), pd.Timestamp(TEST_START)])\n",
    "(\n",
    "    train_south_filtered,\n",
    "    val_south_filtered,\n",
    "    test_south_filtered,\n",
    ") = series_south_filtered.split([pd.Timestamp(VAL_START), pd.Timestamp(TEST_START)])\n",
    "(\n",
    "    train_southeast_filtered,\n",
    "    val_southeast_filtered,\n",
    "    test_southeast_filtered,\n",
    ") = series_southeast_filtered.split([pd.Timestamp(VAL_START), pd.Timestamp(TEST_START)])\n",
    "(\n",
    "    train_midwest_filtered,\n",
    "    val_midwest_filtered,\n",
    "    test_midwest_filtered,\n",
    ") = series_midwest_filtered.split([pd.Timestamp(VAL_START), pd.Timestamp(TEST_START)])\n",
    "(\n",
    "    train_northeast_filtered,\n",
    "    val_northeast_filtered,\n",
    "    test_northeast_filtered,\n",
    ") = series_northeast_filtered.split([pd.Timestamp(VAL_START), pd.Timestamp(TEST_START)])\n",
    "\n",
    "print(\n",
    "    f\"Treinamento: {train_filtered.time_index[0].strftime(DATE_FORMAT_STRING)} - {train_filtered.time_index[- 1].strftime(DATE_FORMAT_STRING)}\"\n",
    ")\n",
    "print(\n",
    "    f\"Validação  : {val_filtered.time_index[0].strftime(DATE_FORMAT_STRING)} - {val_filtered.time_index[-1].strftime(DATE_FORMAT_STRING)}\"\n",
    ")\n",
    "print(\n",
    "    f\"Teste      : {test_filtered.time_index[0].strftime(DATE_FORMAT_STRING)} - {test_filtered.time_index[-1].strftime(DATE_FORMAT_STRING)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qIohiT8sRna"
   },
   "source": [
    "#### Novamente verificando sazonalidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Ne682Xf6r7cy",
    "outputId": "1a484631-557d-40ae-fdd5-6c010d9fc920"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "series_national_filtered.slice(train.start_time(), val.end_time()).plot_acf()\n",
    "series_national_tx_filtered.slice(train.start_time(), val.end_time()).plot_acf()\n",
    "series_north_filtered.slice(train.start_time(), val.end_time()).plot_acf()\n",
    "series_south_filtered.slice(train.start_time(), val.end_time()).plot_acf()\n",
    "series_southeast_filtered.slice(train.start_time(), val.end_time()).plot_acf()\n",
    "series_midwest_filtered.slice(train.start_time(), val.end_time()).plot_acf()\n",
    "series_northeast_filtered.slice(train.start_time(), val.end_time()).plot_acf()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fI-zjdznsVgA"
   },
   "source": [
    "#### Novamente verificando ciclos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "PzCv3_Z3sYpl",
    "outputId": "411f0537-90dc-437c-8e3b-a68d04cb1c00"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "series_national_filtered.slice(train.start_time(), val.end_time()).plot_fourier_analisys()\n",
    "series_north_filtered.slice(train.start_time(), val.end_time()).plot_fourier_analisys()\n",
    "series_south_filtered.slice(train.start_time(), val.end_time()).plot_fourier_analisys()\n",
    "series_southeast_filtered.slice(train.start_time(), val.end_time()).plot_fourier_analisys()\n",
    "series_midwest_filtered.slice(train.start_time(), val.end_time()).plot_fourier_analisys()\n",
    "series_northeast_filtered.slice(train.start_time(), val.end_time()).plot_fourier_analisys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y5YTqq0KNaSI"
   },
   "source": [
    "# Treinando o Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYl0LG0eASHh",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cFJa1bqWlawh"
   },
   "source": [
    "### Brasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "oh8Hx2f6AV74",
    "outputId": "0daf3266-7215-4860-c5b8-8cacbd3b2c91",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_arima = []\n",
    "\n",
    "for p in range(12, 30, 4):\n",
    "    for d in range(1, 3):\n",
    "        for q in range(0, 5, 2):\n",
    "            for s in range(0, 30, 5):\n",
    "                try:\n",
    "                    model = ARIMA(\n",
    "                        p=p, \n",
    "                        d=d, \n",
    "                        seasonal_order=(\n",
    "                            0, \n",
    "                            0, \n",
    "                            q, \n",
    "                            s\n",
    "                        ),\n",
    "                    )\n",
    "                    model.fit(train_scaled)\n",
    "                    pred_series, mape_arima, sle_arima = eval_model(\n",
    "                        model,\n",
    "                        len(val_scaled),\n",
    "                        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "                        val_scaled,\n",
    "                        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                        plot = False,\n",
    "                    )\n",
    "                    uTheil = UTheil()\n",
    "                    u1_arima = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "                    u2_arima = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "                    print({\n",
    "                        'MAPE': mape_arima,\n",
    "                        'SLE': sle_arima,\n",
    "                        'U1': u1_arima,\n",
    "                        'U2': u1_arima,\n",
    "                        'p': p,\n",
    "                        'd': d,\n",
    "                        'q': q,\n",
    "                        's': s,\n",
    "                    })\n",
    "                    models_arima.append({\n",
    "                        'MAPE': mape_arima,\n",
    "                        'SLE': sle_arima,\n",
    "                        'U1': u1_arima,\n",
    "                        'U2': u1_arima,\n",
    "                        'p': p,\n",
    "                        'd': d,\n",
    "                        'q': q,\n",
    "                        's': s,\n",
    "                    })\n",
    "                except:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_arima in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'd': min(models_arima, key=lambda d: d[i])['d'],\n",
    "                                'p': min(models_arima, key=lambda d: d[i])['p'],\n",
    "                                'q': min(models_arima, key=lambda d: d[i])['q'],\n",
    "                                's': min(models_arima, key=lambda d: d[i])['s'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_arima['name'])\n",
    "    model = ARIMA(\n",
    "        p=best_model_arima['p'],\n",
    "        d=best_model_arima['d'],\n",
    "        seasonal_order=(\n",
    "            0, \n",
    "            0, \n",
    "            best_model_arima['q'], \n",
    "            best_model_arima['s']\n",
    "        ),\n",
    "    )\n",
    "    model.fit(train_scaled)\n",
    "    pred_series, mape_arima, sle_arima = eval_model(\n",
    "        model,\n",
    "        len(val_scaled),\n",
    "        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_arima = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "    u2_arima = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_arima)\n",
    "    print('U2: ', u2_arima)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RpTYBZKbvEXA",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Brasil (detrend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_arima = []\n",
    "\n",
    "for p in range(12, 30, 4):\n",
    "    for d in range(1, 3):\n",
    "        for q in range(0, 5, 2):\n",
    "            for s in range(0, 30, 5):\n",
    "                try:\n",
    "                    model = ARIMA(\n",
    "                        p=p, \n",
    "                        d=d, \n",
    "                        seasonal_order=(\n",
    "                            0, \n",
    "                            0, \n",
    "                            q, \n",
    "                            s\n",
    "                        ),\n",
    "                    )\n",
    "                    model.fit(train_detrend_scaled)\n",
    "                    pred_series, mape_arima, sle_arima = eval_model(\n",
    "                        model,\n",
    "                        len(val_detrend_scaled),\n",
    "                        series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "                        val_detrend_scaled,\n",
    "                        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                        plot = False,\n",
    "                    )\n",
    "                    uTheil = UTheil()\n",
    "                    u1_arima = uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)])\n",
    "                    u2_arima = uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)])\n",
    "                    print({\n",
    "                        'MAPE': mape_arima,\n",
    "                        'SLE': sle_arima,\n",
    "                        'U1': u1_arima,\n",
    "                        'U2': u1_arima,\n",
    "                        'p': p,\n",
    "                        'd': d,\n",
    "                        'q': q,\n",
    "                        's': s,\n",
    "                    })\n",
    "                    models_arima.append({\n",
    "                        'MAPE': mape_arima,\n",
    "                        'SLE': sle_arima,\n",
    "                        'U1': u1_arima,\n",
    "                        'U2': u1_arima,\n",
    "                        'p': p,\n",
    "                        'd': d,\n",
    "                        'q': q,\n",
    "                        's': s,\n",
    "                    })\n",
    "                except:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "eQRDovSuvKfn",
    "outputId": "6f58cbd9-a11b-4ad0-bb79-6fd9092f872b"
   },
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_arima in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'd': min(models_arima, key=lambda d: d[i])['d'],\n",
    "                                'p': min(models_arima, key=lambda d: d[i])['p'],\n",
    "                                'q': min(models_arima, key=lambda d: d[i])['q'],\n",
    "                                's': min(models_arima, key=lambda d: d[i])['s'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_arima['name'])\n",
    "    model = ARIMA(\n",
    "        p=best_model_arima['p'],\n",
    "        d=best_model_arima['d'],\n",
    "        seasonal_order=(\n",
    "            0, \n",
    "            0, \n",
    "            best_model_arima['q'], \n",
    "            best_model_arima['s']\n",
    "        ),\n",
    "    )\n",
    "    model.fit(train_detrend_scaled)\n",
    "    pred_series, mape_arima, sle_arima = eval_model(\n",
    "        model,\n",
    "        len(val_detrend_scaled),\n",
    "        series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_detrend_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_arima = uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)])\n",
    "    u2_arima = uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_arima)\n",
    "    print('U2: ', u2_arima)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cFJa1bqWlawh",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Brasil (filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "oh8Hx2f6AV74",
    "outputId": "0daf3266-7215-4860-c5b8-8cacbd3b2c91",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_arima = []\n",
    "\n",
    "for p in range(12, 50, 4):\n",
    "    for d in range(1, 3):\n",
    "        for q in range(0, 5, 2):\n",
    "            for s in range(0, 30, 5):\n",
    "                try:\n",
    "                    model = ARIMA(\n",
    "                        p=p, \n",
    "                        d=d, \n",
    "                        seasonal_order=(\n",
    "                            0, \n",
    "                            0, \n",
    "                            q, \n",
    "                            s\n",
    "                        ),\n",
    "                    )\n",
    "                    model.fit(train_filtered_scaled)\n",
    "                    pred_series, mape_arima, sle_arima = eval_model(\n",
    "                        model,\n",
    "                        len(val_filtered_scaled),\n",
    "                        series_national_filtered_scaled.slice(train.start_time(), val.end_time()),\n",
    "                        val_filtered_scaled,\n",
    "                        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                        plot = False,\n",
    "                    )\n",
    "                    uTheil = UTheil()\n",
    "                    u1_arima = uTheil.calculateU1(val_filtered_scaled, pred_series[:len(val)])\n",
    "                    u2_arima = uTheil.calculateU2(val_filtered_scaled, pred_series[:len(val)])\n",
    "                    print({\n",
    "                        'MAPE': mape_arima,\n",
    "                        'SLE': sle_arima,\n",
    "                        'U1': u1_arima,\n",
    "                        'U2': u1_arima,\n",
    "                        'p': p,\n",
    "                        'd': d,\n",
    "                        'q': q,\n",
    "                        's': s,\n",
    "                    })\n",
    "                    models_arima.append({\n",
    "                        'MAPE': mape_arima,\n",
    "                        'SLE': sle_arima,\n",
    "                        'U1': u1_arima,\n",
    "                        'U2': u1_arima,\n",
    "                        'p': p,\n",
    "                        'd': d,\n",
    "                        'q': q,\n",
    "                        's': s,\n",
    "                    })\n",
    "                except:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_arima in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'd': min(models_arima, key=lambda d: d[i])['d'],\n",
    "                                'p': min(models_arima, key=lambda d: d[i])['p'],\n",
    "                                'q': min(models_arima, key=lambda d: d[i])['q'],\n",
    "                                's': min(models_arima, key=lambda d: d[i])['s'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_arima['name'])\n",
    "    model = ARIMA(\n",
    "        p=best_model_arima['p'],\n",
    "        d=best_model_arima['d'],\n",
    "        seasonal_order=(\n",
    "            0, \n",
    "            0, \n",
    "            best_model_arima['q'], \n",
    "            best_model_arima['s']\n",
    "        ),\n",
    "    )\n",
    "    model.fit(train_filtered_scaled)\n",
    "    pred_series, mape_arima, sle_arima = eval_model(\n",
    "        model,\n",
    "        len(val_filtered_scaled),\n",
    "        series_national_filtered_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_filtered_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_arima = uTheil.calculateU1(val_filtered_scaled, pred_series[:len(val)])\n",
    "    u2_arima = uTheil.calculateU2(val_filtered_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_arima)\n",
    "    print('U2: ', u2_arima)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RpTYBZKbvEXA",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Brasil (filtered/detrend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_arima = []\n",
    "\n",
    "for p in range(12, 30, 4):\n",
    "    for d in range(1, 3):\n",
    "        for q in range(0, 5, 2):\n",
    "            for s in range(0, 30, 5):\n",
    "                try:\n",
    "                    model = ARIMA(\n",
    "                        p=p, \n",
    "                        d=d, \n",
    "                        seasonal_order=(\n",
    "                            0, \n",
    "                            0, \n",
    "                            q, \n",
    "                            s\n",
    "                        ),\n",
    "                    )\n",
    "                    model.fit(train_detrend_filtered_scaled)\n",
    "                    pred_series, mape_arima, sle_arima = eval_model(\n",
    "                        model,\n",
    "                        len(val_detrend_filtered_scaled),\n",
    "                        series_national_detrend_filtered_scaled.slice(train.start_time(), val.end_time()),\n",
    "                        val_detrend_filtered_scaled,\n",
    "                        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                        plot = False,\n",
    "                    )\n",
    "                    uTheil = UTheil()\n",
    "                    u1_arima = uTheil.calculateU1(val_detrend_filtered_scaled, pred_series[:len(val)])\n",
    "                    u2_arima = uTheil.calculateU2(val_detrend_filtered_scaled, pred_series[:len(val)])\n",
    "                    print({\n",
    "                        'MAPE': mape_arima,\n",
    "                        'SLE': sle_arima,\n",
    "                        'U1': u1_arima,\n",
    "                        'U2': u1_arima,\n",
    "                        'p': p,\n",
    "                        'd': d,\n",
    "                        'q': q,\n",
    "                        's': s,\n",
    "                    })\n",
    "                    models_arima.append({\n",
    "                        'MAPE': mape_arima,\n",
    "                        'SLE': sle_arima,\n",
    "                        'U1': u1_arima,\n",
    "                        'U2': u1_arima,\n",
    "                        'p': p,\n",
    "                        'd': d,\n",
    "                        'q': q,\n",
    "                        's': s,\n",
    "                    })\n",
    "                except:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "eQRDovSuvKfn",
    "outputId": "6f58cbd9-a11b-4ad0-bb79-6fd9092f872b"
   },
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_arima in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'd': min(models_arima, key=lambda d: d[i])['d'],\n",
    "                                'p': min(models_arima, key=lambda d: d[i])['p'],\n",
    "                                'q': min(models_arima, key=lambda d: d[i])['q'],\n",
    "                                's': min(models_arima, key=lambda d: d[i])['s'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_arima['name'])\n",
    "    model = ARIMA(\n",
    "        p=best_model_arima['p'],\n",
    "        d=best_model_arima['d'],\n",
    "        seasonal_order=(\n",
    "            0, \n",
    "            0, \n",
    "            best_model_arima['q'], \n",
    "            best_model_arima['s']\n",
    "        ),\n",
    "    )\n",
    "    model.fit(train_detrend_filtered_scaled)\n",
    "    pred_series, mape_arima, sle_arima = eval_model(\n",
    "        model,\n",
    "        len(val_detrend_filtered_scaled),\n",
    "        series_national_detrend_filtered_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_detrend_filtered_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_arima = uTheil.calculateU1(val_detrend_filtered_scaled, pred_series[:len(val)])\n",
    "    u2_arima = uTheil.calculateU2(val_detrend_filtered_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_arima)\n",
    "    print('U2: ', u2_arima)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zyp0EPpTHtno",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4Theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fjt1cKZTlmNZ"
   },
   "source": [
    "### Brasil (taxa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Ww2AgOCAHsad",
    "outputId": "2a9468dc-974d-4b08-d2ae-0ff892684070",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_4theta = []\n",
    "\n",
    "for theta in [i / 10 for i in range(3, 21)]:\n",
    "    for seasonality_period in range(7, 10, 1):\n",
    "        try:\n",
    "            model = FourTheta(\n",
    "                theta=theta, \n",
    "                seasonality_period=seasonality_period,\n",
    "            )\n",
    "            model.fit(train_tx)\n",
    "            pred_series, mape_4theta, sle_4theta = eval_model(\n",
    "                model,\n",
    "                len(val_tx),\n",
    "                series_national_tx.slice(train.start_time(), val.end_time()),\n",
    "                val_tx,\n",
    "                returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                plot = False,\n",
    "            )\n",
    "            uTheil = UTheil()\n",
    "            u1_4theta = uTheil.calculateU1(val_tx, pred_series[:len(val)])\n",
    "            u2_4theta = uTheil.calculateU2(val_tx, pred_series[:len(val)])\n",
    "            print({\n",
    "                'MAPE': mape_4theta,\n",
    "                'SLE': sle_4theta,\n",
    "                'U1': u1_4theta,\n",
    "                'U2': u1_4theta,\n",
    "                'theta': theta,\n",
    "                'seasonality_period': seasonality_period,\n",
    "            })\n",
    "            models_4theta.append({\n",
    "                'MAPE': mape_4theta,\n",
    "                'SLE': sle_4theta,\n",
    "                'U1': u1_4theta,\n",
    "                'U2': u1_4theta,\n",
    "                'theta': theta,\n",
    "                'seasonality_period': seasonality_period,\n",
    "            })\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_4theta in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'theta': min(models_4theta, key=lambda d: d[i])['theta'],\n",
    "                                'seasonality_period': min(models_4theta, key=lambda d: d[i])['seasonality_period'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_4theta['name'])\n",
    "    model = FourTheta(\n",
    "        theta=best_model_4theta['theta'], \n",
    "        seasonality_period=best_model_4theta['seasonality_period'],\n",
    "    )\n",
    "    model.fit(train_tx)\n",
    "    pred_series, mape_4theta, sle_4theta = eval_model(\n",
    "        model,\n",
    "        len(val_tx),\n",
    "        series_national_tx.slice(train.start_time(), val.end_time()),\n",
    "        val_tx,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_4theta = uTheil.calculateU1(val_tx, pred_series[:len(val)])\n",
    "    u2_4theta = uTheil.calculateU2(val_tx, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_4theta)\n",
    "    print('U2: ', u2_4theta)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voltando ao original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "kNTf9sEhJBzn",
    "outputId": "6f49e1d2-96ff-45bc-b0ac-3c98cb7433e2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_4theta in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'theta': min(models_4theta, key=lambda d: d[i])['theta'],\n",
    "                                'seasonality_period': min(models_4theta, key=lambda d: d[i])['seasonality_period'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_4theta['name'])\n",
    "    model = FourTheta(\n",
    "        theta=best_model_4theta['theta'], \n",
    "        seasonality_period=best_model_4theta['seasonality_period'],\n",
    "    )\n",
    "    model.fit(train_tx)\n",
    "    pred_series, mape_4theta, sle_4theta = eval_model(\n",
    "        model,\n",
    "        len(val_tx),\n",
    "        series_national_tx.slice(train.start_time(), val.end_time()),\n",
    "        val_tx,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "        plot=False,\n",
    "    )\n",
    "    pred_series = pred_series.inverse_ratio(train[-1])\n",
    "    pred_series = Scaler().fit(train).transform(pred_series)\n",
    "    uTheil = UTheil()\n",
    "    mape_4theta = mape(val_scaled, pred_series[: len(val)])\n",
    "    sle_4theta = sle(val_scaled, pred_series[: len(val)])\n",
    "    u1_4theta = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "    u2_4theta = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "    plot_series_labels(\n",
    "        [series_national_scaled.slice(train.start_time(), val.end_time()), pred_series],\n",
    "        [\"actual\", \"forecast\"],\n",
    "        \"MAPE: {:.2f}%\".format(mape_4theta) + \" - SLE: {:.2f}\".format(sle_4theta),\n",
    "    )\n",
    "    print('Model (tx): ', model)\n",
    "    print('U1: ', u1_4theta)\n",
    "    print('U2: ', u2_4theta)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## RW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomWalkModel(step=1e-1, random_state=0)\n",
    "model.fit(train_scaled[:1])\n",
    "pred_series, mape_rw = eval_model(\n",
    "    model,\n",
    "    len(series_national_scaled.slice(train.start_time(), val.end_time())),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    returned = ['PREDICT_VALUES', 'MAPE_VAL'],\n",
    ")\n",
    "uTheil = UTheil()\n",
    "u1_rw = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "u2_rw = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "print('Model (tx): ', model)\n",
    "print('U1: ', u1_rw)\n",
    "print('U2: ', u2_rw)\n",
    "print('')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCOkspmJ9Wrd"
   },
   "source": [
    "## NARX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brasil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGF6kc-h4BJU"
   },
   "source": [
    "#### Janela Deslizante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "id": "FQ705nUH9WXK",
    "outputId": "e2eb8927-8d66-4d9f-8946-47656d9956c8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_narx = []\n",
    "\n",
    "for input_chunk_length in [4*3, 4*6]:\n",
    "    for output_chunk_length in [4, 4*2, 4*3]:\n",
    "       for hidden_size in range(3, 7):\n",
    "           for batch_size in range(3, 7):\n",
    "               for lr in range(2, 5):\n",
    "                    model = NARX(\n",
    "                        input_chunk_length=input_chunk_length,\n",
    "                        output_chunk_length=output_chunk_length,\n",
    "                        hidden_size=2**hidden_size,\n",
    "                        batch_size=2**batch_size,\n",
    "                        n_epochs=200,\n",
    "                        lr=10**(-lr),\n",
    "                        preprocessing = [MinMaxScaler()],\n",
    "                        random_state = 0,\n",
    "                    )\n",
    "                    model.fit(train, val)\n",
    "                    metrics = model.evaluate(val)\n",
    "                    print({\n",
    "                        'mape': metrics['mape'],\n",
    "                        'sle': metrics['sle'],\n",
    "                        'rmse': metrics['rmse'],\n",
    "                        'mse': metrics['mse'],\n",
    "                        'u1': metrics['u1'],\n",
    "                        'u2': metrics['u2'],\n",
    "                        'lr': 10**(-lr),\n",
    "                        'input_chunk_length': input_chunk_length,\n",
    "                        'output_chunk_length': output_chunk_length,\n",
    "                        'hidden_size': 2**hidden_size,\n",
    "                        'batch_size': 2**batch_size,\n",
    "                    })\n",
    "                    models_narx.append({\n",
    "                        'mape': metrics['mape'],\n",
    "                        'sle': metrics['sle'],\n",
    "                        'rmse': metrics['rmse'],\n",
    "                        'mse': metrics['mse'],\n",
    "                        'u1': metrics['u1'],\n",
    "                        'u2': metrics['u2'],\n",
    "                        'lr': 10**(-lr),\n",
    "                        'input_chunk_length': input_chunk_length,\n",
    "                        'output_chunk_length': output_chunk_length,\n",
    "                        'hidden_size': 2**hidden_size,\n",
    "                        'batch_size': 2**batch_size,\n",
    "                    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 416    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 396    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MAPE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0aaa6c995474a7a8ffbfb8a141f209d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75385a19ba604f5eac25770c0c5a460e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 208    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 136    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "616       Trainable params\n",
      "0         Non-trainable params\n",
      "616       Total params\n",
      "0.002     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.02704113427395402, 'mse': 0.02051727044901311, 'rmse': 0.10972905514399223, 'sle': 0.015053363879895906, 'u1': 0.42899109319645734, 'u2': 1.793527923266237}\n",
      "Model:  NARX(training=True, prepare_data_per_node=True, allow_zero_length_dataloader_with_multiple_devices=False, n_epochs=200, input_chunk_length=12, output_chunk_length=12, batch_size=8, random_state=0, fit_called=True, optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.0001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), window_model=SlidingWindow(input_chunk_length=12, output_chunk_length=12), preprocessing=[MinMaxScaler()], pl_trainer_kwargs={}, hidden_size=32, last_index=2023-01-23 00:00:00, data_freq=<Week: weekday=0>, last_data=[5.92149, 6.03723, 6.14058, 6.19233, 6.07111, 5.86276, 5.70988, 5.73702, 5.71108, 5.66975, 5.61122, 5.49708])\n",
      "\n",
      "\n",
      "Best SLE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca7c997d71354320ac029918488872bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aed824a942b4a088fa270432998ecdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 208    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 136    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "616       Trainable params\n",
      "0         Non-trainable params\n",
      "616       Total params\n",
      "0.002     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.031231929426551976, 'mse': 0.022705765952552, 'rmse': 0.12585773557662966, 'sle': 0.011797287487654738, 'u1': 0.3712902440069809, 'u2': 2.1525720498297525}\n",
      "Model:  NARX(training=True, prepare_data_per_node=True, allow_zero_length_dataloader_with_multiple_devices=False, n_epochs=200, input_chunk_length=12, output_chunk_length=8, batch_size=8, random_state=0, fit_called=True, optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), window_model=SlidingWindow(input_chunk_length=12, output_chunk_length=8), preprocessing=[MinMaxScaler()], pl_trainer_kwargs={}, hidden_size=16, last_index=2023-01-23 00:00:00, data_freq=<Week: weekday=0>, last_data=[5.92149, 6.03723, 6.14058, 6.19233, 6.07111, 5.86276, 5.70988, 5.73702, 5.71108, 5.66975, 5.61122, 5.49708])\n",
      "\n",
      "\n",
      "Best U1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a30c71d917944834b36b3dc4b129ba64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ac0372d459e4551a876d6da6135357f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 104    | train\n",
      "2 | lin2    | Linear  | 72     | train\n",
      "3 | lin3    | Linear  | 36     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "212       Trainable params\n",
      "0         Non-trainable params\n",
      "212       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.031231929426551976, 'mse': 0.022705765952552, 'rmse': 0.12585773557662966, 'sle': 0.011797287487654738, 'u1': 0.3712902440069809, 'u2': 2.1525720498297525}\n",
      "Model:  NARX(training=True, prepare_data_per_node=True, allow_zero_length_dataloader_with_multiple_devices=False, n_epochs=200, input_chunk_length=12, output_chunk_length=8, batch_size=8, random_state=0, fit_called=True, optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), window_model=SlidingWindow(input_chunk_length=12, output_chunk_length=8), preprocessing=[MinMaxScaler()], pl_trainer_kwargs={}, hidden_size=16, last_index=2023-01-23 00:00:00, data_freq=<Week: weekday=0>, last_data=[5.92149, 6.03723, 6.14058, 6.19233, 6.07111, 5.86276, 5.70988, 5.73702, 5.71108, 5.66975, 5.61122, 5.49708])\n",
      "\n",
      "\n",
      "Best U2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6627babfc5a48388eba2cb3d2a06f32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dc693701d244a839ce1f810a1091cb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.0445057182614803, 'mse': 0.039078972669182005, 'rmse': 0.19574651955390932, 'sle': 0.028038664719204034, 'u1': 0.9494163975537522, 'u2': 0.5838740656105939}\n",
      "Model:  NARX(training=True, prepare_data_per_node=True, allow_zero_length_dataloader_with_multiple_devices=False, n_epochs=200, input_chunk_length=12, output_chunk_length=4, batch_size=16, random_state=0, fit_called=True, optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.0001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), window_model=SlidingWindow(input_chunk_length=12, output_chunk_length=4), preprocessing=[MinMaxScaler()], pl_trainer_kwargs={}, hidden_size=8, last_index=2023-01-23 00:00:00, data_freq=<Week: weekday=0>, last_data=[5.92149, 6.03723, 6.14058, 6.19233, 6.07111, 5.86276, 5.70988, 5.73702, 5.71108, 5.66975, 5.61122, 5.49708])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_narx in [\n",
    "                            {\n",
    "                                'name': 'MAPE',\n",
    "                                'input_chunk_length': min(models_narx, key=lambda d: d['mape'])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_narx, key=lambda d: d['mape'])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_narx, key=lambda d: d['mape'])['hidden_size'],\n",
    "                                'batch_size': min(models_narx, key=lambda d: d['mape'])['batch_size'],\n",
    "                                'lr': min(models_narx, key=lambda d: d['mape'])['lr'],\n",
    "                            },\n",
    "                            {\n",
    "                                'name': 'SLE',\n",
    "                                'input_chunk_length': min(models_narx, key=lambda d: d['sle'])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_narx, key=lambda d: d['sle'])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_narx, key=lambda d: d['sle'])['hidden_size'],\n",
    "                                'batch_size': min(models_narx, key=lambda d: d['sle'])['batch_size'],\n",
    "                                'lr': min(models_narx, key=lambda d: d['sle'])['lr'],\n",
    "                            },\n",
    "                            {\n",
    "                                'name': 'U1',\n",
    "                                'input_chunk_length': min(models_narx, key=lambda d: d['u1'])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_narx, key=lambda d: d['u1'])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_narx, key=lambda d: d['u1'])['hidden_size'],\n",
    "                                'batch_size': min(models_narx, key=lambda d: d['u1'])['batch_size'],\n",
    "                                'lr': min(models_narx, key=lambda d: d['u1'])['lr'],\n",
    "                            },\n",
    "                            {\n",
    "                                'name': 'U2',\n",
    "                                'input_chunk_length': min(models_narx, key=lambda d: d['u2'])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_narx, key=lambda d: d['u2'])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_narx, key=lambda d: d['u2'])['hidden_size'],\n",
    "                                'batch_size': min(models_narx, key=lambda d: d['u2'])['batch_size'],\n",
    "                                'lr': min(models_narx, key=lambda d: d['u2'])['lr'],\n",
    "                            },\n",
    "                        ]:\n",
    "    print('Best', best_model_narx['name'])\n",
    "    model = NARX(\n",
    "        input_chunk_length=best_model_narx['input_chunk_length'],\n",
    "        output_chunk_length=best_model_narx['output_chunk_length'],\n",
    "        hidden_size=best_model_narx['hidden_size'],\n",
    "        batch_size=best_model_narx['batch_size'],\n",
    "        lr=best_model_narx['lr'],\n",
    "        n_epochs=200,\n",
    "        preprocessing = [MinMaxScaler()],\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit(train)\n",
    "    print(model.evaluate(val))\n",
    "    print('Model: ', model)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NARX(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        lr=lr,\n",
    "        n_epochs=n_epochs,\n",
    "        preprocessing = [MinMaxScaler()],\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(train)\n",
    "        metrics = model.evaluate(val)\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "    \n",
    "    mape_val = metrics['mape']\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:36:19,020] A new study created in memory with name: no-name-63bc1527-5b2b-41ad-802c-f0a768254865\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 1.9 K  | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 260    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "6.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.3 K     Total params\n",
      "0.025     Total estimated model params size (MB)\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a54ae43d3c34fc5afb9868d2305835d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=574` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11e28c24af774e9790ac48f4d3d9340e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:36:27,069] Trial 0 finished with value: inf and parameters: {'in_len': 29, 'out_len': 4, 'hidden_size': 6, 'batch_size': 6, 'n_epochs': 574, 'lr': 0.0034764503463942864}. Best is trial 0 with value: inf.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 352    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 187    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "811       Trainable params\n",
      "0         Non-trainable params\n",
      "811       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 29, 'out_len': 4, 'hidden_size': 6, 'batch_size': 6, 'n_epochs': 574, 'lr': 0.0034764503463942864}\n",
      "Best value: inf, Best params: {'in_len': 29, 'out_len': 4, 'hidden_size': 6, 'batch_size': 6, 'n_epochs': 574, 'lr': 0.0034764503463942864}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "498556d63a2d45d3a8a54eb78723dfb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=641` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f6de852d65d40f38e6d8be7b86a7f8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:36:35,602] Trial 1 finished with value: inf and parameters: {'in_len': 21, 'out_len': 11, 'hidden_size': 4, 'batch_size': 3, 'n_epochs': 641, 'lr': 9.460397107030346e-05}. Best is trial 0 with value: inf.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 384    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 68     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "724       Trainable params\n",
      "0         Non-trainable params\n",
      "724       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 21, 'out_len': 11, 'hidden_size': 4, 'batch_size': 3, 'n_epochs': 641, 'lr': 9.460397107030346e-05}\n",
      "Best value: inf, Best params: {'in_len': 29, 'out_len': 4, 'hidden_size': 6, 'batch_size': 6, 'n_epochs': 574, 'lr': 0.0034764503463942864}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b141fbffa1d74e389588b5aeec62b234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=609` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fef9c16c94074370a59aded48d99305b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:36:43,544] Trial 2 finished with value: inf and parameters: {'in_len': 23, 'out_len': 4, 'hidden_size': 4, 'batch_size': 6, 'n_epochs': 609, 'lr': 6.835708785703428e-05}. Best is trial 0 with value: inf.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 4.0 K  | train\n",
      "2 | lin2    | Linear  | 16.5 K | train\n",
      "3 | lin3    | Linear  | 258    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "20.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.7 K    Total params\n",
      "0.083     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 23, 'out_len': 4, 'hidden_size': 4, 'batch_size': 6, 'n_epochs': 609, 'lr': 6.835708785703428e-05}\n",
      "Best value: inf, Best params: {'in_len': 29, 'out_len': 4, 'hidden_size': 6, 'batch_size': 6, 'n_epochs': 574, 'lr': 0.0034764503463942864}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e297b89879d94c1d8bcf8798dd683778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=764` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1fe915c0e6f4a10b2b5fcdefec17455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:36:58,945] Trial 3 finished with value: inf and parameters: {'in_len': 30, 'out_len': 2, 'hidden_size': 7, 'batch_size': 3, 'n_epochs': 764, 'lr': 0.0001916267418004316}. Best is trial 0 with value: inf.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 30, 'out_len': 2, 'hidden_size': 7, 'batch_size': 3, 'n_epochs': 764, 'lr': 0.0001916267418004316}\n",
      "Best value: inf, Best params: {'in_len': 29, 'out_len': 4, 'hidden_size': 6, 'batch_size': 6, 'n_epochs': 574, 'lr': 0.0034764503463942864}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 1.5 K  | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 260    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "5.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.9 K     Total params\n",
      "0.024     Total estimated model params size (MB)\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cacec4199d04952b4e57d5ae048360d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=425` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "568ff7c3495c4409af760b23f99710a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:37:05,198] Trial 4 finished with value: inf and parameters: {'in_len': 22, 'out_len': 4, 'hidden_size': 6, 'batch_size': 3, 'n_epochs': 425, 'lr': 0.0008187405545471868}. Best is trial 0 with value: inf.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 3.5 K  | train\n",
      "2 | lin2    | Linear  | 16.5 K | train\n",
      "3 | lin3    | Linear  | 258    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "20.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.2 K    Total params\n",
      "0.081     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 22, 'out_len': 4, 'hidden_size': 6, 'batch_size': 3, 'n_epochs': 425, 'lr': 0.0008187405545471868}\n",
      "Best value: inf, Best params: {'in_len': 29, 'out_len': 4, 'hidden_size': 6, 'batch_size': 6, 'n_epochs': 574, 'lr': 0.0034764503463942864}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "828c87e229504e839f257915b1911efe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=281` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf33aeb0b1ff4a8094a1196dcd4ebeff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:37:09,715] Trial 5 finished with value: inf and parameters: {'in_len': 26, 'out_len': 2, 'hidden_size': 7, 'batch_size': 7, 'n_epochs': 281, 'lr': 0.00012799323743219602}. Best is trial 0 with value: inf.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 704    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 198    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "2.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 26, 'out_len': 2, 'hidden_size': 7, 'batch_size': 7, 'n_epochs': 281, 'lr': 0.00012799323743219602}\n",
      "Best value: inf, Best params: {'in_len': 29, 'out_len': 4, 'hidden_size': 6, 'batch_size': 6, 'n_epochs': 574, 'lr': 0.0034764503463942864}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eaed63937444836a19a753c9f80dc2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=335` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61211231868243f1b499a7cdd3ae97c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:37:14,387] Trial 6 finished with value: inf and parameters: {'in_len': 21, 'out_len': 6, 'hidden_size': 5, 'batch_size': 6, 'n_epochs': 335, 'lr': 9.271044255884936e-05}. Best is trial 0 with value: inf.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 416    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 231    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "1.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.7 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 21, 'out_len': 6, 'hidden_size': 5, 'batch_size': 6, 'n_epochs': 335, 'lr': 9.271044255884936e-05}\n",
      "Best value: inf, Best params: {'in_len': 29, 'out_len': 4, 'hidden_size': 6, 'batch_size': 6, 'n_epochs': 574, 'lr': 0.0034764503463942864}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bd8fd3d498b4db49e8413f2c9b3131a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=543` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "967eca96a4b74f1bae367a6e5ca38529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:37:21,739] Trial 7 finished with value: 0.31808499372316873 and parameters: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 1.6 K  | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 65     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "5.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.8 K     Total params\n",
      "0.023     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: 0.31808499372316873, Current params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c932f5e539e04b78a86628b8d4546bee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=782` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41bda672de264d21b32bb73f5a991806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:37:33,151] Trial 8 finished with value: inf and parameters: {'in_len': 24, 'out_len': 1, 'hidden_size': 6, 'batch_size': 6, 'n_epochs': 782, 'lr': 0.000307381805725207}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 960    | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 715    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "5.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.8 K     Total params\n",
      "0.023     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 24, 'out_len': 1, 'hidden_size': 6, 'batch_size': 6, 'n_epochs': 782, 'lr': 0.000307381805725207}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8607a03ed7ba4a4aaaf93932f69a5a15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=798` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bed5e019cb6040d88192da42564ff198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:37:44,632] Trial 9 finished with value: inf and parameters: {'in_len': 14, 'out_len': 11, 'hidden_size': 6, 'batch_size': 3, 'n_epochs': 798, 'lr': 0.000380661558612169}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 104    | train\n",
      "2 | lin2    | Linear  | 72     | train\n",
      "3 | lin3    | Linear  | 171    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "347       Trainable params\n",
      "0         Non-trainable params\n",
      "347       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 14, 'out_len': 11, 'hidden_size': 6, 'batch_size': 3, 'n_epochs': 798, 'lr': 0.000380661558612169}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "868aaf054a304c5c83c26513a7f2ad25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=457` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "302abbd44cc34ef3a1fc98d717eab109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:37:50,939] Trial 10 finished with value: inf and parameters: {'in_len': 12, 'out_len': 19, 'hidden_size': 3, 'batch_size': 7, 'n_epochs': 457, 'lr': 0.0012639450568557211}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 576    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 264    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 12, 'out_len': 19, 'hidden_size': 3, 'batch_size': 7, 'n_epochs': 457, 'lr': 0.0012639450568557211}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7322faccde884ad3bf6ba4993a131aec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=574` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46371b2f183642f4a67713b4ab0dbcd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:37:58,884] Trial 11 finished with value: inf and parameters: {'in_len': 17, 'out_len': 8, 'hidden_size': 5, 'batch_size': 5, 'n_epochs': 574, 'lr': 0.0036953735035260902}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 928    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 132    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "2.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 17, 'out_len': 8, 'hidden_size': 5, 'batch_size': 5, 'n_epochs': 574, 'lr': 0.0036953735035260902}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8795d1f6d275424fbe12061f5f774bf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=525` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44e3d419188745eba2f3061db8d63d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:38:06,290] Trial 12 finished with value: inf and parameters: {'in_len': 28, 'out_len': 4, 'hidden_size': 5, 'batch_size': 5, 'n_epochs': 525, 'lr': 0.007346037454735263}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 288    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 136    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "696       Trainable params\n",
      "0         Non-trainable params\n",
      "696       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 28, 'out_len': 4, 'hidden_size': 5, 'batch_size': 5, 'n_epochs': 525, 'lr': 0.007346037454735263}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cb74932c5ff42139dd4ede3e99f5751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=673` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eeb8e025c074bf9b548ee7e9ce6a787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:38:15,515] Trial 13 finished with value: inf and parameters: {'in_len': 17, 'out_len': 8, 'hidden_size': 4, 'batch_size': 7, 'n_epochs': 673, 'lr': 0.0018594870495151977}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 2.0 K  | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 65     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "6.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.3 K     Total params\n",
      "0.025     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 17, 'out_len': 8, 'hidden_size': 4, 'batch_size': 7, 'n_epochs': 673, 'lr': 0.0018594870495151977}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b1ee61e155f40f1927904888dfb8ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=407` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27a59fa38896475d9f16cc2ee0502265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:38:21,492] Trial 14 finished with value: inf and parameters: {'in_len': 31, 'out_len': 1, 'hidden_size': 6, 'batch_size': 6, 'n_epochs': 407, 'lr': 0.00989352310419074}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 2.4 K  | train\n",
      "2 | lin2    | Linear  | 16.5 K | train\n",
      "3 | lin3    | Linear  | 1.4 K  | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "20.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.4 K    Total params\n",
      "0.081     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 31, 'out_len': 1, 'hidden_size': 6, 'batch_size': 6, 'n_epochs': 407, 'lr': 0.00989352310419074}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b21db94f4ba84d76b19063f175b22a83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=521` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "654b3ba0f5b34c24a6136e7393cc5eda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:38:30,109] Trial 15 finished with value: inf and parameters: {'in_len': 18, 'out_len': 11, 'hidden_size': 7, 'batch_size': 4, 'n_epochs': 521, 'lr': 0.002765771690369684}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 216    | train\n",
      "2 | lin2    | Linear  | 72     | train\n",
      "3 | lin3    | Linear  | 45     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "333       Trainable params\n",
      "0         Non-trainable params\n",
      "333       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 18, 'out_len': 11, 'hidden_size': 7, 'batch_size': 4, 'n_epochs': 521, 'lr': 0.002765771690369684}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70cc439d94964d9781f8471bf40551ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=707` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0315ccccaabc4ff485f158d227dceef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:38:39,905] Trial 16 finished with value: inf and parameters: {'in_len': 26, 'out_len': 5, 'hidden_size': 3, 'batch_size': 7, 'n_epochs': 707, 'lr': 0.0005354763987292665}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 960    | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 910    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "6.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.0 K     Total params\n",
      "0.024     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 26, 'out_len': 5, 'hidden_size': 3, 'batch_size': 7, 'n_epochs': 707, 'lr': 0.0005354763987292665}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e1fa0c6923f46fe8abbbea4f3d467c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=566` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97f93ae45f5649f8adf8bc17041d69dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:38:48,097] Trial 17 finished with value: inf and parameters: {'in_len': 14, 'out_len': 14, 'hidden_size': 6, 'batch_size': 6, 'n_epochs': 566, 'lr': 0.003971498603889935}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 640    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 231    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 14, 'out_len': 14, 'hidden_size': 6, 'batch_size': 6, 'n_epochs': 566, 'lr': 0.003971498603889935}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e28be00334b4298ad76566c54a9258f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=219` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3323a5fe1b3e49c0902a17b0938f6f6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:38:51,153] Trial 18 finished with value: inf and parameters: {'in_len': 19, 'out_len': 7, 'hidden_size': 5, 'batch_size': 5, 'n_epochs': 219, 'lr': 5.290219984235562e-05}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 464    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 51     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "787       Trainable params\n",
      "0         Non-trainable params\n",
      "787       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 19, 'out_len': 7, 'hidden_size': 5, 'batch_size': 5, 'n_epochs': 219, 'lr': 5.290219984235562e-05}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ae28762e5164042ab63d26b0be3eb31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=478` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f999bc191b4b8890c63b3acefd4996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:38:57,753] Trial 19 finished with value: inf and parameters: {'in_len': 28, 'out_len': 3, 'hidden_size': 4, 'batch_size': 4, 'n_epochs': 478, 'lr': 0.001173403809447237}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 832    | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 910    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "5.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.9 K     Total params\n",
      "0.024     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 28, 'out_len': 3, 'hidden_size': 4, 'batch_size': 4, 'n_epochs': 478, 'lr': 0.001173403809447237}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cd8cbbea7064794a8ce4324313d86c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=366` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d12e2852537468f8b11aa509de2a7b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:39:03,121] Trial 20 finished with value: inf and parameters: {'in_len': 12, 'out_len': 14, 'hidden_size': 6, 'batch_size': 7, 'n_epochs': 366, 'lr': 0.0002456359393251178}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 336    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 170    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "778       Trainable params\n",
      "0         Non-trainable params\n",
      "778       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 12, 'out_len': 14, 'hidden_size': 6, 'batch_size': 7, 'n_epochs': 366, 'lr': 0.0002456359393251178}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "347446b05bf3451d8ce8f4505330b43c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=639` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad218e926a8e43e998176c91bc1b6c01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:39:11,834] Trial 21 finished with value: inf and parameters: {'in_len': 20, 'out_len': 10, 'hidden_size': 4, 'batch_size': 4, 'n_epochs': 639, 'lr': 0.00015065589091027914}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 256    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 221    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "749       Trainable params\n",
      "0         Non-trainable params\n",
      "749       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 20, 'out_len': 10, 'hidden_size': 4, 'batch_size': 4, 'n_epochs': 639, 'lr': 0.00015065589091027914}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27925df7c69d481ea6a19708b0d22ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=695` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dc57a50e14d4f08ba64c612944ab18c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:39:21,100] Trial 22 finished with value: inf and parameters: {'in_len': 15, 'out_len': 13, 'hidden_size': 4, 'batch_size': 5, 'n_epochs': 695, 'lr': 8.937451635676957e-05}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 832    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 165    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "2.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 15, 'out_len': 13, 'hidden_size': 4, 'batch_size': 5, 'n_epochs': 695, 'lr': 8.937451635676957e-05}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cf69ef2debd4b61a96b319f0d67792a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=579` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c059bd8b0f934b4689f4a542113bca85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:39:29,085] Trial 23 finished with value: inf and parameters: {'in_len': 25, 'out_len': 5, 'hidden_size': 5, 'batch_size': 6, 'n_epochs': 579, 'lr': 0.0005904294870813014}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 232    | train\n",
      "2 | lin2    | Linear  | 72     | train\n",
      "3 | lin3    | Linear  | 27     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "331       Trainable params\n",
      "0         Non-trainable params\n",
      "331       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 25, 'out_len': 5, 'hidden_size': 5, 'batch_size': 6, 'n_epochs': 579, 'lr': 0.0005904294870813014}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd786cfa2ecb4032aa962095d4639acc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=629` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbc034419a604f8095c9a50278efdb80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:39:37,584] Trial 24 finished with value: inf and parameters: {'in_len': 28, 'out_len': 3, 'hidden_size': 3, 'batch_size': 4, 'n_epochs': 629, 'lr': 0.00010932867337156831}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 544    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 297    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 28, 'out_len': 3, 'hidden_size': 3, 'batch_size': 4, 'n_epochs': 629, 'lr': 0.00010932867337156831}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "864a4bb26c384c40bbfa91f09f50473a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=528` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e136f85ebe7640b5a96578ac642ba3c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:39:44,871] Trial 25 finished with value: inf and parameters: {'in_len': 16, 'out_len': 9, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 528, 'lr': 5.5456138325765785e-05}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 352    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 102    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "726       Trainable params\n",
      "0         Non-trainable params\n",
      "726       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 16, 'out_len': 9, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 528, 'lr': 5.5456138325765785e-05}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cc0407e87524a60a1f012ea5f857c5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=724` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "703f5f6fcaba43cbb4a817f16deba875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:39:54,538] Trial 26 finished with value: inf and parameters: {'in_len': 21, 'out_len': 6, 'hidden_size': 4, 'batch_size': 6, 'n_epochs': 724, 'lr': 0.0001835327334437171}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 992    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 33     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "2.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 21, 'out_len': 6, 'hidden_size': 4, 'batch_size': 6, 'n_epochs': 724, 'lr': 0.0001835327334437171}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3927642e17f74cc3b960ce0258bab242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=655` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "097c5505aecb4ebba92baea310f4b730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:40:03,612] Trial 27 finished with value: inf and parameters: {'in_len': 30, 'out_len': 1, 'hidden_size': 5, 'batch_size': 5, 'n_epochs': 655, 'lr': 0.00040116441662693317}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 768    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 231    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "2.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 30, 'out_len': 1, 'hidden_size': 5, 'batch_size': 5, 'n_epochs': 655, 'lr': 0.00040116441662693317}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28605d8080974ec8a6987fde02130f68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=597` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29d094756cd14faaa3a00cfe88bf80e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:40:11,820] Trial 28 finished with value: inf and parameters: {'in_len': 23, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 597, 'lr': 0.0053764500052075745}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 320    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 153    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "745       Trainable params\n",
      "0         Non-trainable params\n",
      "745       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 23, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 597, 'lr': 0.0053764500052075745}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5a033b777ed4b489b271e0eca3e9d4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=552` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deefc1ffbf2b4ceebbc815d6fa70d099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:40:19,413] Trial 29 finished with value: inf and parameters: {'in_len': 19, 'out_len': 9, 'hidden_size': 4, 'batch_size': 6, 'n_epochs': 552, 'lr': 8.933701285256679e-05}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 192    | train\n",
      "2 | lin2    | Linear  | 72     | train\n",
      "3 | lin3    | Linear  | 45     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "309       Trainable params\n",
      "0         Non-trainable params\n",
      "309       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 19, 'out_len': 9, 'hidden_size': 4, 'batch_size': 6, 'n_epochs': 552, 'lr': 8.933701285256679e-05}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54229048f6f84067889d04bb076b2903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=614` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db95388a899b4a94abb11616eaabc13b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:40:27,760] Trial 30 finished with value: inf and parameters: {'in_len': 23, 'out_len': 5, 'hidden_size': 3, 'batch_size': 3, 'n_epochs': 614, 'lr': 0.0023184644443023338}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 480    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 34     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "786       Trainable params\n",
      "0         Non-trainable params\n",
      "786       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 23, 'out_len': 5, 'hidden_size': 3, 'batch_size': 3, 'n_epochs': 614, 'lr': 0.0023184644443023338}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e9c873d334c472ab8fb7e01686947a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=475` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f605a80315f43e49f9460eed74aa6e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:40:34,176] Trial 31 finished with value: inf and parameters: {'in_len': 29, 'out_len': 2, 'hidden_size': 4, 'batch_size': 6, 'n_epochs': 475, 'lr': 6.514293116907686e-05}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 4.1 K  | train\n",
      "2 | lin2    | Linear  | 16.5 K | train\n",
      "3 | lin3    | Linear  | 129    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "20.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.7 K    Total params\n",
      "0.083     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 29, 'out_len': 2, 'hidden_size': 4, 'batch_size': 6, 'n_epochs': 475, 'lr': 6.514293116907686e-05}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96bee87757e34aa4b764ccb7d4e4e08a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=605` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0cecd512c564e68a90c315b531ae81f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:40:43,601] Trial 32 finished with value: inf and parameters: {'in_len': 31, 'out_len': 1, 'hidden_size': 7, 'batch_size': 5, 'n_epochs': 605, 'lr': 0.00019547444945125728}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 432    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 51     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "755       Trainable params\n",
      "0         Non-trainable params\n",
      "755       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 31, 'out_len': 1, 'hidden_size': 7, 'batch_size': 5, 'n_epochs': 605, 'lr': 0.00019547444945125728}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8721e320c4b44bd29896121f32b94c88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=547` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbbf1848cf0b4bf68e32bceae7f2b8ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:40:53,354] Trial 33 finished with value: inf and parameters: {'in_len': 26, 'out_len': 3, 'hidden_size': 4, 'batch_size': 3, 'n_epochs': 547, 'lr': 7.254357777798809e-05}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 1.5 K  | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 260    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "5.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.9 K     Total params\n",
      "0.024     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 26, 'out_len': 3, 'hidden_size': 4, 'batch_size': 3, 'n_epochs': 547, 'lr': 7.254357777798809e-05}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c76b5219f4da4f66be61cec7bb8453d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=740` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05d9c01ec05743108b1057f411d4d15d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:41:03,877] Trial 34 finished with value: inf and parameters: {'in_len': 22, 'out_len': 4, 'hidden_size': 6, 'batch_size': 6, 'n_epochs': 740, 'lr': 0.0001216438552695186}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 3.2 K  | train\n",
      "2 | lin2    | Linear  | 16.5 K | train\n",
      "3 | lin3    | Linear  | 516    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "20.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.2 K    Total params\n",
      "0.081     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 22, 'out_len': 4, 'hidden_size': 6, 'batch_size': 6, 'n_epochs': 740, 'lr': 0.0001216438552695186}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bfe03c92c164855a99ca6596b63ef36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=664` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c90bbe7bf3942209b0bbe3ffa2c1512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:41:14,211] Trial 35 finished with value: inf and parameters: {'in_len': 24, 'out_len': 4, 'hidden_size': 7, 'batch_size': 7, 'n_epochs': 664, 'lr': 0.0001501084398868491}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 896    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 66     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "2.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 24, 'out_len': 4, 'hidden_size': 7, 'batch_size': 7, 'n_epochs': 664, 'lr': 0.0001501084398868491}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a0d772fa3e948598c3d39346eef264a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=748` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a95cf1942ecc4204bc850999ce37c10f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:41:24,338] Trial 36 finished with value: inf and parameters: {'in_len': 27, 'out_len': 2, 'hidden_size': 5, 'batch_size': 6, 'n_epochs': 748, 'lr': 7.678077571402538e-05}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 112    | train\n",
      "2 | lin2    | Linear  | 72     | train\n",
      "3 | lin3    | Linear  | 108    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "292       Trainable params\n",
      "0         Non-trainable params\n",
      "292       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 27, 'out_len': 2, 'hidden_size': 5, 'batch_size': 6, 'n_epochs': 748, 'lr': 7.678077571402538e-05}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37a780f14a844c8e8a8d0af51be46af2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=501` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6091a422e18545e3b556e7008dd2d643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:41:30,962] Trial 37 finished with value: inf and parameters: {'in_len': 13, 'out_len': 12, 'hidden_size': 3, 'batch_size': 7, 'n_epochs': 501, 'lr': 0.0011128574052500445}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 1.3 K  | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 390    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "5.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.9 K     Total params\n",
      "0.024     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 13, 'out_len': 12, 'hidden_size': 3, 'batch_size': 7, 'n_epochs': 501, 'lr': 0.0011128574052500445}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d592361cb00e4775b05b66008950dbda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=677` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48b63fe99ecb48038f1c8c66cd1610d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:41:40,411] Trial 38 finished with value: inf and parameters: {'in_len': 20, 'out_len': 6, 'hidden_size': 6, 'batch_size': 4, 'n_epochs': 677, 'lr': 0.0007723520678388062}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 400    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 68     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "740       Trainable params\n",
      "0         Non-trainable params\n",
      "740       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 20, 'out_len': 6, 'hidden_size': 6, 'batch_size': 4, 'n_epochs': 677, 'lr': 0.0007723520678388062}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aa159071b794e4e9a009f8dda57eace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=423` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "399b5be135e247958f2674b41825b1cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:41:45,978] Trial 39 finished with value: inf and parameters: {'in_len': 24, 'out_len': 4, 'hidden_size': 4, 'batch_size': 6, 'n_epochs': 423, 'lr': 0.0003063417988876448}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 736    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 165    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "2.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 24, 'out_len': 4, 'hidden_size': 4, 'batch_size': 6, 'n_epochs': 423, 'lr': 0.0003063417988876448}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc951a2a1dde4976aa59aa9621aab614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=594` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc6842eaf2fc418ab5854f9f9e870115",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:41:54,123] Trial 40 finished with value: inf and parameters: {'in_len': 22, 'out_len': 5, 'hidden_size': 5, 'batch_size': 3, 'n_epochs': 594, 'lr': 0.00010208994900394779}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 4.0 K  | train\n",
      "2 | lin2    | Linear  | 16.5 K | train\n",
      "3 | lin3    | Linear  | 258    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "20.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.7 K    Total params\n",
      "0.083     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 22, 'out_len': 5, 'hidden_size': 5, 'batch_size': 3, 'n_epochs': 594, 'lr': 0.00010208994900394779}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d3c3bc2a6fa48f19c2aa89c6b54fcd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=773` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76a1c37adf394871b0354b70fd8d94a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:42:09,673] Trial 41 finished with value: inf and parameters: {'in_len': 30, 'out_len': 2, 'hidden_size': 7, 'batch_size': 3, 'n_epochs': 773, 'lr': 0.0001481388188596119}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 3.8 K  | train\n",
      "2 | lin2    | Linear  | 16.5 K | train\n",
      "3 | lin3    | Linear  | 258    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "20.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.6 K    Total params\n",
      "0.082     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 30, 'out_len': 2, 'hidden_size': 7, 'batch_size': 3, 'n_epochs': 773, 'lr': 0.0001481388188596119}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3914544dc81d4e378e2f40acc72cf046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=636` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5c62b931e3e4d94a3c563247e7d45ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:42:22,567] Trial 42 finished with value: inf and parameters: {'in_len': 29, 'out_len': 2, 'hidden_size': 7, 'batch_size': 3, 'n_epochs': 636, 'lr': 0.00021687803532788934}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 2.0 K  | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 65     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "6.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.3 K     Total params\n",
      "0.025     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 29, 'out_len': 2, 'hidden_size': 7, 'batch_size': 3, 'n_epochs': 636, 'lr': 0.00021687803532788934}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5262bdc8f33941c7a8ced41f73254b8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=799` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "368cda2e2b8840efba4e909936c9fe3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:42:44,525] Trial 43 finished with value: inf and parameters: {'in_len': 31, 'out_len': 1, 'hidden_size': 6, 'batch_size': 3, 'n_epochs': 799, 'lr': 6.53172188619787e-05}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 3.6 K  | train\n",
      "2 | lin2    | Linear  | 16.5 K | train\n",
      "3 | lin3    | Linear  | 387    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "20.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.5 K    Total params\n",
      "0.082     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 31, 'out_len': 1, 'hidden_size': 6, 'batch_size': 3, 'n_epochs': 799, 'lr': 6.53172188619787e-05}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4003e9bcd72d4dc4b7c9b8469c522491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=452` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01ed9a76d93c4441a7e61266ab79d3c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:42:51,838] Trial 44 finished with value: inf and parameters: {'in_len': 27, 'out_len': 3, 'hidden_size': 7, 'batch_size': 5, 'n_epochs': 452, 'lr': 8.557312007899956e-05}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 1.2 K  | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 1.0 K  | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "6.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.4 K     Total params\n",
      "0.025     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 27, 'out_len': 3, 'hidden_size': 7, 'batch_size': 5, 'n_epochs': 452, 'lr': 8.557312007899956e-05}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b358c2291d942669ede76697460130d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=698` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6ec5593178a4c1c8393c73fae8404c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:43:01,621] Trial 45 finished with value: inf and parameters: {'in_len': 17, 'out_len': 16, 'hidden_size': 6, 'batch_size': 4, 'n_epochs': 698, 'lr': 5.087498208123509e-05}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 1.7 K  | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 390    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "6.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.2 K     Total params\n",
      "0.025     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 17, 'out_len': 16, 'hidden_size': 6, 'batch_size': 4, 'n_epochs': 698, 'lr': 5.087498208123509e-05}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d849c02523fc43f2915fa5cc2827d26e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=518` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b41adc1ada36472ea0068efa6e66c30d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:43:08,838] Trial 46 finished with value: inf and parameters: {'in_len': 25, 'out_len': 6, 'hidden_size': 6, 'batch_size': 7, 'n_epochs': 518, 'lr': 0.00011599686112288687}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 992    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 66     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "2.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 25, 'out_len': 6, 'hidden_size': 6, 'batch_size': 7, 'n_epochs': 518, 'lr': 0.00011599686112288687}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a82d37785e34b7d80a7e021dcfe3923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=558` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50839975ed774823a530aa6063848719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:43:18,823] Trial 47 finished with value: inf and parameters: {'in_len': 30, 'out_len': 2, 'hidden_size': 5, 'batch_size': 3, 'n_epochs': 558, 'lr': 0.0015310969892074265}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 2.0 K  | train\n",
      "2 | lin2    | Linear  | 16.5 K | train\n",
      "3 | lin3    | Linear  | 903    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "19.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "19.5 K    Total params\n",
      "0.078     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 30, 'out_len': 2, 'hidden_size': 5, 'batch_size': 3, 'n_epochs': 558, 'lr': 0.0015310969892074265}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "920b9b1dd6114710a4086f82b8217a46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=757` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad44388eb7064ef88287ff9aeb9b73b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:43:30,349] Trial 48 finished with value: 0.34468058651564004 and parameters: {'in_len': 15, 'out_len': 7, 'hidden_size': 7, 'batch_size': 5, 'n_epochs': 757, 'lr': 0.00029587203986698214}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 112    | train\n",
      "2 | lin2    | Linear  | 72     | train\n",
      "3 | lin3    | Linear  | 72     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "256       Trainable params\n",
      "0         Non-trainable params\n",
      "256       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: 0.34468058651564004, Current params: {'in_len': 15, 'out_len': 7, 'hidden_size': 7, 'batch_size': 5, 'n_epochs': 757, 'lr': 0.00029587203986698214}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ab7ea0404744def96130fc1e1ad1c5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=625` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58e01e18fe2c42f48545461baa9f24b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:43:38,681] Trial 49 finished with value: 0.30691858609270606 and parameters: {'in_len': 13, 'out_len': 8, 'hidden_size': 3, 'batch_size': 5, 'n_epochs': 625, 'lr': 0.00027719726790487604}. Best is trial 49 with value: 0.30691858609270606.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: 0.30691858609270606, Current params: {'in_len': 13, 'out_len': 8, 'hidden_size': 3, 'batch_size': 5, 'n_epochs': 625, 'lr': 0.00027719726790487604}\n",
      "Best value: 0.30691858609270606, Best params: {'in_len': 13, 'out_len': 8, 'hidden_size': 3, 'batch_size': 5, 'n_epochs': 625, 'lr': 0.00027719726790487604}\n"
     ]
    }
   ],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NARX(training=True, prepare_data_per_node=True, allow_zero_length_dataloader_with_multiple_devices=False, n_epochs=625, input_chunk_length=13, output_chunk_length=8, batch_size=32, random_state=0, fit_called=False, optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00027719726790487604\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), window_model=SlidingWindow(input_chunk_length=13, output_chunk_length=8), preprocessing=[MinMaxScaler()], pl_trainer_kwargs={}, hidden_size=8)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(model)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# train the model\u001b[39;00m\n\u001b[1;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m---> 14\u001b[0m   series\u001b[38;5;241m=\u001b[39m\u001b[43mtrain_scaled\u001b[49m\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     16\u001b[0m pred_series \u001b[38;5;241m=\u001b[39m eval_model(\n\u001b[1;32m     17\u001b[0m     model,\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mlen\u001b[39m(val_scaled),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m     returned \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPREDICT_VALUES\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     23\u001b[0m )\n\u001b[1;32m     24\u001b[0m pred_series \u001b[38;5;241m=\u001b[39m pred_series[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "model = NARX(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    preprocessing = [MinMaxScaler()],\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1,12)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NARX(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        lr=lr,\n",
    "        n_epochs=n_epochs,\n",
    "        preprocessing = [MinMaxScaler()],\n",
    "        random_state = 0\n",
    "    )\n",
    "    # train the model\n",
    "    model.fit(train)\n",
    "    metrics = model.evaluate(val)\n",
    "\n",
    "    \n",
    "    mape_val = metrics['u2']\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:51:19,848] A new study created in memory with name: no-name-6fd6e466-f99f-47aa-b607-0563cc00477d\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 3.2 K  | train\n",
      "2 | lin2    | Linear  | 16.5 K | train\n",
      "3 | lin3    | Linear  | 516    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "20.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.2 K    Total params\n",
      "0.081     Total estimated model params size (MB)\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae10c06bb4e74c84adbccf7f3b75de8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=655` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca3c93cdf927454485ee1773e02d5acf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-07-24 18:51:30,024] Trial 0 failed with parameters: {'in_len': 24, 'out_len': 4, 'hidden_size': 7, 'batch_size': 5, 'n_epochs': 655, 'lr': 0.002172236929503528} because of the following error: ValueError('Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_57764/802593498.py\", line 27, in objective\n",
      "    metrics = model.evaluate(val)\n",
      "              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/classes/models/torch_generic_model.py\", line 291, in evaluate\n",
      "    \"mape\": mape([i[1] for i in val], predicted_outputs_original),\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/sklearn/metrics/_regression.py\", line 399, in mean_absolute_percentage_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/sklearn/metrics/_regression.py\", line 112, in _check_reg_targets\n",
      "    y_true = check_array(y_true, ensure_2d=False, dtype=dtype)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 1082, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "[W 2024-07-24 18:51:30,027] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# optimize hyperparameters by minimizing the mape on the validation set\u001b[39;00m\n\u001b[1;32m      2\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mprint_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/optuna/study/_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 62\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/optuna/study/_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/optuna/study/_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    246\u001b[0m ):\n\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[33], line 27\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# train the model\u001b[39;00m\n\u001b[1;32m     26\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(train)\n\u001b[0;32m---> 27\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m mape_val \u001b[38;5;241m=\u001b[39m metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mu2\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mape_val \u001b[38;5;28;01mif\u001b[39;00m mape_val \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documentos/Projeto-da-Graduacao/classes/models/torch_generic_model.py:291\u001b[0m, in \u001b[0;36mTorchGenericModel.evaluate\u001b[0;34m(self, val)\u001b[0m\n\u001b[1;32m    287\u001b[0m         predicted_outputs\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m    288\u001b[0m         progress_bar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m--> 291\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmape\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mmape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_outputs_original\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m\"\u001b[39m: mse([i[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m val], predicted_outputs_original),\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m\"\u001b[39m: rmse([i[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m val], predicted_outputs_original),\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msle\u001b[39m\u001b[38;5;124m\"\u001b[39m: sle([i[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m val], predicted_outputs_original),\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mu1\u001b[39m\u001b[38;5;124m\"\u001b[39m: UTheil()\u001b[38;5;241m.\u001b[39mcalculateU1([i[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m val_scaled], predicted_outputs),\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mu2\u001b[39m\u001b[38;5;124m\"\u001b[39m: UTheil()\u001b[38;5;241m.\u001b[39mcalculateU2([i[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m val_scaled], predicted_outputs),\n\u001b[1;32m    297\u001b[0m }\n",
      "File \u001b[0;32m~/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/sklearn/metrics/_regression.py:399\u001b[0m, in \u001b[0;36mmean_absolute_percentage_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m    322\u001b[0m     {\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    331\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    332\u001b[0m ):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Mean absolute percentage error (MAPE) regression loss.\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \n\u001b[1;32m    335\u001b[0m \u001b[38;5;124;03m    Note here that the output is not a percentage in the range [0, 100]\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;124;03m    112589990684262.48\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 399\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    402\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    403\u001b[0m     epsilon \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfinfo(np\u001b[38;5;241m.\u001b[39mfloat64)\u001b[38;5;241m.\u001b[39meps\n",
      "File \u001b[0;32m~/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/sklearn/metrics/_regression.py:112\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype, xp)\u001b[0m\n\u001b[1;32m    109\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred, multioutput, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[1;32m    111\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m--> 112\u001b[0m y_true \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/sklearn/utils/validation.py:1082\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1080\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[1;32m   1081\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[0;32m-> 1082\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1085\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[1;32m   1086\u001b[0m         )\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m   1089\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NARX(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    preprocessing = [MinMaxScaler()],\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando U2 e MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NARX(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        lr=lr,\n",
    "        n_epochs=n_epochs,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_scaled, preds)\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NARX(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4vOQfZh94Fsr",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Takens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 703
    },
    "id": "82zIFoHt4Ihr",
    "outputId": "d1420d33-465f-4000-84fd-6376a30090b1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_narx = []\n",
    "\n",
    "for input_chunk_length in [4*3, 4*6]:\n",
    "    for output_chunk_length in [4, 4*2, 4*3]:\n",
    "       for hidden_size in range(3, 7):\n",
    "           for batch_size in range(3, 7):\n",
    "               for lr in range(2, 5):\n",
    "                   for takens_tau in range(1,4):\n",
    "                        model = NARX(\n",
    "                            input_chunk_length=input_chunk_length,\n",
    "                            output_chunk_length=output_chunk_length,\n",
    "                            hidden_size=2**hidden_size,\n",
    "                            batch_size=2**batch_size,\n",
    "                            n_epochs=200,\n",
    "                            lr=10**(-lr),\n",
    "                            window_model = Takens(tau=takens_tau),\n",
    "                            preprocessing = [MinMaxScaler()],\n",
    "                            random_state = 0,\n",
    "                        )\n",
    "                        try:\n",
    "                            model.fit(train, val)\n",
    "                            metrics = model.evaluate(val)\n",
    "                        except:\n",
    "                            continue\n",
    "                        print({\n",
    "                            'mape': metrics['mape'],\n",
    "                            'sle': metrics['sle'],\n",
    "                            'rmse': metrics['rmse'],\n",
    "                            'mse': metrics['mse'],\n",
    "                            'u1': metrics['u1'],\n",
    "                            'u2': metrics['u2'],\n",
    "                            'lr': 10**(-lr),\n",
    "                            'input_chunk_length': input_chunk_length,\n",
    "                            'output_chunk_length': output_chunk_length,\n",
    "                            'takens_tau': takens_tau,\n",
    "                            'hidden_size': 2**hidden_size,\n",
    "                            'batch_size': 2**batch_size,\n",
    "                        })\n",
    "                        models_narx.append({\n",
    "                            'mape': metrics['mape'],\n",
    "                            'sle': metrics['sle'],\n",
    "                            'rmse': metrics['rmse'],\n",
    "                            'mse': metrics['mse'],\n",
    "                            'u1': metrics['u1'],\n",
    "                            'u2': metrics['u2'],\n",
    "                            'lr': 10**(-lr),\n",
    "                            'input_chunk_length': input_chunk_length,\n",
    "                            'output_chunk_length': output_chunk_length,\n",
    "                            'takens_tau': takens_tau,\n",
    "                            'hidden_size': 2**hidden_size,\n",
    "                            'batch_size': 2**batch_size,\n",
    "                        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 416    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 132    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "1.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MAPE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (6) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0e4bfbbabf74e838887cc510ed8cbbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56aa807401e54d56bfb8b0b3e7cd0b15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 208    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 204    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "684       Trainable params\n",
      "0         Non-trainable params\n",
      "684       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.2324093377939715, 'mse': 0.98575220185428, 'rmse': 0.9925120025865224, 'sle': 1.7191925110238624, 'u1': 1.1503641848146937, 'u2': 1.560531732321116}\n",
      "Model:  NARX(training=True, prepare_data_per_node=True, allow_zero_length_dataloader_with_multiple_devices=False, n_epochs=200, input_chunk_length=12, output_chunk_length=4, batch_size=8, random_state=0, fit_called=True, optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), window_model=Takens(input_chunk_length=12, output_chunk_length=4, tau=1), preprocessing=[MinMaxScaler()], pl_trainer_kwargs={}, hidden_size=32, last_index=2023-01-23 00:00:00, data_freq=<Week: weekday=0>, last_data=[5.92149, 6.03723, 6.14058, 6.19233, 6.07111, 5.86276, 5.70988, 5.73702, 5.71108, 5.66975, 5.61122, 5.49708])\n",
      "\n",
      "\n",
      "Best SLE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (5) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "493434134ee14cafa07ee4059aa3a50a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "247daf608550462aafe60c1bcad3328d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 104    | train\n",
      "2 | lin2    | Linear  | 72     | train\n",
      "3 | lin3    | Linear  | 108    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "284       Trainable params\n",
      "0         Non-trainable params\n",
      "284       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.37763866279917124, 'mse': 2.3471365012348033, 'rmse': 1.5174640101496377, 'sle': 1.2470942255157498, 'u1': 1.372268142025938, 'u2': 5.508058361701673}\n",
      "Model:  NARX(training=True, prepare_data_per_node=True, allow_zero_length_dataloader_with_multiple_devices=False, n_epochs=200, input_chunk_length=12, output_chunk_length=12, batch_size=8, random_state=0, fit_called=True, optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), window_model=Takens(input_chunk_length=12, output_chunk_length=12, tau=1), preprocessing=[MinMaxScaler()], pl_trainer_kwargs={}, hidden_size=16, last_index=2023-01-23 00:00:00, data_freq=<Week: weekday=0>, last_data=[5.92149, 6.03723, 6.14058, 6.19233, 6.07111, 5.86276, 5.70988, 5.73702, 5.71108, 5.66975, 5.61122, 5.49708])\n",
      "\n",
      "\n",
      "Best U1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (5) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22d93b197d0a45798d616d7230507f4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85fd952021874a638d1128579f457825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 208    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 68     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "548       Trainable params\n",
      "0         Non-trainable params\n",
      "548       Total params\n",
      "0.002     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.3073188597916276, 'mse': 1.5431212924979099, 'rmse': 1.2360263349914549, 'sle': 0.8686603141560766, 'u1': 0.5887653324799269, 'u2': 1.6114552996931215}\n",
      "Model:  NARX(training=True, prepare_data_per_node=True, allow_zero_length_dataloader_with_multiple_devices=False, n_epochs=200, input_chunk_length=12, output_chunk_length=12, batch_size=8, random_state=0, fit_called=True, optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), window_model=Takens(input_chunk_length=12, output_chunk_length=12, tau=1), preprocessing=[MinMaxScaler()], pl_trainer_kwargs={}, hidden_size=8, last_index=2023-01-23 00:00:00, data_freq=<Week: weekday=0>, last_data=[5.92149, 6.03723, 6.14058, 6.19233, 6.07111, 5.86276, 5.70988, 5.73702, 5.71108, 5.66975, 5.61122, 5.49708])\n",
      "\n",
      "\n",
      "Best U2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa461179391548ef947512e7de727c5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0caf3024cacc4d2dbbe6d4024ab474a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.30512161920573744, 'mse': 1.5416499548548561, 'rmse': 1.2380502831750853, 'sle': 2.605050987124422, 'u1': 1.0701756670534535, 'u2': 3.307390076302709}\n",
      "Model:  NARX(training=True, prepare_data_per_node=True, allow_zero_length_dataloader_with_multiple_devices=False, n_epochs=200, input_chunk_length=12, output_chunk_length=4, batch_size=64, random_state=0, fit_called=True, optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.0001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), window_model=Takens(input_chunk_length=12, output_chunk_length=4, tau=1), preprocessing=[MinMaxScaler()], pl_trainer_kwargs={}, hidden_size=16, last_index=2023-01-23 00:00:00, data_freq=<Week: weekday=0>, last_data=[5.92149, 6.03723, 6.14058, 6.19233, 6.07111, 5.86276, 5.70988, 5.73702, 5.71108, 5.66975, 5.61122, 5.49708])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_narx in [\n",
    "                            {\n",
    "                                'name': 'MAPE',\n",
    "                                'input_chunk_length': min(models_narx, key=lambda d: d['mape'])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_narx, key=lambda d: d['mape'])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_narx, key=lambda d: d['mape'])['hidden_size'],\n",
    "                                'batch_size': min(models_narx, key=lambda d: d['mape'])['batch_size'],\n",
    "                                'lr': min(models_narx, key=lambda d: d['mape'])['lr'],\n",
    "                                'takens_tau': min(models_narx, key=lambda d: d['mape'])['takens_tau'],\n",
    "                            },\n",
    "                            {\n",
    "                                'name': 'SLE',\n",
    "                                'input_chunk_length': min(models_narx, key=lambda d: d['sle'])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_narx, key=lambda d: d['sle'])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_narx, key=lambda d: d['sle'])['hidden_size'],\n",
    "                                'batch_size': min(models_narx, key=lambda d: d['sle'])['batch_size'],\n",
    "                                'lr': min(models_narx, key=lambda d: d['sle'])['lr'],\n",
    "                                'takens_tau': min(models_narx, key=lambda d: d['sle'])['takens_tau'],\n",
    "                            },\n",
    "                            {\n",
    "                                'name': 'U1',\n",
    "                                'input_chunk_length': min(models_narx, key=lambda d: d['u1'])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_narx, key=lambda d: d['u1'])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_narx, key=lambda d: d['u1'])['hidden_size'],\n",
    "                                'batch_size': min(models_narx, key=lambda d: d['u1'])['batch_size'],\n",
    "                                'lr': min(models_narx, key=lambda d: d['u1'])['lr'],\n",
    "                                'takens_tau': min(models_narx, key=lambda d: d['u1'])['takens_tau'],\n",
    "                            },\n",
    "                            {\n",
    "                                'name': 'U2',\n",
    "                                'input_chunk_length': min(models_narx, key=lambda d: d['u2'])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_narx, key=lambda d: d['u2'])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_narx, key=lambda d: d['u2'])['hidden_size'],\n",
    "                                'batch_size': min(models_narx, key=lambda d: d['u2'])['batch_size'],\n",
    "                                'lr': min(models_narx, key=lambda d: d['u2'])['lr'],\n",
    "                                'takens_tau': min(models_narx, key=lambda d: d['u2'])['takens_tau'],\n",
    "                            },\n",
    "                        ]:\n",
    "    print('Best', best_model_narx['name'])\n",
    "    model = NARX(\n",
    "        input_chunk_length=best_model_narx['input_chunk_length'],\n",
    "        output_chunk_length=best_model_narx['output_chunk_length'],\n",
    "        hidden_size=best_model_narx['hidden_size'],\n",
    "        batch_size=best_model_narx['batch_size'],\n",
    "        lr=best_model_narx['lr'],\n",
    "        window_model = Takens(tau=best_model_narx['takens_tau']),\n",
    "        n_epochs=200,\n",
    "        preprocessing = [MinMaxScaler()],\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit(train)\n",
    "    print(model.evaluate(val))\n",
    "    print('Model: ', model)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, 3)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NARX(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        lr=lr,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        n_epochs=n_epochs,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NARX(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, 3)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NARX(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        lr=lr,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        n_epochs=n_epochs,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NARX(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando U2 e MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, 3)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NARX(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        lr=lr,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        n_epochs=n_epochs,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_scaled, preds)\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NARX(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Brasil (detrend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Janela deslizante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "id": "FQ705nUH9WXK",
    "outputId": "e2eb8927-8d66-4d9f-8946-47656d9956c8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_narx = []\n",
    "\n",
    "for input_chunk_length in [4*3, 4*6]:\n",
    "    for output_chunk_length in [4, 4*2, 4*3]:\n",
    "       for hidden_size in range(3, 7):\n",
    "           for batch_size in range(3, 7):\n",
    "               for lr in range(2, 5):\n",
    "                    model = NARX(\n",
    "                        input_chunk_length=input_chunk_length,\n",
    "                        output_chunk_length=output_chunk_length,\n",
    "                        hidden_size=2**hidden_size,\n",
    "                        batch_size=2**batch_size,\n",
    "                        n_epochs=200,\n",
    "                        lr=10**(-lr),\n",
    "                        preprocessing = [Detrend(), MinMaxScaler()],\n",
    "                        random_state = 0,\n",
    "                    )\n",
    "                    model.fit(train, val)\n",
    "                    metrics = model.evaluate(val)\n",
    "                    print({\n",
    "                        'mape': metrics['mape'],\n",
    "                        'sle': metrics['sle'],\n",
    "                        'rmse': metrics['rmse'],\n",
    "                        'mse': metrics['mse'],\n",
    "                        'u1': metrics['u1'],\n",
    "                        'u2': metrics['u2'],\n",
    "                        'lr': 10**(-lr),\n",
    "                        'input_chunk_length': input_chunk_length,\n",
    "                        'output_chunk_length': output_chunk_length,\n",
    "                        'hidden_size': 2**hidden_size,\n",
    "                        'batch_size': 2**batch_size,\n",
    "                    })\n",
    "                    models_narx.append({\n",
    "                        'mape': metrics['mape'],\n",
    "                        'sle': metrics['sle'],\n",
    "                        'rmse': metrics['rmse'],\n",
    "                        'mse': metrics['mse'],\n",
    "                        'u1': metrics['u1'],\n",
    "                        'u2': metrics['u2'],\n",
    "                        'lr': 10**(-lr),\n",
    "                        'input_chunk_length': input_chunk_length,\n",
    "                        'output_chunk_length': output_chunk_length,\n",
    "                        'hidden_size': 2**hidden_size,\n",
    "                        'batch_size': 2**batch_size,\n",
    "                    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 832    | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 520    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "5.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.5 K     Total params\n",
      "0.022     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MAPE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee382bfcee314da8899da44a6fd89075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a941b8992d646419a5a2de36df12804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 104    | train\n",
      "2 | lin2    | Linear  | 72     | train\n",
      "3 | lin3    | Linear  | 72     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "248       Trainable params\n",
      "0         Non-trainable params\n",
      "248       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.030046106554488323, 'mse': 0.02064387638115314, 'rmse': 0.12133545062062545, 'sle': 0.010596414904083253, 'u1': 0.42126112888452394, 'u2': 1.8932321407946269}\n",
      "Model:  NARX(training=True, prepare_data_per_node=True, allow_zero_length_dataloader_with_multiple_devices=False, n_epochs=200, input_chunk_length=12, output_chunk_length=8, batch_size=8, random_state=0, fit_called=True, optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), window_model=SlidingWindow(input_chunk_length=12, output_chunk_length=8), preprocessing=[<classes.models.preprocessing.detrend.Detrend object at 0x7fed836bcce0>, MinMaxScaler()], pl_trainer_kwargs={}, hidden_size=64, last_index=2023-01-23 00:00:00, data_freq=<Week: weekday=0>, last_data=[5.92149, 6.03723, 6.14058, 6.19233, 6.07111, 5.86276, 5.70988, 5.73702, 5.71108, 5.66975, 5.61122, 5.49708])\n",
      "\n",
      "\n",
      "Best SLE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0136a29a47a4f6bb253bc470dbabf8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0a6c8f207d40dbb7f24e062442b10d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 104    | train\n",
      "2 | lin2    | Linear  | 72     | train\n",
      "3 | lin3    | Linear  | 72     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "248       Trainable params\n",
      "0         Non-trainable params\n",
      "248       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.019862035085207282, 'mse': 0.010666349487247642, 'rmse': 0.08028217995306952, 'sle': 0.005393332636704602, 'u1': 0.27548803042912434, 'u2': 1.260955661371924}\n",
      "Model:  NARX(training=True, prepare_data_per_node=True, allow_zero_length_dataloader_with_multiple_devices=False, n_epochs=200, input_chunk_length=12, output_chunk_length=8, batch_size=8, random_state=0, fit_called=True, optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), window_model=SlidingWindow(input_chunk_length=12, output_chunk_length=8), preprocessing=[<classes.models.preprocessing.detrend.Detrend object at 0x7fed32f99340>, MinMaxScaler()], pl_trainer_kwargs={}, hidden_size=8, last_index=2023-01-23 00:00:00, data_freq=<Week: weekday=0>, last_data=[5.92149, 6.03723, 6.14058, 6.19233, 6.07111, 5.86276, 5.70988, 5.73702, 5.71108, 5.66975, 5.61122, 5.49708])\n",
      "\n",
      "\n",
      "Best U1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaa3ec76fa0547c9aa7e8894cef015cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cdd3e10e2284de59420f49ef56f0f66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 832    | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 520    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "5.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.5 K     Total params\n",
      "0.022     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.019862035085207282, 'mse': 0.010666349487247642, 'rmse': 0.08028217995306952, 'sle': 0.005393332636704602, 'u1': 0.27548803042912434, 'u2': 1.260955661371924}\n",
      "Model:  NARX(training=True, prepare_data_per_node=True, allow_zero_length_dataloader_with_multiple_devices=False, n_epochs=200, input_chunk_length=12, output_chunk_length=8, batch_size=8, random_state=0, fit_called=True, optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), window_model=SlidingWindow(input_chunk_length=12, output_chunk_length=8), preprocessing=[<classes.models.preprocessing.detrend.Detrend object at 0x7fed3301c050>, MinMaxScaler()], pl_trainer_kwargs={}, hidden_size=8, last_index=2023-01-23 00:00:00, data_freq=<Week: weekday=0>, last_data=[5.92149, 6.03723, 6.14058, 6.19233, 6.07111, 5.86276, 5.70988, 5.73702, 5.71108, 5.66975, 5.61122, 5.49708])\n",
      "\n",
      "\n",
      "Best U2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "130a31e16c784c328ed7a21a53ea1b6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8087ade0745d42fb8b06648306c7a391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.018569588787902516, 'mse': 0.011632023480552936, 'rmse': 0.07492443928058967, 'sle': 0.0059259569840861715, 'u1': 0.29005496706087625, 'u2': 1.0335938447152981}\n",
      "Model:  NARX(training=True, prepare_data_per_node=True, allow_zero_length_dataloader_with_multiple_devices=False, n_epochs=200, input_chunk_length=12, output_chunk_length=8, batch_size=8, random_state=0, fit_called=True, optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), window_model=SlidingWindow(input_chunk_length=12, output_chunk_length=8), preprocessing=[<classes.models.preprocessing.detrend.Detrend object at 0x7fed32d4c050>, MinMaxScaler()], pl_trainer_kwargs={}, hidden_size=64, last_index=2023-01-23 00:00:00, data_freq=<Week: weekday=0>, last_data=[5.92149, 6.03723, 6.14058, 6.19233, 6.07111, 5.86276, 5.70988, 5.73702, 5.71108, 5.66975, 5.61122, 5.49708])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_narx in [\n",
    "                            {\n",
    "                                'name': 'MAPE',\n",
    "                                'input_chunk_length': min(models_narx, key=lambda d: d['mape'])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_narx, key=lambda d: d['mape'])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_narx, key=lambda d: d['mape'])['hidden_size'],\n",
    "                                'batch_size': min(models_narx, key=lambda d: d['mape'])['batch_size'],\n",
    "                                'lr': min(models_narx, key=lambda d: d['mape'])['lr'],\n",
    "                            },\n",
    "                            {\n",
    "                                'name': 'SLE',\n",
    "                                'input_chunk_length': min(models_narx, key=lambda d: d['sle'])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_narx, key=lambda d: d['sle'])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_narx, key=lambda d: d['sle'])['hidden_size'],\n",
    "                                'batch_size': min(models_narx, key=lambda d: d['sle'])['batch_size'],\n",
    "                                'lr': min(models_narx, key=lambda d: d['sle'])['lr'],\n",
    "                            },\n",
    "                            {\n",
    "                                'name': 'U1',\n",
    "                                'input_chunk_length': min(models_narx, key=lambda d: d['u1'])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_narx, key=lambda d: d['u1'])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_narx, key=lambda d: d['u1'])['hidden_size'],\n",
    "                                'batch_size': min(models_narx, key=lambda d: d['u1'])['batch_size'],\n",
    "                                'lr': min(models_narx, key=lambda d: d['u1'])['lr'],\n",
    "                            },\n",
    "                            {\n",
    "                                'name': 'U2',\n",
    "                                'input_chunk_length': min(models_narx, key=lambda d: d['u2'])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_narx, key=lambda d: d['u2'])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_narx, key=lambda d: d['u2'])['hidden_size'],\n",
    "                                'batch_size': min(models_narx, key=lambda d: d['u2'])['batch_size'],\n",
    "                                'lr': min(models_narx, key=lambda d: d['u2'])['lr'],\n",
    "                            },\n",
    "                        ]:\n",
    "    print('Best', best_model_narx['name'])\n",
    "    model = NARX(\n",
    "        input_chunk_length=best_model_narx['input_chunk_length'],\n",
    "        output_chunk_length=best_model_narx['output_chunk_length'],\n",
    "        hidden_size=best_model_narx['hidden_size'],\n",
    "        batch_size=best_model_narx['batch_size'],\n",
    "        lr=best_model_narx['lr'],\n",
    "        n_epochs=200,\n",
    "        preprocessing = [Detrend(), MinMaxScaler()],\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit(train)\n",
    "    print(model.evaluate(val))\n",
    "    print('Model: ', model)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NARX(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        lr=lr,\n",
    "        n_epochs=n_epochs,\n",
    "        preprocessing = [MinMaxScaler()],\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(train)\n",
    "        metrics = model.evaluate(val)\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "    \n",
    "    mape_val = metrics['mape']\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:36:19,020] A new study created in memory with name: no-name-63bc1527-5b2b-41ad-802c-f0a768254865\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 1.9 K  | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 260    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "6.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.3 K     Total params\n",
      "0.025     Total estimated model params size (MB)\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a54ae43d3c34fc5afb9868d2305835d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=574` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11e28c24af774e9790ac48f4d3d9340e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:36:27,069] Trial 0 finished with value: inf and parameters: {'in_len': 29, 'out_len': 4, 'hidden_size': 6, 'batch_size': 6, 'n_epochs': 574, 'lr': 0.0034764503463942864}. Best is trial 0 with value: inf.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 352    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 187    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "811       Trainable params\n",
      "0         Non-trainable params\n",
      "811       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 29, 'out_len': 4, 'hidden_size': 6, 'batch_size': 6, 'n_epochs': 574, 'lr': 0.0034764503463942864}\n",
      "Best value: inf, Best params: {'in_len': 29, 'out_len': 4, 'hidden_size': 6, 'batch_size': 6, 'n_epochs': 574, 'lr': 0.0034764503463942864}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "498556d63a2d45d3a8a54eb78723dfb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=641` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f6de852d65d40f38e6d8be7b86a7f8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:36:35,602] Trial 1 finished with value: inf and parameters: {'in_len': 21, 'out_len': 11, 'hidden_size': 4, 'batch_size': 3, 'n_epochs': 641, 'lr': 9.460397107030346e-05}. Best is trial 0 with value: inf.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 384    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 68     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "724       Trainable params\n",
      "0         Non-trainable params\n",
      "724       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 21, 'out_len': 11, 'hidden_size': 4, 'batch_size': 3, 'n_epochs': 641, 'lr': 9.460397107030346e-05}\n",
      "Best value: inf, Best params: {'in_len': 29, 'out_len': 4, 'hidden_size': 6, 'batch_size': 6, 'n_epochs': 574, 'lr': 0.0034764503463942864}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b141fbffa1d74e389588b5aeec62b234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=609` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fef9c16c94074370a59aded48d99305b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:36:43,544] Trial 2 finished with value: inf and parameters: {'in_len': 23, 'out_len': 4, 'hidden_size': 4, 'batch_size': 6, 'n_epochs': 609, 'lr': 6.835708785703428e-05}. Best is trial 0 with value: inf.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 4.0 K  | train\n",
      "2 | lin2    | Linear  | 16.5 K | train\n",
      "3 | lin3    | Linear  | 258    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "20.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.7 K    Total params\n",
      "0.083     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 23, 'out_len': 4, 'hidden_size': 4, 'batch_size': 6, 'n_epochs': 609, 'lr': 6.835708785703428e-05}\n",
      "Best value: inf, Best params: {'in_len': 29, 'out_len': 4, 'hidden_size': 6, 'batch_size': 6, 'n_epochs': 574, 'lr': 0.0034764503463942864}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e297b89879d94c1d8bcf8798dd683778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=764` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1fe915c0e6f4a10b2b5fcdefec17455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:36:58,945] Trial 3 finished with value: inf and parameters: {'in_len': 30, 'out_len': 2, 'hidden_size': 7, 'batch_size': 3, 'n_epochs': 764, 'lr': 0.0001916267418004316}. Best is trial 0 with value: inf.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 30, 'out_len': 2, 'hidden_size': 7, 'batch_size': 3, 'n_epochs': 764, 'lr': 0.0001916267418004316}\n",
      "Best value: inf, Best params: {'in_len': 29, 'out_len': 4, 'hidden_size': 6, 'batch_size': 6, 'n_epochs': 574, 'lr': 0.0034764503463942864}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 1.5 K  | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 260    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "5.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.9 K     Total params\n",
      "0.024     Total estimated model params size (MB)\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cacec4199d04952b4e57d5ae048360d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=425` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "568ff7c3495c4409af760b23f99710a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:37:05,198] Trial 4 finished with value: inf and parameters: {'in_len': 22, 'out_len': 4, 'hidden_size': 6, 'batch_size': 3, 'n_epochs': 425, 'lr': 0.0008187405545471868}. Best is trial 0 with value: inf.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 3.5 K  | train\n",
      "2 | lin2    | Linear  | 16.5 K | train\n",
      "3 | lin3    | Linear  | 258    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "20.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.2 K    Total params\n",
      "0.081     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 22, 'out_len': 4, 'hidden_size': 6, 'batch_size': 3, 'n_epochs': 425, 'lr': 0.0008187405545471868}\n",
      "Best value: inf, Best params: {'in_len': 29, 'out_len': 4, 'hidden_size': 6, 'batch_size': 6, 'n_epochs': 574, 'lr': 0.0034764503463942864}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "828c87e229504e839f257915b1911efe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=281` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf33aeb0b1ff4a8094a1196dcd4ebeff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:37:09,715] Trial 5 finished with value: inf and parameters: {'in_len': 26, 'out_len': 2, 'hidden_size': 7, 'batch_size': 7, 'n_epochs': 281, 'lr': 0.00012799323743219602}. Best is trial 0 with value: inf.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 704    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 198    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "2.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 26, 'out_len': 2, 'hidden_size': 7, 'batch_size': 7, 'n_epochs': 281, 'lr': 0.00012799323743219602}\n",
      "Best value: inf, Best params: {'in_len': 29, 'out_len': 4, 'hidden_size': 6, 'batch_size': 6, 'n_epochs': 574, 'lr': 0.0034764503463942864}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eaed63937444836a19a753c9f80dc2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=335` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61211231868243f1b499a7cdd3ae97c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:37:14,387] Trial 6 finished with value: inf and parameters: {'in_len': 21, 'out_len': 6, 'hidden_size': 5, 'batch_size': 6, 'n_epochs': 335, 'lr': 9.271044255884936e-05}. Best is trial 0 with value: inf.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 416    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 231    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "1.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.7 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 21, 'out_len': 6, 'hidden_size': 5, 'batch_size': 6, 'n_epochs': 335, 'lr': 9.271044255884936e-05}\n",
      "Best value: inf, Best params: {'in_len': 29, 'out_len': 4, 'hidden_size': 6, 'batch_size': 6, 'n_epochs': 574, 'lr': 0.0034764503463942864}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bd8fd3d498b4db49e8413f2c9b3131a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=543` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "967eca96a4b74f1bae367a6e5ca38529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:37:21,739] Trial 7 finished with value: 0.31808499372316873 and parameters: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 1.6 K  | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 65     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "5.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.8 K     Total params\n",
      "0.023     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: 0.31808499372316873, Current params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c932f5e539e04b78a86628b8d4546bee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=782` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41bda672de264d21b32bb73f5a991806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:37:33,151] Trial 8 finished with value: inf and parameters: {'in_len': 24, 'out_len': 1, 'hidden_size': 6, 'batch_size': 6, 'n_epochs': 782, 'lr': 0.000307381805725207}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 960    | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 715    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "5.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.8 K     Total params\n",
      "0.023     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 24, 'out_len': 1, 'hidden_size': 6, 'batch_size': 6, 'n_epochs': 782, 'lr': 0.000307381805725207}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8607a03ed7ba4a4aaaf93932f69a5a15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=798` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bed5e019cb6040d88192da42564ff198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:37:44,632] Trial 9 finished with value: inf and parameters: {'in_len': 14, 'out_len': 11, 'hidden_size': 6, 'batch_size': 3, 'n_epochs': 798, 'lr': 0.000380661558612169}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 104    | train\n",
      "2 | lin2    | Linear  | 72     | train\n",
      "3 | lin3    | Linear  | 171    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "347       Trainable params\n",
      "0         Non-trainable params\n",
      "347       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 14, 'out_len': 11, 'hidden_size': 6, 'batch_size': 3, 'n_epochs': 798, 'lr': 0.000380661558612169}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "868aaf054a304c5c83c26513a7f2ad25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=457` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "302abbd44cc34ef3a1fc98d717eab109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:37:50,939] Trial 10 finished with value: inf and parameters: {'in_len': 12, 'out_len': 19, 'hidden_size': 3, 'batch_size': 7, 'n_epochs': 457, 'lr': 0.0012639450568557211}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 576    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 264    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 12, 'out_len': 19, 'hidden_size': 3, 'batch_size': 7, 'n_epochs': 457, 'lr': 0.0012639450568557211}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7322faccde884ad3bf6ba4993a131aec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=574` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46371b2f183642f4a67713b4ab0dbcd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:37:58,884] Trial 11 finished with value: inf and parameters: {'in_len': 17, 'out_len': 8, 'hidden_size': 5, 'batch_size': 5, 'n_epochs': 574, 'lr': 0.0036953735035260902}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 928    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 132    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "2.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 17, 'out_len': 8, 'hidden_size': 5, 'batch_size': 5, 'n_epochs': 574, 'lr': 0.0036953735035260902}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8795d1f6d275424fbe12061f5f774bf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=525` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44e3d419188745eba2f3061db8d63d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:38:06,290] Trial 12 finished with value: inf and parameters: {'in_len': 28, 'out_len': 4, 'hidden_size': 5, 'batch_size': 5, 'n_epochs': 525, 'lr': 0.007346037454735263}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 288    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 136    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "696       Trainable params\n",
      "0         Non-trainable params\n",
      "696       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 28, 'out_len': 4, 'hidden_size': 5, 'batch_size': 5, 'n_epochs': 525, 'lr': 0.007346037454735263}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cb74932c5ff42139dd4ede3e99f5751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=673` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eeb8e025c074bf9b548ee7e9ce6a787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:38:15,515] Trial 13 finished with value: inf and parameters: {'in_len': 17, 'out_len': 8, 'hidden_size': 4, 'batch_size': 7, 'n_epochs': 673, 'lr': 0.0018594870495151977}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 2.0 K  | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 65     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "6.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.3 K     Total params\n",
      "0.025     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 17, 'out_len': 8, 'hidden_size': 4, 'batch_size': 7, 'n_epochs': 673, 'lr': 0.0018594870495151977}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b1ee61e155f40f1927904888dfb8ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=407` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27a59fa38896475d9f16cc2ee0502265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:38:21,492] Trial 14 finished with value: inf and parameters: {'in_len': 31, 'out_len': 1, 'hidden_size': 6, 'batch_size': 6, 'n_epochs': 407, 'lr': 0.00989352310419074}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 2.4 K  | train\n",
      "2 | lin2    | Linear  | 16.5 K | train\n",
      "3 | lin3    | Linear  | 1.4 K  | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "20.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.4 K    Total params\n",
      "0.081     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 31, 'out_len': 1, 'hidden_size': 6, 'batch_size': 6, 'n_epochs': 407, 'lr': 0.00989352310419074}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b21db94f4ba84d76b19063f175b22a83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=521` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "654b3ba0f5b34c24a6136e7393cc5eda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:38:30,109] Trial 15 finished with value: inf and parameters: {'in_len': 18, 'out_len': 11, 'hidden_size': 7, 'batch_size': 4, 'n_epochs': 521, 'lr': 0.002765771690369684}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 216    | train\n",
      "2 | lin2    | Linear  | 72     | train\n",
      "3 | lin3    | Linear  | 45     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "333       Trainable params\n",
      "0         Non-trainable params\n",
      "333       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 18, 'out_len': 11, 'hidden_size': 7, 'batch_size': 4, 'n_epochs': 521, 'lr': 0.002765771690369684}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70cc439d94964d9781f8471bf40551ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=707` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0315ccccaabc4ff485f158d227dceef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:38:39,905] Trial 16 finished with value: inf and parameters: {'in_len': 26, 'out_len': 5, 'hidden_size': 3, 'batch_size': 7, 'n_epochs': 707, 'lr': 0.0005354763987292665}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 960    | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 910    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "6.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.0 K     Total params\n",
      "0.024     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 26, 'out_len': 5, 'hidden_size': 3, 'batch_size': 7, 'n_epochs': 707, 'lr': 0.0005354763987292665}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e1fa0c6923f46fe8abbbea4f3d467c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=566` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97f93ae45f5649f8adf8bc17041d69dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:38:48,097] Trial 17 finished with value: inf and parameters: {'in_len': 14, 'out_len': 14, 'hidden_size': 6, 'batch_size': 6, 'n_epochs': 566, 'lr': 0.003971498603889935}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 640    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 231    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 14, 'out_len': 14, 'hidden_size': 6, 'batch_size': 6, 'n_epochs': 566, 'lr': 0.003971498603889935}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e28be00334b4298ad76566c54a9258f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=219` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3323a5fe1b3e49c0902a17b0938f6f6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:38:51,153] Trial 18 finished with value: inf and parameters: {'in_len': 19, 'out_len': 7, 'hidden_size': 5, 'batch_size': 5, 'n_epochs': 219, 'lr': 5.290219984235562e-05}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 464    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 51     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "787       Trainable params\n",
      "0         Non-trainable params\n",
      "787       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 19, 'out_len': 7, 'hidden_size': 5, 'batch_size': 5, 'n_epochs': 219, 'lr': 5.290219984235562e-05}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ae28762e5164042ab63d26b0be3eb31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=478` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f999bc191b4b8890c63b3acefd4996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:38:57,753] Trial 19 finished with value: inf and parameters: {'in_len': 28, 'out_len': 3, 'hidden_size': 4, 'batch_size': 4, 'n_epochs': 478, 'lr': 0.001173403809447237}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 832    | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 910    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "5.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.9 K     Total params\n",
      "0.024     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 28, 'out_len': 3, 'hidden_size': 4, 'batch_size': 4, 'n_epochs': 478, 'lr': 0.001173403809447237}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cd8cbbea7064794a8ce4324313d86c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=366` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d12e2852537468f8b11aa509de2a7b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:39:03,121] Trial 20 finished with value: inf and parameters: {'in_len': 12, 'out_len': 14, 'hidden_size': 6, 'batch_size': 7, 'n_epochs': 366, 'lr': 0.0002456359393251178}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 336    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 170    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "778       Trainable params\n",
      "0         Non-trainable params\n",
      "778       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 12, 'out_len': 14, 'hidden_size': 6, 'batch_size': 7, 'n_epochs': 366, 'lr': 0.0002456359393251178}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "347446b05bf3451d8ce8f4505330b43c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=639` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad218e926a8e43e998176c91bc1b6c01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:39:11,834] Trial 21 finished with value: inf and parameters: {'in_len': 20, 'out_len': 10, 'hidden_size': 4, 'batch_size': 4, 'n_epochs': 639, 'lr': 0.00015065589091027914}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 256    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 221    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "749       Trainable params\n",
      "0         Non-trainable params\n",
      "749       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 20, 'out_len': 10, 'hidden_size': 4, 'batch_size': 4, 'n_epochs': 639, 'lr': 0.00015065589091027914}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27925df7c69d481ea6a19708b0d22ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=695` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dc57a50e14d4f08ba64c612944ab18c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:39:21,100] Trial 22 finished with value: inf and parameters: {'in_len': 15, 'out_len': 13, 'hidden_size': 4, 'batch_size': 5, 'n_epochs': 695, 'lr': 8.937451635676957e-05}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 832    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 165    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "2.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 15, 'out_len': 13, 'hidden_size': 4, 'batch_size': 5, 'n_epochs': 695, 'lr': 8.937451635676957e-05}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cf69ef2debd4b61a96b319f0d67792a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=579` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c059bd8b0f934b4689f4a542113bca85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:39:29,085] Trial 23 finished with value: inf and parameters: {'in_len': 25, 'out_len': 5, 'hidden_size': 5, 'batch_size': 6, 'n_epochs': 579, 'lr': 0.0005904294870813014}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 232    | train\n",
      "2 | lin2    | Linear  | 72     | train\n",
      "3 | lin3    | Linear  | 27     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "331       Trainable params\n",
      "0         Non-trainable params\n",
      "331       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 25, 'out_len': 5, 'hidden_size': 5, 'batch_size': 6, 'n_epochs': 579, 'lr': 0.0005904294870813014}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd786cfa2ecb4032aa962095d4639acc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=629` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbc034419a604f8095c9a50278efdb80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:39:37,584] Trial 24 finished with value: inf and parameters: {'in_len': 28, 'out_len': 3, 'hidden_size': 3, 'batch_size': 4, 'n_epochs': 629, 'lr': 0.00010932867337156831}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 544    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 297    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 28, 'out_len': 3, 'hidden_size': 3, 'batch_size': 4, 'n_epochs': 629, 'lr': 0.00010932867337156831}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "864a4bb26c384c40bbfa91f09f50473a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=528` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e136f85ebe7640b5a96578ac642ba3c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:39:44,871] Trial 25 finished with value: inf and parameters: {'in_len': 16, 'out_len': 9, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 528, 'lr': 5.5456138325765785e-05}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 352    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 102    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "726       Trainable params\n",
      "0         Non-trainable params\n",
      "726       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 16, 'out_len': 9, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 528, 'lr': 5.5456138325765785e-05}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cc0407e87524a60a1f012ea5f857c5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=724` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "703f5f6fcaba43cbb4a817f16deba875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:39:54,538] Trial 26 finished with value: inf and parameters: {'in_len': 21, 'out_len': 6, 'hidden_size': 4, 'batch_size': 6, 'n_epochs': 724, 'lr': 0.0001835327334437171}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 992    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 33     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "2.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 21, 'out_len': 6, 'hidden_size': 4, 'batch_size': 6, 'n_epochs': 724, 'lr': 0.0001835327334437171}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3927642e17f74cc3b960ce0258bab242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=655` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "097c5505aecb4ebba92baea310f4b730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:40:03,612] Trial 27 finished with value: inf and parameters: {'in_len': 30, 'out_len': 1, 'hidden_size': 5, 'batch_size': 5, 'n_epochs': 655, 'lr': 0.00040116441662693317}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 768    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 231    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "2.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 30, 'out_len': 1, 'hidden_size': 5, 'batch_size': 5, 'n_epochs': 655, 'lr': 0.00040116441662693317}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28605d8080974ec8a6987fde02130f68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=597` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29d094756cd14faaa3a00cfe88bf80e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:40:11,820] Trial 28 finished with value: inf and parameters: {'in_len': 23, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 597, 'lr': 0.0053764500052075745}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 320    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 153    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "745       Trainable params\n",
      "0         Non-trainable params\n",
      "745       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 23, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 597, 'lr': 0.0053764500052075745}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5a033b777ed4b489b271e0eca3e9d4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=552` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deefc1ffbf2b4ceebbc815d6fa70d099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:40:19,413] Trial 29 finished with value: inf and parameters: {'in_len': 19, 'out_len': 9, 'hidden_size': 4, 'batch_size': 6, 'n_epochs': 552, 'lr': 8.933701285256679e-05}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 192    | train\n",
      "2 | lin2    | Linear  | 72     | train\n",
      "3 | lin3    | Linear  | 45     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "309       Trainable params\n",
      "0         Non-trainable params\n",
      "309       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 19, 'out_len': 9, 'hidden_size': 4, 'batch_size': 6, 'n_epochs': 552, 'lr': 8.933701285256679e-05}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54229048f6f84067889d04bb076b2903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=614` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db95388a899b4a94abb11616eaabc13b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:40:27,760] Trial 30 finished with value: inf and parameters: {'in_len': 23, 'out_len': 5, 'hidden_size': 3, 'batch_size': 3, 'n_epochs': 614, 'lr': 0.0023184644443023338}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 480    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 34     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "786       Trainable params\n",
      "0         Non-trainable params\n",
      "786       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 23, 'out_len': 5, 'hidden_size': 3, 'batch_size': 3, 'n_epochs': 614, 'lr': 0.0023184644443023338}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e9c873d334c472ab8fb7e01686947a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=475` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f605a80315f43e49f9460eed74aa6e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:40:34,176] Trial 31 finished with value: inf and parameters: {'in_len': 29, 'out_len': 2, 'hidden_size': 4, 'batch_size': 6, 'n_epochs': 475, 'lr': 6.514293116907686e-05}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 4.1 K  | train\n",
      "2 | lin2    | Linear  | 16.5 K | train\n",
      "3 | lin3    | Linear  | 129    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "20.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.7 K    Total params\n",
      "0.083     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 29, 'out_len': 2, 'hidden_size': 4, 'batch_size': 6, 'n_epochs': 475, 'lr': 6.514293116907686e-05}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96bee87757e34aa4b764ccb7d4e4e08a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=605` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0cecd512c564e68a90c315b531ae81f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:40:43,601] Trial 32 finished with value: inf and parameters: {'in_len': 31, 'out_len': 1, 'hidden_size': 7, 'batch_size': 5, 'n_epochs': 605, 'lr': 0.00019547444945125728}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 432    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 51     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "755       Trainable params\n",
      "0         Non-trainable params\n",
      "755       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 31, 'out_len': 1, 'hidden_size': 7, 'batch_size': 5, 'n_epochs': 605, 'lr': 0.00019547444945125728}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8721e320c4b44bd29896121f32b94c88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=547` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbbf1848cf0b4bf68e32bceae7f2b8ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:40:53,354] Trial 33 finished with value: inf and parameters: {'in_len': 26, 'out_len': 3, 'hidden_size': 4, 'batch_size': 3, 'n_epochs': 547, 'lr': 7.254357777798809e-05}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 1.5 K  | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 260    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "5.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.9 K     Total params\n",
      "0.024     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 26, 'out_len': 3, 'hidden_size': 4, 'batch_size': 3, 'n_epochs': 547, 'lr': 7.254357777798809e-05}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c76b5219f4da4f66be61cec7bb8453d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=740` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05d9c01ec05743108b1057f411d4d15d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:41:03,877] Trial 34 finished with value: inf and parameters: {'in_len': 22, 'out_len': 4, 'hidden_size': 6, 'batch_size': 6, 'n_epochs': 740, 'lr': 0.0001216438552695186}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 3.2 K  | train\n",
      "2 | lin2    | Linear  | 16.5 K | train\n",
      "3 | lin3    | Linear  | 516    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "20.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.2 K    Total params\n",
      "0.081     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 22, 'out_len': 4, 'hidden_size': 6, 'batch_size': 6, 'n_epochs': 740, 'lr': 0.0001216438552695186}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bfe03c92c164855a99ca6596b63ef36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=664` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c90bbe7bf3942209b0bbe3ffa2c1512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:41:14,211] Trial 35 finished with value: inf and parameters: {'in_len': 24, 'out_len': 4, 'hidden_size': 7, 'batch_size': 7, 'n_epochs': 664, 'lr': 0.0001501084398868491}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 896    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 66     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "2.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 24, 'out_len': 4, 'hidden_size': 7, 'batch_size': 7, 'n_epochs': 664, 'lr': 0.0001501084398868491}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a0d772fa3e948598c3d39346eef264a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=748` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a95cf1942ecc4204bc850999ce37c10f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:41:24,338] Trial 36 finished with value: inf and parameters: {'in_len': 27, 'out_len': 2, 'hidden_size': 5, 'batch_size': 6, 'n_epochs': 748, 'lr': 7.678077571402538e-05}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 112    | train\n",
      "2 | lin2    | Linear  | 72     | train\n",
      "3 | lin3    | Linear  | 108    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "292       Trainable params\n",
      "0         Non-trainable params\n",
      "292       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 27, 'out_len': 2, 'hidden_size': 5, 'batch_size': 6, 'n_epochs': 748, 'lr': 7.678077571402538e-05}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37a780f14a844c8e8a8d0af51be46af2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=501` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6091a422e18545e3b556e7008dd2d643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:41:30,962] Trial 37 finished with value: inf and parameters: {'in_len': 13, 'out_len': 12, 'hidden_size': 3, 'batch_size': 7, 'n_epochs': 501, 'lr': 0.0011128574052500445}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 1.3 K  | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 390    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "5.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.9 K     Total params\n",
      "0.024     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 13, 'out_len': 12, 'hidden_size': 3, 'batch_size': 7, 'n_epochs': 501, 'lr': 0.0011128574052500445}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d592361cb00e4775b05b66008950dbda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=677` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48b63fe99ecb48038f1c8c66cd1610d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:41:40,411] Trial 38 finished with value: inf and parameters: {'in_len': 20, 'out_len': 6, 'hidden_size': 6, 'batch_size': 4, 'n_epochs': 677, 'lr': 0.0007723520678388062}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 400    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 68     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "740       Trainable params\n",
      "0         Non-trainable params\n",
      "740       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 20, 'out_len': 6, 'hidden_size': 6, 'batch_size': 4, 'n_epochs': 677, 'lr': 0.0007723520678388062}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aa159071b794e4e9a009f8dda57eace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=423` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "399b5be135e247958f2674b41825b1cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:41:45,978] Trial 39 finished with value: inf and parameters: {'in_len': 24, 'out_len': 4, 'hidden_size': 4, 'batch_size': 6, 'n_epochs': 423, 'lr': 0.0003063417988876448}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 736    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 165    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "2.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 24, 'out_len': 4, 'hidden_size': 4, 'batch_size': 6, 'n_epochs': 423, 'lr': 0.0003063417988876448}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc951a2a1dde4976aa59aa9621aab614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=594` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc6842eaf2fc418ab5854f9f9e870115",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:41:54,123] Trial 40 finished with value: inf and parameters: {'in_len': 22, 'out_len': 5, 'hidden_size': 5, 'batch_size': 3, 'n_epochs': 594, 'lr': 0.00010208994900394779}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 4.0 K  | train\n",
      "2 | lin2    | Linear  | 16.5 K | train\n",
      "3 | lin3    | Linear  | 258    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "20.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.7 K    Total params\n",
      "0.083     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 22, 'out_len': 5, 'hidden_size': 5, 'batch_size': 3, 'n_epochs': 594, 'lr': 0.00010208994900394779}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d3c3bc2a6fa48f19c2aa89c6b54fcd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=773` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76a1c37adf394871b0354b70fd8d94a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:42:09,673] Trial 41 finished with value: inf and parameters: {'in_len': 30, 'out_len': 2, 'hidden_size': 7, 'batch_size': 3, 'n_epochs': 773, 'lr': 0.0001481388188596119}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 3.8 K  | train\n",
      "2 | lin2    | Linear  | 16.5 K | train\n",
      "3 | lin3    | Linear  | 258    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "20.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.6 K    Total params\n",
      "0.082     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 30, 'out_len': 2, 'hidden_size': 7, 'batch_size': 3, 'n_epochs': 773, 'lr': 0.0001481388188596119}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3914544dc81d4e378e2f40acc72cf046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=636` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5c62b931e3e4d94a3c563247e7d45ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:42:22,567] Trial 42 finished with value: inf and parameters: {'in_len': 29, 'out_len': 2, 'hidden_size': 7, 'batch_size': 3, 'n_epochs': 636, 'lr': 0.00021687803532788934}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 2.0 K  | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 65     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "6.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.3 K     Total params\n",
      "0.025     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 29, 'out_len': 2, 'hidden_size': 7, 'batch_size': 3, 'n_epochs': 636, 'lr': 0.00021687803532788934}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5262bdc8f33941c7a8ced41f73254b8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=799` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "368cda2e2b8840efba4e909936c9fe3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:42:44,525] Trial 43 finished with value: inf and parameters: {'in_len': 31, 'out_len': 1, 'hidden_size': 6, 'batch_size': 3, 'n_epochs': 799, 'lr': 6.53172188619787e-05}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 3.6 K  | train\n",
      "2 | lin2    | Linear  | 16.5 K | train\n",
      "3 | lin3    | Linear  | 387    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "20.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.5 K    Total params\n",
      "0.082     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 31, 'out_len': 1, 'hidden_size': 6, 'batch_size': 3, 'n_epochs': 799, 'lr': 6.53172188619787e-05}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4003e9bcd72d4dc4b7c9b8469c522491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=452` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01ed9a76d93c4441a7e61266ab79d3c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:42:51,838] Trial 44 finished with value: inf and parameters: {'in_len': 27, 'out_len': 3, 'hidden_size': 7, 'batch_size': 5, 'n_epochs': 452, 'lr': 8.557312007899956e-05}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 1.2 K  | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 1.0 K  | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "6.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.4 K     Total params\n",
      "0.025     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 27, 'out_len': 3, 'hidden_size': 7, 'batch_size': 5, 'n_epochs': 452, 'lr': 8.557312007899956e-05}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b358c2291d942669ede76697460130d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=698` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6ec5593178a4c1c8393c73fae8404c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:43:01,621] Trial 45 finished with value: inf and parameters: {'in_len': 17, 'out_len': 16, 'hidden_size': 6, 'batch_size': 4, 'n_epochs': 698, 'lr': 5.087498208123509e-05}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 1.7 K  | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 390    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "6.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.2 K     Total params\n",
      "0.025     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 17, 'out_len': 16, 'hidden_size': 6, 'batch_size': 4, 'n_epochs': 698, 'lr': 5.087498208123509e-05}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d849c02523fc43f2915fa5cc2827d26e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=518` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b41adc1ada36472ea0068efa6e66c30d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:43:08,838] Trial 46 finished with value: inf and parameters: {'in_len': 25, 'out_len': 6, 'hidden_size': 6, 'batch_size': 7, 'n_epochs': 518, 'lr': 0.00011599686112288687}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 992    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 66     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "2.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 25, 'out_len': 6, 'hidden_size': 6, 'batch_size': 7, 'n_epochs': 518, 'lr': 0.00011599686112288687}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a82d37785e34b7d80a7e021dcfe3923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=558` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50839975ed774823a530aa6063848719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:43:18,823] Trial 47 finished with value: inf and parameters: {'in_len': 30, 'out_len': 2, 'hidden_size': 5, 'batch_size': 3, 'n_epochs': 558, 'lr': 0.0015310969892074265}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 2.0 K  | train\n",
      "2 | lin2    | Linear  | 16.5 K | train\n",
      "3 | lin3    | Linear  | 903    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "19.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "19.5 K    Total params\n",
      "0.078     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: inf, Current params: {'in_len': 30, 'out_len': 2, 'hidden_size': 5, 'batch_size': 3, 'n_epochs': 558, 'lr': 0.0015310969892074265}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "920b9b1dd6114710a4086f82b8217a46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=757` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad44388eb7064ef88287ff9aeb9b73b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:43:30,349] Trial 48 finished with value: 0.34468058651564004 and parameters: {'in_len': 15, 'out_len': 7, 'hidden_size': 7, 'batch_size': 5, 'n_epochs': 757, 'lr': 0.00029587203986698214}. Best is trial 7 with value: 0.31808499372316873.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 112    | train\n",
      "2 | lin2    | Linear  | 72     | train\n",
      "3 | lin3    | Linear  | 72     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "256       Trainable params\n",
      "0         Non-trainable params\n",
      "256       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: 0.34468058651564004, Current params: {'in_len': 15, 'out_len': 7, 'hidden_size': 7, 'batch_size': 5, 'n_epochs': 757, 'lr': 0.00029587203986698214}\n",
      "Best value: 0.31808499372316873, Best params: {'in_len': 12, 'out_len': 7, 'hidden_size': 5, 'batch_size': 7, 'n_epochs': 543, 'lr': 8.612076518164722e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ab7ea0404744def96130fc1e1ad1c5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=625` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58e01e18fe2c42f48545461baa9f24b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:43:38,681] Trial 49 finished with value: 0.30691858609270606 and parameters: {'in_len': 13, 'out_len': 8, 'hidden_size': 3, 'batch_size': 5, 'n_epochs': 625, 'lr': 0.00027719726790487604}. Best is trial 49 with value: 0.30691858609270606.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value: 0.30691858609270606, Current params: {'in_len': 13, 'out_len': 8, 'hidden_size': 3, 'batch_size': 5, 'n_epochs': 625, 'lr': 0.00027719726790487604}\n",
      "Best value: 0.30691858609270606, Best params: {'in_len': 13, 'out_len': 8, 'hidden_size': 3, 'batch_size': 5, 'n_epochs': 625, 'lr': 0.00027719726790487604}\n"
     ]
    }
   ],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NARX(training=True, prepare_data_per_node=True, allow_zero_length_dataloader_with_multiple_devices=False, n_epochs=625, input_chunk_length=13, output_chunk_length=8, batch_size=32, random_state=0, fit_called=False, optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.00027719726790487604\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), window_model=SlidingWindow(input_chunk_length=13, output_chunk_length=8), preprocessing=[MinMaxScaler()], pl_trainer_kwargs={}, hidden_size=8)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(model)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# train the model\u001b[39;00m\n\u001b[1;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m---> 14\u001b[0m   series\u001b[38;5;241m=\u001b[39m\u001b[43mtrain_scaled\u001b[49m\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     16\u001b[0m pred_series \u001b[38;5;241m=\u001b[39m eval_model(\n\u001b[1;32m     17\u001b[0m     model,\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mlen\u001b[39m(val_scaled),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m     returned \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPREDICT_VALUES\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     23\u001b[0m )\n\u001b[1;32m     24\u001b[0m pred_series \u001b[38;5;241m=\u001b[39m pred_series[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "model = NARX(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    preprocessing = [MinMaxScaler()],\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1,12)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NARX(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        lr=lr,\n",
    "        n_epochs=n_epochs,\n",
    "        preprocessing = [MinMaxScaler()],\n",
    "        random_state = 0\n",
    "    )\n",
    "    # train the model\n",
    "    model.fit(train)\n",
    "    metrics = model.evaluate(val)\n",
    "\n",
    "    \n",
    "    mape_val = metrics['u2']\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 18:51:19,848] A new study created in memory with name: no-name-6fd6e466-f99f-47aa-b607-0563cc00477d\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3578/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 3.2 K  | train\n",
      "2 | lin2    | Linear  | 16.5 K | train\n",
      "3 | lin3    | Linear  | 516    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "20.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.2 K    Total params\n",
      "0.081     Total estimated model params size (MB)\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae10c06bb4e74c84adbccf7f3b75de8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=655` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca3c93cdf927454485ee1773e02d5acf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-07-24 18:51:30,024] Trial 0 failed with parameters: {'in_len': 24, 'out_len': 4, 'hidden_size': 7, 'batch_size': 5, 'n_epochs': 655, 'lr': 0.002172236929503528} because of the following error: ValueError('Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_57764/802593498.py\", line 27, in objective\n",
      "    metrics = model.evaluate(val)\n",
      "              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/classes/models/torch_generic_model.py\", line 291, in evaluate\n",
      "    \"mape\": mape([i[1] for i in val], predicted_outputs_original),\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/sklearn/metrics/_regression.py\", line 399, in mean_absolute_percentage_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/sklearn/metrics/_regression.py\", line 112, in _check_reg_targets\n",
      "    y_true = check_array(y_true, ensure_2d=False, dtype=dtype)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 1082, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "[W 2024-07-24 18:51:30,027] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# optimize hyperparameters by minimizing the mape on the validation set\u001b[39;00m\n\u001b[1;32m      2\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mprint_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/optuna/study/_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 62\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/optuna/study/_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/optuna/study/_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    246\u001b[0m ):\n\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[33], line 27\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# train the model\u001b[39;00m\n\u001b[1;32m     26\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(train)\n\u001b[0;32m---> 27\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m mape_val \u001b[38;5;241m=\u001b[39m metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mu2\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mape_val \u001b[38;5;28;01mif\u001b[39;00m mape_val \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documentos/Projeto-da-Graduacao/classes/models/torch_generic_model.py:291\u001b[0m, in \u001b[0;36mTorchGenericModel.evaluate\u001b[0;34m(self, val)\u001b[0m\n\u001b[1;32m    287\u001b[0m         predicted_outputs\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m    288\u001b[0m         progress_bar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m--> 291\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmape\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mmape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_outputs_original\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m\"\u001b[39m: mse([i[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m val], predicted_outputs_original),\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m\"\u001b[39m: rmse([i[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m val], predicted_outputs_original),\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msle\u001b[39m\u001b[38;5;124m\"\u001b[39m: sle([i[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m val], predicted_outputs_original),\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mu1\u001b[39m\u001b[38;5;124m\"\u001b[39m: UTheil()\u001b[38;5;241m.\u001b[39mcalculateU1([i[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m val_scaled], predicted_outputs),\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mu2\u001b[39m\u001b[38;5;124m\"\u001b[39m: UTheil()\u001b[38;5;241m.\u001b[39mcalculateU2([i[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m val_scaled], predicted_outputs),\n\u001b[1;32m    297\u001b[0m }\n",
      "File \u001b[0;32m~/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/sklearn/metrics/_regression.py:399\u001b[0m, in \u001b[0;36mmean_absolute_percentage_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m    322\u001b[0m     {\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    331\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    332\u001b[0m ):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Mean absolute percentage error (MAPE) regression loss.\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \n\u001b[1;32m    335\u001b[0m \u001b[38;5;124;03m    Note here that the output is not a percentage in the range [0, 100]\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;124;03m    112589990684262.48\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 399\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    402\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    403\u001b[0m     epsilon \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfinfo(np\u001b[38;5;241m.\u001b[39mfloat64)\u001b[38;5;241m.\u001b[39meps\n",
      "File \u001b[0;32m~/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/sklearn/metrics/_regression.py:112\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype, xp)\u001b[0m\n\u001b[1;32m    109\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred, multioutput, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[1;32m    111\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m--> 112\u001b[0m y_true \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/sklearn/utils/validation.py:1082\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1080\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[1;32m   1081\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[0;32m-> 1082\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1085\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[1;32m   1086\u001b[0m         )\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m   1089\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NARX(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    preprocessing = [MinMaxScaler()],\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando U2 e MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NARX(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        lr=lr,\n",
    "        n_epochs=n_epochs,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_scaled, preds)\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NARX(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4vOQfZh94Fsr",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Takens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 703
    },
    "id": "82zIFoHt4Ihr",
    "outputId": "d1420d33-465f-4000-84fd-6376a30090b1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_narx = []\n",
    "\n",
    "for input_chunk_length in [4*3, 4*6]:\n",
    "    for output_chunk_length in [4, 4*2, 4*3]:\n",
    "       for hidden_size in range(3, 7):\n",
    "           for batch_size in range(3, 7):\n",
    "               for lr in range(2, 5):\n",
    "                   for takens_tau in range(1,4):\n",
    "                        model = NARX(\n",
    "                            input_chunk_length=input_chunk_length,\n",
    "                            output_chunk_length=output_chunk_length,\n",
    "                            hidden_size=2**hidden_size,\n",
    "                            batch_size=2**batch_size,\n",
    "                            n_epochs=200,\n",
    "                            lr=10**(-lr),\n",
    "                            window_model = Takens(tau=takens_tau),\n",
    "                            preprocessing = [MinMaxScaler()],\n",
    "                            random_state = 0,\n",
    "                        )\n",
    "                        try:\n",
    "                            model.fit(train, val)\n",
    "                            metrics = model.evaluate(val)\n",
    "                        except:\n",
    "                            continue\n",
    "                        print({\n",
    "                            'mape': metrics['mape'],\n",
    "                            'sle': metrics['sle'],\n",
    "                            'rmse': metrics['rmse'],\n",
    "                            'mse': metrics['mse'],\n",
    "                            'u1': metrics['u1'],\n",
    "                            'u2': metrics['u2'],\n",
    "                            'lr': 10**(-lr),\n",
    "                            'input_chunk_length': input_chunk_length,\n",
    "                            'output_chunk_length': output_chunk_length,\n",
    "                            'takens_tau': takens_tau,\n",
    "                            'hidden_size': 2**hidden_size,\n",
    "                            'batch_size': 2**batch_size,\n",
    "                        })\n",
    "                        models_narx.append({\n",
    "                            'mape': metrics['mape'],\n",
    "                            'sle': metrics['sle'],\n",
    "                            'rmse': metrics['rmse'],\n",
    "                            'mse': metrics['mse'],\n",
    "                            'u1': metrics['u1'],\n",
    "                            'u2': metrics['u2'],\n",
    "                            'lr': 10**(-lr),\n",
    "                            'input_chunk_length': input_chunk_length,\n",
    "                            'output_chunk_length': output_chunk_length,\n",
    "                            'takens_tau': takens_tau,\n",
    "                            'hidden_size': 2**hidden_size,\n",
    "                            'batch_size': 2**batch_size,\n",
    "                        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 208    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 204    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "684       Trainable params\n",
      "0         Non-trainable params\n",
      "684       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MAPE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (5) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e12a83898b3a455db28fe94b0aab7992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "148a949e9df74a91947beaa04e514d25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 208    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 204    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "684       Trainable params\n",
      "0         Non-trainable params\n",
      "684       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.019981096632082418, 'mse': 0.010651060883335443, 'rmse': 0.0796762024243672, 'sle': 0.007978863970636088, 'u1': 0.3879987988896881, 'u2': 1.1544126640897698}\n",
      "Model:  NARX(training=True, prepare_data_per_node=True, allow_zero_length_dataloader_with_multiple_devices=False, n_epochs=200, input_chunk_length=12, output_chunk_length=12, batch_size=8, random_state=0, fit_called=True, optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), window_model=Takens(input_chunk_length=12, output_chunk_length=12, tau=1), preprocessing=[MinMaxScaler()], pl_trainer_kwargs={}, hidden_size=16, last_index=2023-01-23 00:00:00, data_freq=<Week: weekday=0>, last_data=[5.92149, 6.03723, 6.14058, 6.19233, 6.07111, 5.86276, 5.70988, 5.73702, 5.71108, 5.66975, 5.61122, 5.49708])\n",
      "\n",
      "\n",
      "Best SLE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (5) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d2dcd66f3b24c62b3db99d87f46dc0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4e8385cc3014b8dafec227d5aeec68b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 104    | train\n",
      "2 | lin2    | Linear  | 72     | train\n",
      "3 | lin3    | Linear  | 108    | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "284       Trainable params\n",
      "0         Non-trainable params\n",
      "284       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.019981096632082418, 'mse': 0.010651060883335443, 'rmse': 0.0796762024243672, 'sle': 0.007978863970636088, 'u1': 0.3879987988896881, 'u2': 1.1544126640897698}\n",
      "Model:  NARX(training=True, prepare_data_per_node=True, allow_zero_length_dataloader_with_multiple_devices=False, n_epochs=200, input_chunk_length=12, output_chunk_length=12, batch_size=8, random_state=0, fit_called=True, optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), window_model=Takens(input_chunk_length=12, output_chunk_length=12, tau=1), preprocessing=[MinMaxScaler()], pl_trainer_kwargs={}, hidden_size=16, last_index=2023-01-23 00:00:00, data_freq=<Week: weekday=0>, last_data=[5.92149, 6.03723, 6.14058, 6.19233, 6.07111, 5.86276, 5.70988, 5.73702, 5.71108, 5.66975, 5.61122, 5.49708])\n",
      "\n",
      "\n",
      "Best U1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (5) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71596c5217e74acaaa08678dbdacee74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ff90c177dfc465b98d1530063c04e8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 208    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 68     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "548       Trainable params\n",
      "0         Non-trainable params\n",
      "548       Total params\n",
      "0.002     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.03045109118969225, 'mse': 0.022461150549662384, 'rmse': 0.12129518703460691, 'sle': 0.016525144991660384, 'u1': 0.5887653324799269, 'u2': 1.6114552996931215}\n",
      "Model:  NARX(training=True, prepare_data_per_node=True, allow_zero_length_dataloader_with_multiple_devices=False, n_epochs=200, input_chunk_length=12, output_chunk_length=12, batch_size=8, random_state=0, fit_called=True, optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), window_model=Takens(input_chunk_length=12, output_chunk_length=12, tau=1), preprocessing=[MinMaxScaler()], pl_trainer_kwargs={}, hidden_size=8, last_index=2023-01-23 00:00:00, data_freq=<Week: weekday=0>, last_data=[5.92149, 6.03723, 6.14058, 6.19233, 6.07111, 5.86276, 5.70988, 5.73702, 5.71108, 5.66975, 5.61122, 5.49708])\n",
      "\n",
      "\n",
      "Best U2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61ed5c211d2a47aca393bce5256c2531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab0eaffb7bb94e61b8d2177f6ac68e9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.0579169981276531, 'mse': 0.06935187248721682, 'rmse': 0.2511378452050789, 'sle': 0.1442910438997791, 'u1': 1.0701756670534535, 'u2': 3.307390076302709}\n",
      "Model:  NARX(training=True, prepare_data_per_node=True, allow_zero_length_dataloader_with_multiple_devices=False, n_epochs=200, input_chunk_length=12, output_chunk_length=4, batch_size=64, random_state=0, fit_called=True, optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.0001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), window_model=Takens(input_chunk_length=12, output_chunk_length=4, tau=1), preprocessing=[MinMaxScaler()], pl_trainer_kwargs={}, hidden_size=16, last_index=2023-01-23 00:00:00, data_freq=<Week: weekday=0>, last_data=[5.92149, 6.03723, 6.14058, 6.19233, 6.07111, 5.86276, 5.70988, 5.73702, 5.71108, 5.66975, 5.61122, 5.49708])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_narx in [\n",
    "                            {\n",
    "                                'name': 'MAPE',\n",
    "                                'input_chunk_length': min(models_narx, key=lambda d: d['mape'])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_narx, key=lambda d: d['mape'])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_narx, key=lambda d: d['mape'])['hidden_size'],\n",
    "                                'batch_size': min(models_narx, key=lambda d: d['mape'])['batch_size'],\n",
    "                                'lr': min(models_narx, key=lambda d: d['mape'])['lr'],\n",
    "                                'takens_tau': min(models_narx, key=lambda d: d['mape'])['takens_tau'],\n",
    "                            },\n",
    "                            {\n",
    "                                'name': 'SLE',\n",
    "                                'input_chunk_length': min(models_narx, key=lambda d: d['sle'])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_narx, key=lambda d: d['sle'])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_narx, key=lambda d: d['sle'])['hidden_size'],\n",
    "                                'batch_size': min(models_narx, key=lambda d: d['sle'])['batch_size'],\n",
    "                                'lr': min(models_narx, key=lambda d: d['sle'])['lr'],\n",
    "                                'takens_tau': min(models_narx, key=lambda d: d['sle'])['takens_tau'],\n",
    "                            },\n",
    "                            {\n",
    "                                'name': 'U1',\n",
    "                                'input_chunk_length': min(models_narx, key=lambda d: d['u1'])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_narx, key=lambda d: d['u1'])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_narx, key=lambda d: d['u1'])['hidden_size'],\n",
    "                                'batch_size': min(models_narx, key=lambda d: d['u1'])['batch_size'],\n",
    "                                'lr': min(models_narx, key=lambda d: d['u1'])['lr'],\n",
    "                                'takens_tau': min(models_narx, key=lambda d: d['u1'])['takens_tau'],\n",
    "                            },\n",
    "                            {\n",
    "                                'name': 'U2',\n",
    "                                'input_chunk_length': min(models_narx, key=lambda d: d['u2'])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_narx, key=lambda d: d['u2'])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_narx, key=lambda d: d['u2'])['hidden_size'],\n",
    "                                'batch_size': min(models_narx, key=lambda d: d['u2'])['batch_size'],\n",
    "                                'lr': min(models_narx, key=lambda d: d['u2'])['lr'],\n",
    "                                'takens_tau': min(models_narx, key=lambda d: d['u2'])['takens_tau'],\n",
    "                            },\n",
    "                        ]:\n",
    "    print('Best', best_model_narx['name'])\n",
    "    model = NARX(\n",
    "        input_chunk_length=best_model_narx['input_chunk_length'],\n",
    "        output_chunk_length=best_model_narx['output_chunk_length'],\n",
    "        hidden_size=best_model_narx['hidden_size'],\n",
    "        batch_size=best_model_narx['batch_size'],\n",
    "        lr=best_model_narx['lr'],\n",
    "        window_model = Takens(tau=best_model_narx['takens_tau']),\n",
    "        n_epochs=200,\n",
    "        preprocessing = [MinMaxScaler()],\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit(train)\n",
    "    print(model.evaluate(val))\n",
    "    print('Model: ', model)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, 3)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NARX(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        lr=lr,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        n_epochs=n_epochs,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NARX(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, 3)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NARX(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        lr=lr,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        n_epochs=n_epochs,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NARX(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando U2 e MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, 3)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NARX(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        lr=lr,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        n_epochs=n_epochs,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_scaled, preds)\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NARX(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Brasil + Óleo de Soja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGF6kc-h4BJU"
   },
   "source": [
    "#### Janela Deslizante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "id": "FQ705nUH9WXK",
    "outputId": "e2eb8927-8d66-4d9f-8946-47656d9956c8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 168    | train\n",
      "2 | lin2    | Linear  | 72     | train\n",
      "3 | lin3    | Linear  | 9      | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "249       Trainable params\n",
      "0         Non-trainable params\n",
      "249       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "070b6f302b8c4cefa88e7a47f78b6234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98a49a26e6774feb8915abec6d9e2c62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.014307100390329463, 'sle': 0.0013685826175918385, 'rmse': 0.07352693943366395, 'mse': 0.005406210822481688, 'u1': 0.2596452664074085, 'u2': 0.6091925066787471, 'lr': 0.01, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 8, 'batch_size': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 168    | train\n",
      "2 | lin2    | Linear  | 72     | train\n",
      "3 | lin3    | Linear  | 9      | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "249       Trainable params\n",
      "0         Non-trainable params\n",
      "249       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb55198d6c714aff9c4e143e39410d64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c6a55ac9a334e8a84b639e3988e023b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.014044513792484784, 'sle': 0.0009043027437784913, 'rmse': 0.06107318712281624, 'mse': 0.0037299341853385274, 'u1': 0.21352648185738712, 'u2': 1.075414933028669, 'lr': 0.001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 8, 'batch_size': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 168    | train\n",
      "2 | lin2    | Linear  | 72     | train\n",
      "3 | lin3    | Linear  | 9      | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "249       Trainable params\n",
      "0         Non-trainable params\n",
      "249       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a0ff4003f974dd3a593aca47ead6e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91023a9473d84616843ae4f0147a4514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.018716042726915752, 'sle': 0.0014984298550116933, 'rmse': 0.07829278500704198, 'mse': 0.006129760184158898, 'u1': 0.2535233263052373, 'u2': 1.4391199166370672, 'lr': 0.0001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 8, 'batch_size': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 168    | train\n",
      "2 | lin2    | Linear  | 72     | train\n",
      "3 | lin3    | Linear  | 9      | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "249       Trainable params\n",
      "0         Non-trainable params\n",
      "249       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7486c01e971477198d0f6548a297c50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "681cb1d27ab94fea85dc3cd6675aeab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.013476692812255192, 'sle': 0.0008246647104210664, 'rmse': 0.05777583537875076, 'mse': 0.0033380471537125074, 'u1': 0.1876571043139377, 'u2': 0.9738049380517221, 'lr': 0.01, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 8, 'batch_size': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 168    | train\n",
      "2 | lin2    | Linear  | 72     | train\n",
      "3 | lin3    | Linear  | 9      | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "249       Trainable params\n",
      "0         Non-trainable params\n",
      "249       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a973bb5ee0f4707a777f875728e236e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93b2abe594734c9ba1519e38e4478b58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.014775976853394091, 'sle': 0.00096516645800122, 'rmse': 0.06302588514731217, 'mse': 0.003972262198602184, 'u1': 0.21659866379699247, 'u2': 1.1230859783710232, 'lr': 0.001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 8, 'batch_size': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 168    | train\n",
      "2 | lin2    | Linear  | 72     | train\n",
      "3 | lin3    | Linear  | 9      | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "249       Trainable params\n",
      "0         Non-trainable params\n",
      "249       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aa5d85d42ce4ac5bb409d78870b0ee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c25588ffda7e424cbdc588720e4ea38d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.01961186878647674, 'sle': 0.0016515720069442041, 'rmse': 0.0822426791912713, 'mse': 0.006763858280558369, 'u1': 0.2560140961820589, 'u2': 1.5456516035878463, 'lr': 0.0001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 8, 'batch_size': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 168    | train\n",
      "2 | lin2    | Linear  | 72     | train\n",
      "3 | lin3    | Linear  | 9      | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "249       Trainable params\n",
      "0         Non-trainable params\n",
      "249       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "011266bdf6d94403a7e07453b9af09aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ac5329e17f540b8b0d6481b6effc358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.016717846224977927, 'sle': 0.0018239767670485516, 'rmse': 0.08534516149014826, 'mse': 0.007283796589779484, 'u1': 0.3195162086438326, 'u2': 0.8698601085738044, 'lr': 0.01, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 8, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 168    | train\n",
      "2 | lin2    | Linear  | 72     | train\n",
      "3 | lin3    | Linear  | 9      | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "249       Trainable params\n",
      "0         Non-trainable params\n",
      "249       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2e8b152349d48fba3e183d0e3853bc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87f406ef5e79470ea637984428686f18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.015261628840057474, 'sle': 0.00124695765613742, 'rmse': 0.07110967814086323, 'mse': 0.0050565863252971625, 'u1': 0.25396820319634705, 'u2': 0.968879463094266, 'lr': 0.001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 8, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 168    | train\n",
      "2 | lin2    | Linear  | 72     | train\n",
      "3 | lin3    | Linear  | 9      | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "249       Trainable params\n",
      "0         Non-trainable params\n",
      "249       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66bd21975adc44eb8c234b810b95815c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32f90f1cd64548d19c8aae10cc218429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.020551523740928133, 'sle': 0.00206548205963617, 'rmse': 0.09071593586466671, 'mse': 0.008229381019802324, 'u1': 0.2746112181418858, 'u2': 1.2693589454524152, 'lr': 0.0001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 8, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 168    | train\n",
      "2 | lin2    | Linear  | 72     | train\n",
      "3 | lin3    | Linear  | 9      | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "249       Trainable params\n",
      "0         Non-trainable params\n",
      "249       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cc9c6b6bf98485da81040922a91230e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c220835e35be46db8dee446a28539c5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.012851126505463911, 'sle': 0.0010820129346683241, 'rmse': 0.06619051233481536, 'mse': 0.004381183923145345, 'u1': 0.24408206262516036, 'u2': 0.7562254053958911, 'lr': 0.01, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 8, 'batch_size': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 168    | train\n",
      "2 | lin2    | Linear  | 72     | train\n",
      "3 | lin3    | Linear  | 9      | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "249       Trainable params\n",
      "0         Non-trainable params\n",
      "249       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e04ecf1922fc41678ab2dfa7e8857672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9754f7ba0a04f74a97bc091a5522de3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.01612170728270363, 'sle': 0.001119140737673099, 'rmse': 0.06775312676979171, 'mse': 0.004590486187083466, 'u1': 0.2250195105211287, 'u2': 1.2465599197401946, 'lr': 0.001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 8, 'batch_size': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 168    | train\n",
      "2 | lin2    | Linear  | 72     | train\n",
      "3 | lin3    | Linear  | 9      | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "249       Trainable params\n",
      "0         Non-trainable params\n",
      "249       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c48088360a64ae1bc8335d38bdcdc4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56aa1c6feae24bafa3d45459a009a955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.019517684057709372, 'sle': 0.0026144408587166824, 'rmse': 0.1009683983875713, 'mse': 0.01019461747295131, 'u1': 0.2941743477287048, 'u2': 0.9396397260786008, 'lr': 0.0001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 8, 'batch_size': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 336    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 17     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "625       Trainable params\n",
      "0         Non-trainable params\n",
      "625       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d39874f7de649a1b1f917f0ac9d9cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c06a4c2704a24f5cbf1fc98638d34bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.016356976864982744, 'sle': 0.0018035865045614718, 'rmse': 0.08721871827862045, 'mse': 0.007607104818165361, 'u1': 0.25412709324603905, 'u2': 2.0035473347586024, 'lr': 0.01, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 16, 'batch_size': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 336    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 17     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "625       Trainable params\n",
      "0         Non-trainable params\n",
      "625       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28d1da595a8e4511800643dc6b25a38a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc83ffb44f3843c0b11eac17c36775c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.013389899323915384, 'sle': 0.0008681981033347791, 'rmse': 0.05958040102379285, 'mse': 0.003549824186155976, 'u1': 0.2084670466823499, 'u2': 0.939406151173372, 'lr': 0.001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 16, 'batch_size': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 336    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 17     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "625       Trainable params\n",
      "0         Non-trainable params\n",
      "625       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec51db0b64914b9280670cf94bcbf596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a434d6356817483c87c9939882a65a5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.017486089095487645, 'sle': 0.0013110710570909654, 'rmse': 0.07329856447881224, 'mse': 0.005372679554654594, 'u1': 0.24067186382534814, 'u2': 1.3527756472931887, 'lr': 0.0001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 16, 'batch_size': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 336    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 17     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "625       Trainable params\n",
      "0         Non-trainable params\n",
      "625       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33242b26247b4b36b1e4b638e25bceaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9111395491440c7ab5882e299860b63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.013396214570624496, 'sle': 0.0009498222472110933, 'rmse': 0.06218133787290549, 'mse': 0.0038665187796644305, 'u1': 0.2183000331475353, 'u2': 0.9362930527229362, 'lr': 0.01, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 16, 'batch_size': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 336    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 17     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "625       Trainable params\n",
      "0         Non-trainable params\n",
      "625       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e7d1ee5a524fcc8a27c0a41e7fa4af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81bb8ac140214032b981157481584b40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.014747744459540909, 'sle': 0.0009637044747948464, 'rmse': 0.06288421916651545, 'mse': 0.003954425020182348, 'u1': 0.21571625641439382, 'u2': 1.0872660333355813, 'lr': 0.001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 16, 'batch_size': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 336    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 17     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "625       Trainable params\n",
      "0         Non-trainable params\n",
      "625       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f34821ec49d4e529585031d43d71a3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "636ebdf9719a4f7a933e3e8190468f3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.018674706791630295, 'sle': 0.001509457344112385, 'rmse': 0.07862654674339427, 'mse': 0.006182133852791164, 'u1': 0.2494203541515549, 'u2': 1.4963699756620645, 'lr': 0.0001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 16, 'batch_size': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 336    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 17     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "625       Trainable params\n",
      "0         Non-trainable params\n",
      "625       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f757351534fc43e6be69daf8063e4a32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cf5562c1bb9439ba5beee7cb7268b42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.025167378744447796, 'sle': 0.003356303103577897, 'rmse': 0.11466083499177288, 'mse': 0.013147107081010568, 'u1': 0.44572652556706466, 'u2': 1.2144265279978839, 'lr': 0.01, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 16, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 336    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 17     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "625       Trainable params\n",
      "0         Non-trainable params\n",
      "625       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "250bb54bfe8b4a929c9bb652b186a8ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c38af7d3f16d454da6b829d96b2dc50e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.015287370318934297, 'sle': 0.0012632287944411812, 'rmse': 0.07150593083311438, 'mse': 0.005113098144310138, 'u1': 0.2559822136358115, 'u2': 0.9244900855441378, 'lr': 0.001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 16, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 336    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 17     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "625       Trainable params\n",
      "0         Non-trainable params\n",
      "625       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85251eca6d2649e5b400c327e4173f08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ec058b92bb84ad49fb65aa7a9cdbda1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.020285671613297588, 'sle': 0.0018819832629226152, 'rmse': 0.08693654597787558, 'mse': 0.007557963026563273, 'u1': 0.26825725813860624, 'u2': 1.3876614812433297, 'lr': 0.0001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 16, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 336    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 17     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "625       Trainable params\n",
      "0         Non-trainable params\n",
      "625       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2395c0660faa48679e8e81e4bcde6976",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3b59bdd3712440bbb39503edee259da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.014420124363667304, 'sle': 0.0012088173637707692, 'rmse': 0.07017161859185314, 'mse': 0.00492405605580051, 'u1': 0.2563515986900003, 'u2': 0.9807910527587491, 'lr': 0.01, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 16, 'batch_size': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 336    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 17     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "625       Trainable params\n",
      "0         Non-trainable params\n",
      "625       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cc7bf3b83844ada9aefabaf11891793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9a1b220680540379805dcc1688b583b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.016062853949263538, 'sle': 0.0010852858606983167, 'rmse': 0.0669850828645704, 'mse': 0.004487001326373364, 'u1': 0.21798939131165337, 'u2': 1.336025804394658, 'lr': 0.001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 16, 'batch_size': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 336    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 17     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "625       Trainable params\n",
      "0         Non-trainable params\n",
      "625       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4f321b351d24b998e62d009fc9f1422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3672ee2f6d6c489c8c3120fcc4d9df03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.02037550274337506, 'sle': 0.0022728263494241597, 'rmse': 0.09488405925850761, 'mse': 0.009002984701371985, 'u1': 0.28053643359280084, 'u2': 1.2754524941590104, 'lr': 0.0001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 16, 'batch_size': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 672    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 33     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6fd1d6d690c47e1891f77b084f8f3ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80b1e4a141e7463f9e837c30023eeab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.008941665314196778, 'sle': 0.0005856823571491276, 'rmse': 0.04945003157718137, 'mse': 0.0024453056229842346, 'u1': 0.19102776487670997, 'u2': 0.7528795118640808, 'lr': 0.01, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 32, 'batch_size': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 672    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 33     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6df1cee13fdc47a6bd4779b6707b0b0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9fa51fb052c462ba1ba9da78a5895f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.012051243799418384, 'sle': 0.0006329794961058757, 'rmse': 0.0511352606352566, 'mse': 0.002614814880235623, 'u1': 0.17516524498652195, 'u2': 0.9520814778316232, 'lr': 0.001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 32, 'batch_size': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 672    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 33     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cd5125c111d4f758d1054493db49b2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0a93c1e04a3473aab316b986c92194e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.01645476450946216, 'sle': 0.0011151512358346933, 'rmse': 0.06763912291667008, 'mse': 0.004575050948936404, 'u1': 0.22320878572064556, 'u2': 1.2184610209412152, 'lr': 0.0001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 32, 'batch_size': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 672    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 33     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11650780fa4d4101947eac479a5e10d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0943640d7dc40ae96186a1863c1cbec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.014091842223243474, 'sle': 0.001467586086058348, 'rmse': 0.0753398377338885, 'mse': 0.00567609114976865, 'u1': 0.23786027299658152, 'u2': 0.4624666399896742, 'lr': 0.01, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 32, 'batch_size': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 672    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 33     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e6d73752320427aaf54343073dbfa34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77039517357447398eb27f3c5b5604da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.014948423325169012, 'sle': 0.0009612775721155629, 'rmse': 0.06299762744989958, 'mse': 0.00396870106431634, 'u1': 0.2138990811660067, 'u2': 1.1793303054794402, 'lr': 0.001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 32, 'batch_size': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 672    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 33     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "723edb6bf55741ba89813419da00e369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b83ae287e26841cc85e4089261909cb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.017620599312573322, 'sle': 0.0012953849498281592, 'rmse': 0.07267794064460802, 'mse': 0.005282083056341166, 'u1': 0.23881911686313903, 'u2': 1.2373967396903538, 'lr': 0.0001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 32, 'batch_size': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 672    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 33     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2066a5c53d364a35a32c1a7095fe68c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35a5b98a04f946a5b4554bbfbeeeeeb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.013822999327244756, 'sle': 0.0009381608633388278, 'rmse': 0.062037603977472384, 'mse': 0.0038486643072656976, 'u1': 0.19130228491616857, 'u2': 1.242407692691864, 'lr': 0.01, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 32, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 672    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 33     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c452ffdc831f4de2b35cd3eca8921933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c1e49de27be47e99d5a1996c2b514dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.01536882719860605, 'sle': 0.0013838010522177493, 'rmse': 0.07473936935490941, 'mse': 0.005585973331569571, 'u1': 0.2713320000640427, 'u2': 0.8924359563397651, 'lr': 0.001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 32, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 672    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 33     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2afb1ab7d269416b8edaf0188a9a67ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9f15495122448f9916abc0333c8a671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.019446693709673588, 'sle': 0.0015753846899324976, 'rmse': 0.08015049001734473, 'mse': 0.006424101050020476, 'u1': 0.2555041651503179, 'u2': 1.40439895074094, 'lr': 0.0001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 32, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 672    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 33     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "816d8db8d2ee4d3485ed4f7052b0f482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62bc720861c3446e9347a4eb1af0fb23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.013160143441917516, 'sle': 0.000780715541848073, 'rmse': 0.05652047802577549, 'mse': 0.00319456443626217, 'u1': 0.19515618458593664, 'u2': 0.9103008446681001, 'lr': 0.01, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 32, 'batch_size': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 672    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 33     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c822a85d2fd490db91c9910eb9ce186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e4ed115e1674f679cf2da06ef6aa4c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.014943869710998932, 'sle': 0.000980626062807197, 'rmse': 0.06331572923467486, 'mse': 0.004008881568518661, 'u1': 0.21886729393558932, 'u2': 0.9913482065126678, 'lr': 0.001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 32, 'batch_size': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 672    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 33     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8f4f183364e4d3186cefd83e318613a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cffeb9dc61e49bc807daa17f122cc9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.02069639853867583, 'sle': 0.0019814721818604995, 'rmse': 0.08880783152801411, 'mse': 0.007886830940708136, 'u1': 0.28398500876750044, 'u2': 1.1873699782969986, 'lr': 0.0001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 32, 'batch_size': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 1.3 K  | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 65     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "5.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.6 K     Total params\n",
      "0.022     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e0738e6bbb34b6c824926962342b146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd7d825fb5b24d608ef89c3528485386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.06583904881823543, 'sle': 0.020161766885958977, 'rmse': 0.2762186331463289, 'mse': 0.07629673329722622, 'u1': 1.1399894350971338, 'u2': 3.714752344886803, 'lr': 0.01, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 64, 'batch_size': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 1.3 K  | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 65     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "5.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.6 K     Total params\n",
      "0.022     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c34e6866566d48a58355118adb6e4f30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca6c90871a104043b0237f68d90d477a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.011786147863618056, 'sle': 0.0006220616568288808, 'rmse': 0.0505471709881486, 'mse': 0.002555016494905132, 'u1': 0.17659776816436135, 'u2': 0.7933945623009397, 'lr': 0.001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 64, 'batch_size': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 1.3 K  | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 65     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "5.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.6 K     Total params\n",
      "0.022     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e00b467dfa4c44319142fbee63fde832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c10160680b3c41f3b89d60305111b6ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.015277359038092105, 'sle': 0.00096531825048369, 'rmse': 0.06308341905235301, 'mse': 0.003979517759334775, 'u1': 0.21107960518951888, 'u2': 1.169735482194199, 'lr': 0.0001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 64, 'batch_size': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 1.3 K  | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 65     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "5.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.6 K     Total params\n",
      "0.022     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f9b866d08944463b6d3edf9ae99e3a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e58e0991cb56405699d7fc3d891c4044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.015080377973303718, 'sle': 0.0011208173918833841, 'rmse': 0.06655661495286579, 'mse': 0.004429782993984038, 'u1': 0.23803895799703848, 'u2': 0.8087489054508177, 'lr': 0.01, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 64, 'batch_size': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 1.3 K  | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 65     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "5.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.6 K     Total params\n",
      "0.022     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b3a84b337af4f4dba2299c70d4f690f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56b8133b40b94192bf10801f0a4dddca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.014014824566087509, 'sle': 0.0008627304669784925, 'rmse': 0.05983648747070212, 'mse': 0.003580405232831491, 'u1': 0.20509698460982376, 'u2': 1.1502528214436891, 'lr': 0.001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 64, 'batch_size': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 1.3 K  | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 65     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "5.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.6 K     Total params\n",
      "0.022     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea8f555a9ea444b5b75b29c19a5f60f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cf37e8c1fd84fed8802ac7390d0580b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.015346006794322454, 'sle': 0.001051149864500258, 'rmse': 0.06544077748568225, 'mse': 0.0042824953579305765, 'u1': 0.2248840134150685, 'u2': 1.0112441269789998, 'lr': 0.0001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 64, 'batch_size': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 1.3 K  | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 65     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "5.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.6 K     Total params\n",
      "0.022     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfa28819ed804be09eaff453cb5a6b0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33ebc90add6b4fa9b67d3f73285fe708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.009842683983122325, 'sle': 0.0009372498882403332, 'rmse': 0.06236927395757833, 'mse': 0.003889926333995459, 'u1': 0.24913276184976704, 'u2': 0.8902480740837316, 'lr': 0.01, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 64, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 1.3 K  | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 65     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "5.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.6 K     Total params\n",
      "0.022     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26f05b8191bf4956ae907e5eef91e9fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dadd76fd10da43dbb090c4b1be1a3d30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.014842637738421397, 'sle': 0.0014780207752983004, 'rmse': 0.07732919776812104, 'mse': 0.005979804827461176, 'u1': 0.2894264860653003, 'u2': 0.9194202919987913, 'lr': 0.001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 64, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 1.3 K  | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 65     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "5.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.6 K     Total params\n",
      "0.022     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f512787bdf6c441ebb7722062cfb9a5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f91067be0bb7483e8636d4979d6ec24e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.015938111539095415, 'sle': 0.0010573405300897745, 'rmse': 0.065966098933208, 'mse': 0.004351526208465786, 'u1': 0.21641140420106242, 'u2': 1.2528099373210648, 'lr': 0.0001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 64, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 1.3 K  | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 65     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "5.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.6 K     Total params\n",
      "0.022     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "952c89946c7b43c384f34edcb1731fe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7be0391652147329788cde5922295a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.01221990816789737, 'sle': 0.000685529234043427, 'rmse': 0.05343408297734896, 'mse': 0.002855201223630214, 'u1': 0.18152505355782833, 'u2': 1.0905464451277571, 'lr': 0.01, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 64, 'batch_size': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 1.3 K  | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 65     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "5.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.6 K     Total params\n",
      "0.022     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "229adf97f4914cdd8a5f6ff0eccf3a00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de2c2f91f4fc45dcb96138c9bd000347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.014970734090295996, 'sle': 0.0010097490789657154, 'rmse': 0.06421216155129489, 'mse': 0.0041232016910895935, 'u1': 0.22352456826101702, 'u2': 0.9769140100610366, 'lr': 0.001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 64, 'batch_size': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 1.3 K  | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 65     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "5.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.6 K     Total params\n",
      "0.022     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7338870521ec4a089627c36131d6bcc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ebe0ef286b343e7a506ed51d8f4671f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 168    | train\n",
      "2 | lin2    | Linear  | 72     | train\n",
      "3 | lin3    | Linear  | 45     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "285       Trainable params\n",
      "0         Non-trainable params\n",
      "285       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.016352062523853596, 'sle': 0.001220726894746726, 'rmse': 0.07025912774350941, 'mse': 0.004936345031278775, 'u1': 0.23647518594502825, 'u2': 1.0607212224451315, 'lr': 0.0001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'hidden_size': 64, 'batch_size': 64}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75bd2d76ffee4078a426e14f1ee61b3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7dd43314b3d4d60bee3289f94a786b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 19\u001b[0m\n\u001b[1;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m NARX(\n\u001b[1;32m      9\u001b[0m     input_chunk_length\u001b[38;5;241m=\u001b[39minput_chunk_length,\n\u001b[1;32m     10\u001b[0m     output_chunk_length\u001b[38;5;241m=\u001b[39moutput_chunk_length,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     18\u001b[0m model\u001b[38;5;241m.\u001b[39mfit([train, soybean_oil\u001b[38;5;241m.\u001b[39mslice(soybean_oil\u001b[38;5;241m.\u001b[39mstart_time(), train\u001b[38;5;241m.\u001b[39mend_time())])\n\u001b[0;32m---> 19\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m({\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmape\u001b[39m\u001b[38;5;124m'\u001b[39m: metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmape\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msle\u001b[39m\u001b[38;5;124m'\u001b[39m: metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msle\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbatch_size,\n\u001b[1;32m     32\u001b[0m })\n\u001b[1;32m     33\u001b[0m models_narx\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmape\u001b[39m\u001b[38;5;124m'\u001b[39m: metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmape\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msle\u001b[39m\u001b[38;5;124m'\u001b[39m: metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msle\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbatch_size,\n\u001b[1;32m     45\u001b[0m })\n",
      "File \u001b[0;32m~/Documentos/Projeto-da-Graduacao/classes/models/torch_generic_model.py:308\u001b[0m, in \u001b[0;36mTorchGenericModel.evaluate\u001b[0;34m(self, val)\u001b[0m\n\u001b[1;32m    304\u001b[0m         predicted_outputs\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m    305\u001b[0m         progress_bar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m--> 308\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmape\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mmape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_outputs_original\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m\"\u001b[39m: mse([i[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m val], predicted_outputs_original),\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m\"\u001b[39m: rmse([i[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m val], predicted_outputs_original),\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msle\u001b[39m\u001b[38;5;124m\"\u001b[39m: sle([i[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m val], predicted_outputs_original),\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mu1\u001b[39m\u001b[38;5;124m\"\u001b[39m: UTheil()\u001b[38;5;241m.\u001b[39mcalculateU1([i[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m val_scaled], predicted_outputs),\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mu2\u001b[39m\u001b[38;5;124m\"\u001b[39m: UTheil()\u001b[38;5;241m.\u001b[39mcalculateU2([i[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m val_scaled], predicted_outputs),\n\u001b[1;32m    314\u001b[0m }\n",
      "File \u001b[0;32m~/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/sklearn/metrics/_regression.py:399\u001b[0m, in \u001b[0;36mmean_absolute_percentage_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m    322\u001b[0m     {\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    331\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    332\u001b[0m ):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Mean absolute percentage error (MAPE) regression loss.\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \n\u001b[1;32m    335\u001b[0m \u001b[38;5;124;03m    Note here that the output is not a percentage in the range [0, 100]\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;124;03m    112589990684262.48\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 399\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    402\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    403\u001b[0m     epsilon \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfinfo(np\u001b[38;5;241m.\u001b[39mfloat64)\u001b[38;5;241m.\u001b[39meps\n",
      "File \u001b[0;32m~/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/sklearn/metrics/_regression.py:112\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype, xp)\u001b[0m\n\u001b[1;32m    109\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred, multioutput, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[1;32m    111\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m--> 112\u001b[0m y_true \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/sklearn/utils/validation.py:1082\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1080\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[1;32m   1081\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[0;32m-> 1082\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1085\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[1;32m   1086\u001b[0m         )\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m   1089\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "models_narx = []\n",
    "\n",
    "for input_chunk_length in range(20, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "       for hidden_size in range(3, 7):\n",
    "           for batch_size in range(3, 7):\n",
    "               for lr in range(2, 5):\n",
    "                    model = NARX(\n",
    "                        input_chunk_length=input_chunk_length,\n",
    "                        output_chunk_length=output_chunk_length,\n",
    "                        hidden_size=2**hidden_size,\n",
    "                        batch_size=2**batch_size,\n",
    "                        n_epochs=200,\n",
    "                        lr=10**(-lr),\n",
    "                        preprocessing = [MinMaxScaler()],\n",
    "                        random_state = 0,\n",
    "                    )\n",
    "                    model.fit([train, soybean_oil.slice(soybean_oil.start_time(), train.end_time())])\n",
    "                    metrics = model.evaluate(val)\n",
    "                    print({\n",
    "                        'mape': metrics['mape'],\n",
    "                        'sle': metrics['sle'],\n",
    "                        'rmse': metrics['rmse'],\n",
    "                        'mse': metrics['mse'],\n",
    "                        'u1': metrics['u1'],\n",
    "                        'u2': metrics['u2'],\n",
    "                        'lr': 10**(-lr),\n",
    "                        'input_chunk_length': input_chunk_length,\n",
    "                        'output_chunk_length': output_chunk_length,\n",
    "                        'hidden_size': 2**hidden_size,\n",
    "                        'batch_size': 2**batch_size,\n",
    "                    })\n",
    "                    models_narx.append({\n",
    "                        'mape': metrics['mape'],\n",
    "                        'sle': metrics['sle'],\n",
    "                        'rmse': metrics['rmse'],\n",
    "                        'mse': metrics['mse'],\n",
    "                        'u1': metrics['u1'],\n",
    "                        'u2': metrics['u2'],\n",
    "                        'lr': 10**(-lr),\n",
    "                        'input_chunk_length': input_chunk_length,\n",
    "                        'output_chunk_length': output_chunk_length,\n",
    "                        'hidden_size': 2**hidden_size,\n",
    "                        'batch_size': 2**batch_size,\n",
    "                    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MAPE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 672    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 33     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d456ea16041c4f029ad271e71b45ef70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4148a4e86e44403d9e2f0f1d3bbd6644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.008941665314196778, 'sle': 0.0005856823571491276, 'rmse': 0.04945003157718137, 'mse': 0.0024453056229842346, 'u1': 0.19102776487670997, 'u2': 0.7528795118640808, 'lr': 0.01, 'input_chunk_length': 20, 'output_chunk_length': 5, 'hidden_size': 8, 'batch_size': 8}\n",
      "Model:  NARX(training=True, prepare_data_per_node=True, allow_zero_length_dataloader_with_multiple_devices=False, n_epochs=200, input_chunk_length=20, output_chunk_length=1, batch_size=8, random_state=0, fit_called=True, optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), window_model=SlidingWindow(input_chunk_length=20, output_chunk_length=1), preprocessing=[MinMaxScaler()], pl_trainer_kwargs={}, hidden_size=32)\n",
      "\n",
      "\n",
      "Best SLE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 672    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 33     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97fdf245f1b54767b35a058eb8984e87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dcbbd0428944d50836128fce26ce291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.008941665314196778, 'sle': 0.0005856823571491276, 'rmse': 0.04945003157718137, 'mse': 0.0024453056229842346, 'u1': 0.19102776487670997, 'u2': 0.7528795118640808, 'lr': 0.01, 'input_chunk_length': 20, 'output_chunk_length': 5, 'hidden_size': 8, 'batch_size': 8}\n",
      "Model:  NARX(training=True, prepare_data_per_node=True, allow_zero_length_dataloader_with_multiple_devices=False, n_epochs=200, input_chunk_length=20, output_chunk_length=1, batch_size=8, random_state=0, fit_called=True, optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), window_model=SlidingWindow(input_chunk_length=20, output_chunk_length=1), preprocessing=[MinMaxScaler()], pl_trainer_kwargs={}, hidden_size=32)\n",
      "\n",
      "\n",
      "Best U1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 672    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 33     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "479a1ae12db94db5a28c868cd4fe37f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3dfe95da1524f4a97833a58455ade55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.012051243799418384, 'sle': 0.0006329794961058757, 'rmse': 0.0511352606352566, 'mse': 0.002614814880235623, 'u1': 0.17516524498652195, 'u2': 0.9520814778316232, 'lr': 0.01, 'input_chunk_length': 20, 'output_chunk_length': 5, 'hidden_size': 8, 'batch_size': 8}\n",
      "Model:  NARX(training=True, prepare_data_per_node=True, allow_zero_length_dataloader_with_multiple_devices=False, n_epochs=200, input_chunk_length=20, output_chunk_length=1, batch_size=8, random_state=0, fit_called=True, optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), window_model=SlidingWindow(input_chunk_length=20, output_chunk_length=1), preprocessing=[MinMaxScaler()], pl_trainer_kwargs={}, hidden_size=32)\n",
      "\n",
      "\n",
      "Best U2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3626/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 672    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 33     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cbeabbdd16f4ea8a1d0cd97996afd5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bd63400183c44efbb76cd6765298333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.014091842223243474, 'sle': 0.001467586086058348, 'rmse': 0.0753398377338885, 'mse': 0.00567609114976865, 'u1': 0.23786027299658152, 'u2': 0.4624666399896742, 'lr': 0.01, 'input_chunk_length': 20, 'output_chunk_length': 5, 'hidden_size': 8, 'batch_size': 8}\n",
      "Model:  NARX(training=True, prepare_data_per_node=True, allow_zero_length_dataloader_with_multiple_devices=False, n_epochs=200, input_chunk_length=20, output_chunk_length=1, batch_size=16, random_state=0, fit_called=True, optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), window_model=SlidingWindow(input_chunk_length=20, output_chunk_length=1), preprocessing=[MinMaxScaler()], pl_trainer_kwargs={}, hidden_size=32)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_narx in [\n",
    "                            {\n",
    "                                'name': 'MAPE',\n",
    "                                'input_chunk_length': min(models_narx, key=lambda d: d['mape'])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_narx, key=lambda d: d['mape'])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_narx, key=lambda d: d['mape'])['hidden_size'],\n",
    "                                'batch_size': min(models_narx, key=lambda d: d['mape'])['batch_size'],\n",
    "                                'lr': min(models_narx, key=lambda d: d['mape'])['lr'],\n",
    "                            },\n",
    "                            {\n",
    "                                'name': 'SLE',\n",
    "                                'input_chunk_length': min(models_narx, key=lambda d: d['sle'])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_narx, key=lambda d: d['sle'])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_narx, key=lambda d: d['sle'])['hidden_size'],\n",
    "                                'batch_size': min(models_narx, key=lambda d: d['sle'])['batch_size'],\n",
    "                                'lr': min(models_narx, key=lambda d: d['sle'])['lr'],\n",
    "                            },\n",
    "                            {\n",
    "                                'name': 'U1',\n",
    "                                'input_chunk_length': min(models_narx, key=lambda d: d['u1'])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_narx, key=lambda d: d['u1'])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_narx, key=lambda d: d['u1'])['hidden_size'],\n",
    "                                'batch_size': min(models_narx, key=lambda d: d['u1'])['batch_size'],\n",
    "                                'lr': min(models_narx, key=lambda d: d['u1'])['lr'],\n",
    "                            },\n",
    "                            {\n",
    "                                'name': 'U2',\n",
    "                                'input_chunk_length': min(models_narx, key=lambda d: d['u2'])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_narx, key=lambda d: d['u2'])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_narx, key=lambda d: d['u2'])['hidden_size'],\n",
    "                                'batch_size': min(models_narx, key=lambda d: d['u2'])['batch_size'],\n",
    "                                'lr': min(models_narx, key=lambda d: d['u2'])['lr'],\n",
    "                            },\n",
    "                        ]:\n",
    "    print('Best', best_model_narx['name'])\n",
    "    model = NARX(\n",
    "        input_chunk_length=best_model_narx['input_chunk_length'],\n",
    "        output_chunk_length=best_model_narx['output_chunk_length'],\n",
    "        hidden_size=best_model_narx['hidden_size'],\n",
    "        batch_size=best_model_narx['batch_size'],\n",
    "        n_epochs=200,\n",
    "        lr=best_model_narx['lr'],\n",
    "        preprocessing = [MinMaxScaler()],\n",
    "        random_state = 0,\n",
    "    )\n",
    "    model.fit([train, soybean_oil.slice(soybean_oil.start_time(), train.end_time())])\n",
    "    metrics = model.evaluate(val)\n",
    "    print({\n",
    "        'mape': metrics['mape'],\n",
    "        'sle': metrics['sle'],\n",
    "        'rmse': metrics['rmse'],\n",
    "        'mse': metrics['mse'],\n",
    "        'u1': metrics['u1'],\n",
    "        'u2': metrics['u2'],\n",
    "        'lr': 10**(-lr),\n",
    "        'input_chunk_length': input_chunk_length,\n",
    "        'output_chunk_length': output_chunk_length,\n",
    "        'hidden_size': 2**hidden_size,\n",
    "        'batch_size': 2**batch_size,\n",
    "    })\n",
    "    print('Model: ', model)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NARX(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        lr=lr,\n",
    "        n_epochs=n_epochs,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NARX(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NARX(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        lr=lr,\n",
    "        n_epochs=n_epochs,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NARX(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando U1 e MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NARX(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        lr=lr,\n",
    "        n_epochs=n_epochs,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_scaled, preds)\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NARX(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4vOQfZh94Fsr"
   },
   "source": [
    "#### Takens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 703
    },
    "id": "82zIFoHt4Ihr",
    "outputId": "d1420d33-465f-4000-84fd-6376a30090b1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 168    | train\n",
      "2 | lin2    | Linear  | 72     | train\n",
      "3 | lin3    | Linear  | 9      | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "249       Trainable params\n",
      "0         Non-trainable params\n",
      "249       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f61813df3d14f78a13d44775da77432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ccca938a9dc4975a02e5b685a6de8ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.013900717681058512, 'sle': 0.001255726207190585, 'rmse': 0.07036815774308455, 'mse': 0.004951677624155631, 'u1': 0.23457052143259993, 'u2': 0.7173478752503417, 'lr': 0.01, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 8, 'batch_size': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 168    | train\n",
      "2 | lin2    | Linear  | 72     | train\n",
      "3 | lin3    | Linear  | 9      | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "249       Trainable params\n",
      "0         Non-trainable params\n",
      "249       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cb51d3ec342488e8776c2cf177981b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1ac36313a8d4ab19262d94c505fddbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.014044513792484784, 'sle': 0.0009043027437784913, 'rmse': 0.06107318712281624, 'mse': 0.0037299341853385274, 'u1': 0.21352648185738712, 'u2': 1.075414933028669, 'lr': 0.001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 8, 'batch_size': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 168    | train\n",
      "2 | lin2    | Linear  | 72     | train\n",
      "3 | lin3    | Linear  | 9      | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "249       Trainable params\n",
      "0         Non-trainable params\n",
      "249       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3884a52dc114d31b09e8dc5f4e684d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "975addd9d8d4406888c9e2dbbe2b5901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.018716042726915752, 'sle': 0.0014984298550116933, 'rmse': 0.07829278500704198, 'mse': 0.006129760184158898, 'u1': 0.2535233263052373, 'u2': 1.4391199166370672, 'lr': 0.0001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 8, 'batch_size': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 168    | train\n",
      "2 | lin2    | Linear  | 72     | train\n",
      "3 | lin3    | Linear  | 9      | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "249       Trainable params\n",
      "0         Non-trainable params\n",
      "249       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a80de8a01cb43d69dc7cae6d5ac0fd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95e0f27f79944b018ebf810654f226c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.013476692812255192, 'sle': 0.0008246647104210664, 'rmse': 0.05777583537875076, 'mse': 0.0033380471537125074, 'u1': 0.1876571043139377, 'u2': 0.9738049380517221, 'lr': 0.01, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 8, 'batch_size': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 168    | train\n",
      "2 | lin2    | Linear  | 72     | train\n",
      "3 | lin3    | Linear  | 9      | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "249       Trainable params\n",
      "0         Non-trainable params\n",
      "249       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93c4b630fe8a4a90992f16568cda0baa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cc54fb3e2e04c9ca38f94fc85c9c3cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.014775976853394091, 'sle': 0.00096516645800122, 'rmse': 0.06302588514731217, 'mse': 0.003972262198602184, 'u1': 0.21659866379699247, 'u2': 1.1230859783710232, 'lr': 0.001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 8, 'batch_size': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 168    | train\n",
      "2 | lin2    | Linear  | 72     | train\n",
      "3 | lin3    | Linear  | 9      | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "249       Trainable params\n",
      "0         Non-trainable params\n",
      "249       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "276e80bbe30c4c0f9a1ed35940d51b9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74032914eeb34148a95d7be69713944d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.01961186878647674, 'sle': 0.0016515720069442041, 'rmse': 0.0822426791912713, 'mse': 0.006763858280558369, 'u1': 0.2560140961820589, 'u2': 1.5456516035878463, 'lr': 0.0001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 8, 'batch_size': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 168    | train\n",
      "2 | lin2    | Linear  | 72     | train\n",
      "3 | lin3    | Linear  | 9      | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "249       Trainable params\n",
      "0         Non-trainable params\n",
      "249       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0fb0368a57649b4a64dcfec745925b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0102673b90384e5c88c80e520bc3a973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.016717846224977927, 'sle': 0.0018239767670485516, 'rmse': 0.08534516149014826, 'mse': 0.007283796589779484, 'u1': 0.3195162086438326, 'u2': 0.8698601085738044, 'lr': 0.01, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 8, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 168    | train\n",
      "2 | lin2    | Linear  | 72     | train\n",
      "3 | lin3    | Linear  | 9      | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "249       Trainable params\n",
      "0         Non-trainable params\n",
      "249       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b55f5c0c37ef4f10826f0564bd437660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a6a0e8cb14f498fb5bcd2d190d4de1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.015261628840057474, 'sle': 0.00124695765613742, 'rmse': 0.07110967814086323, 'mse': 0.0050565863252971625, 'u1': 0.25396820319634705, 'u2': 0.968879463094266, 'lr': 0.001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 8, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 168    | train\n",
      "2 | lin2    | Linear  | 72     | train\n",
      "3 | lin3    | Linear  | 9      | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "249       Trainable params\n",
      "0         Non-trainable params\n",
      "249       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4147394f9a034d56ae8f4da29b50654d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "186213a0e5fb4659a78bda774b925563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.020551523740928133, 'sle': 0.00206548205963617, 'rmse': 0.09071593586466671, 'mse': 0.008229381019802324, 'u1': 0.2746112181418858, 'u2': 1.2693589454524152, 'lr': 0.0001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 8, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 168    | train\n",
      "2 | lin2    | Linear  | 72     | train\n",
      "3 | lin3    | Linear  | 9      | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "249       Trainable params\n",
      "0         Non-trainable params\n",
      "249       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12d5abbcc528461392138abc22488a25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0049546761549ec86aec5a1c56f5a48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.012851126505463911, 'sle': 0.0010820129346683241, 'rmse': 0.06619051233481536, 'mse': 0.004381183923145345, 'u1': 0.24408206262516036, 'u2': 0.7562254053958911, 'lr': 0.01, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 8, 'batch_size': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 168    | train\n",
      "2 | lin2    | Linear  | 72     | train\n",
      "3 | lin3    | Linear  | 9      | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "249       Trainable params\n",
      "0         Non-trainable params\n",
      "249       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c019de254fc40cebbf18ad4a14567de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ace37aa9398f4b74a44f4e656f06f704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.01612170728270363, 'sle': 0.001119140737673099, 'rmse': 0.06775312676979171, 'mse': 0.004590486187083466, 'u1': 0.2250195105211287, 'u2': 1.2465599197401946, 'lr': 0.001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 8, 'batch_size': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 168    | train\n",
      "2 | lin2    | Linear  | 72     | train\n",
      "3 | lin3    | Linear  | 9      | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "249       Trainable params\n",
      "0         Non-trainable params\n",
      "249       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07366445fcf44c6380a2bee7ab05176b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aecd9e9dbe9c4d65bafa57c4f76d8a05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.019517684057709372, 'sle': 0.0026144408587166824, 'rmse': 0.1009683983875713, 'mse': 0.01019461747295131, 'u1': 0.2941743477287048, 'u2': 0.9396397260786008, 'lr': 0.0001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 8, 'batch_size': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 336    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 17     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "625       Trainable params\n",
      "0         Non-trainable params\n",
      "625       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56df2fb7a792408ea715ffff3495e5b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4be0f2123ce34170bbffd4beae8f6b25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.016356976864982744, 'sle': 0.0018035865045614718, 'rmse': 0.08721871827862045, 'mse': 0.007607104818165361, 'u1': 0.25412709324603905, 'u2': 2.0035473347586024, 'lr': 0.01, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 16, 'batch_size': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 336    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 17     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "625       Trainable params\n",
      "0         Non-trainable params\n",
      "625       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a0fd0f0684f4993895cf20db8a4d3f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e93c8b7f1f2f432ab33e76278a5e7f7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.013389899323915384, 'sle': 0.0008681981033347791, 'rmse': 0.05958040102379285, 'mse': 0.003549824186155976, 'u1': 0.2084670466823499, 'u2': 0.939406151173372, 'lr': 0.001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 16, 'batch_size': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 336    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 17     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "625       Trainable params\n",
      "0         Non-trainable params\n",
      "625       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc837606bf564ad58298fbb905c53bd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1ccce484fdc4b958d4c521bf35fe7c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.017486089095487645, 'sle': 0.0013110710570909654, 'rmse': 0.07329856447881224, 'mse': 0.005372679554654594, 'u1': 0.24067186382534814, 'u2': 1.3527756472931887, 'lr': 0.0001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 16, 'batch_size': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 336    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 17     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "625       Trainable params\n",
      "0         Non-trainable params\n",
      "625       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c441e8b6475e437ab30097f7a945e8b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e68f328be8d409a880590996e8834e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.013396214570624496, 'sle': 0.0009498222472110933, 'rmse': 0.06218133787290549, 'mse': 0.0038665187796644305, 'u1': 0.2183000331475353, 'u2': 0.9362930527229362, 'lr': 0.01, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 16, 'batch_size': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 336    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 17     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "625       Trainable params\n",
      "0         Non-trainable params\n",
      "625       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e652beacae324b1b871af527179cbcf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b117093e4e1f4d1ea56e9849df5002fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.014747744459540909, 'sle': 0.0009637044747948464, 'rmse': 0.06288421916651545, 'mse': 0.003954425020182348, 'u1': 0.21571625641439382, 'u2': 1.0872660333355813, 'lr': 0.001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 16, 'batch_size': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 336    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 17     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "625       Trainable params\n",
      "0         Non-trainable params\n",
      "625       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2bec1d0b5ae452383e3ddc1bd15562b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "308e7978890b4c51844b78f317b98f4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.018674706791630295, 'sle': 0.001509457344112385, 'rmse': 0.07862654674339427, 'mse': 0.006182133852791164, 'u1': 0.2494203541515549, 'u2': 1.4963699756620645, 'lr': 0.0001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 16, 'batch_size': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 336    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 17     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "625       Trainable params\n",
      "0         Non-trainable params\n",
      "625       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11aab0750dd940ffa6a018625106545e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fc914c7fe4d4e21bf412d44e01d53b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.025167378744447796, 'sle': 0.003356303103577897, 'rmse': 0.11466083499177288, 'mse': 0.013147107081010568, 'u1': 0.44572652556706466, 'u2': 1.2144265279978839, 'lr': 0.01, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 16, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 336    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 17     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "625       Trainable params\n",
      "0         Non-trainable params\n",
      "625       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1b8683897044e5ca81bb50c10c237e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62657215e5da45f5a4617929a4790b5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.015287370318934297, 'sle': 0.0012632287944411812, 'rmse': 0.07150593083311438, 'mse': 0.005113098144310138, 'u1': 0.2559822136358115, 'u2': 0.9244900855441378, 'lr': 0.001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 16, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 336    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 17     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "625       Trainable params\n",
      "0         Non-trainable params\n",
      "625       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97b5863a659a4691be7952efe062bcbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0250c4ce883a4fc0bf8ac968ce0f5b27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.020285671613297588, 'sle': 0.0018819832629226152, 'rmse': 0.08693654597787558, 'mse': 0.007557963026563273, 'u1': 0.26825725813860624, 'u2': 1.3876614812433297, 'lr': 0.0001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 16, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 336    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 17     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "625       Trainable params\n",
      "0         Non-trainable params\n",
      "625       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04593f2289784fe4b0a2c8007a853bcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62cf0a73316943dfa1c3686d07ffb900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.014420124363667304, 'sle': 0.0012088173637707692, 'rmse': 0.07017161859185314, 'mse': 0.00492405605580051, 'u1': 0.2563515986900003, 'u2': 0.9807910527587491, 'lr': 0.01, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 16, 'batch_size': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 336    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 17     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "625       Trainable params\n",
      "0         Non-trainable params\n",
      "625       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be49f26d1ef841eb82152bec38f07792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ee1670b6a584458bbba6f4000e0d921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.016062853949263538, 'sle': 0.0010852858606983167, 'rmse': 0.0669850828645704, 'mse': 0.004487001326373364, 'u1': 0.21798939131165337, 'u2': 1.336025804394658, 'lr': 0.001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 16, 'batch_size': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 336    | train\n",
      "2 | lin2    | Linear  | 272    | train\n",
      "3 | lin3    | Linear  | 17     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "625       Trainable params\n",
      "0         Non-trainable params\n",
      "625       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d68b9c9c3b1f4e8ca4dac0d3f04f197b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "131bc1398890465a932be66ee1533ee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.02037550274337506, 'sle': 0.0022728263494241597, 'rmse': 0.09488405925850761, 'mse': 0.009002984701371985, 'u1': 0.28053643359280084, 'u2': 1.2754524941590104, 'lr': 0.0001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 16, 'batch_size': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 672    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 33     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b004770f36a43a890f165f75db1dc67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e55a9b37f1294136abecd63939ee4dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.008941665314196778, 'sle': 0.0005856823571491276, 'rmse': 0.04945003157718137, 'mse': 0.0024453056229842346, 'u1': 0.19102776487670997, 'u2': 0.7528795118640808, 'lr': 0.01, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 32, 'batch_size': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 672    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 33     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73be8a126d6643d9ab2f3b3904819013",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b24510b25855435b9fea90992dc88158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.012051243799418384, 'sle': 0.0006329794961058757, 'rmse': 0.0511352606352566, 'mse': 0.002614814880235623, 'u1': 0.17516524498652195, 'u2': 0.9520814778316232, 'lr': 0.001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 32, 'batch_size': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 672    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 33     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5d76b94a4514375a42c7443f6bebd9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac601312ddb94985a7dbfb514c203af9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.01645476450946216, 'sle': 0.0011151512358346933, 'rmse': 0.06763912291667008, 'mse': 0.004575050948936404, 'u1': 0.22320878572064556, 'u2': 1.2184610209412152, 'lr': 0.0001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 32, 'batch_size': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 672    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 33     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adabd45459c641489a1679905b186550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86a12cd977f0415c90e2d8cf236d3a86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.014091842223243474, 'sle': 0.001467586086058348, 'rmse': 0.0753398377338885, 'mse': 0.00567609114976865, 'u1': 0.23786027299658152, 'u2': 0.4624666399896742, 'lr': 0.01, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 32, 'batch_size': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 672    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 33     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "583038051fb74acf90e45fbb8b174236",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33cb3102d1874d008ffce6202312b462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.014948423325169012, 'sle': 0.0009612775721155629, 'rmse': 0.06299762744989958, 'mse': 0.00396870106431634, 'u1': 0.2138990811660067, 'u2': 1.1793303054794402, 'lr': 0.001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 32, 'batch_size': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 672    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 33     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe6ccbe878e44e21b092c016543a8f36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b0f726f95a042d6b2fa84307d89abec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.017620599312573322, 'sle': 0.0012953849498281592, 'rmse': 0.07267794064460802, 'mse': 0.005282083056341166, 'u1': 0.23881911686313903, 'u2': 1.2373967396903538, 'lr': 0.0001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 32, 'batch_size': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 672    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 33     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97a32ff3cedb496db1b6815726e1d9fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d04ae6d560d7478eaecaa1f933f6b686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.013822999327244756, 'sle': 0.0009381608633388278, 'rmse': 0.062037603977472384, 'mse': 0.0038486643072656976, 'u1': 0.19130228491616857, 'u2': 1.242407692691864, 'lr': 0.01, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 32, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 672    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 33     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30168f3a2b304c30be48330cfb6d0bfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af76e6be50564e6098503ff5644797b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.01536882719860605, 'sle': 0.0013838010522177493, 'rmse': 0.07473936935490941, 'mse': 0.005585973331569571, 'u1': 0.2713320000640427, 'u2': 0.8924359563397651, 'lr': 0.001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 32, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 672    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 33     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dae1384353bd4af79a7d90f117c1b651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f749a30be3a04ef1a05d2002876b6df9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.019446693709673588, 'sle': 0.0015753846899324976, 'rmse': 0.08015049001734473, 'mse': 0.006424101050020476, 'u1': 0.2555041651503179, 'u2': 1.40439895074094, 'lr': 0.0001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 32, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 672    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 33     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a574559a6074cbba02f9aeda33fea4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1532ab5be0a540969e3ee976bff05867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.013160143441917516, 'sle': 0.000780715541848073, 'rmse': 0.05652047802577549, 'mse': 0.00319456443626217, 'u1': 0.19515618458593664, 'u2': 0.9103008446681001, 'lr': 0.01, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 32, 'batch_size': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 672    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 33     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95240f8b1e824bec97c9e63e47b820f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39c38e7b726c4c2fad47339ca0ecf967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.014943869710998932, 'sle': 0.000980626062807197, 'rmse': 0.06331572923467486, 'mse': 0.004008881568518661, 'u1': 0.21886729393558932, 'u2': 0.9913482065126678, 'lr': 0.001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 32, 'batch_size': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 672    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 33     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3ab7099d5d64a74887fb1e039987125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "148ec30ea3eb4748a6fa54681f5603d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.02069639853867583, 'sle': 0.0019814721818604995, 'rmse': 0.08880783152801411, 'mse': 0.007886830940708136, 'u1': 0.28398500876750044, 'u2': 1.1873699782969986, 'lr': 0.0001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 32, 'batch_size': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 1.3 K  | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 65     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "5.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.6 K     Total params\n",
      "0.022     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0474b48bc914f1fa3dff1199074bd31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf432e5391c74ed6b310e17b32bf4f19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.06583904881823543, 'sle': 0.020161766885958977, 'rmse': 0.2762186331463289, 'mse': 0.07629673329722622, 'u1': 1.1399894350971338, 'u2': 3.714752344886803, 'lr': 0.01, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 64, 'batch_size': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 1.3 K  | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 65     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "5.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.6 K     Total params\n",
      "0.022     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "605a80c36b9142239d956d4c6d5a91bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2622f83a5834948a2ba2602cbc2e9b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.011786147863618056, 'sle': 0.0006220616568288808, 'rmse': 0.0505471709881486, 'mse': 0.002555016494905132, 'u1': 0.17659776816436135, 'u2': 0.7933945623009397, 'lr': 0.001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 64, 'batch_size': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 1.3 K  | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 65     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "5.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.6 K     Total params\n",
      "0.022     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f06722763cb419ab81df15afc97546f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db75834f3dde46efae375fd379791e43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.015277359038092105, 'sle': 0.00096531825048369, 'rmse': 0.06308341905235301, 'mse': 0.003979517759334775, 'u1': 0.21107960518951888, 'u2': 1.169735482194199, 'lr': 0.0001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 64, 'batch_size': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 1.3 K  | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 65     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "5.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.6 K     Total params\n",
      "0.022     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7558da9f49aa42dba888e278d21499f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "204db666d0fc48ab85d9e57ae36042e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.0553637283672569, 'sle': 0.013153702628951967, 'rmse': 0.22670702551648414, 'mse': 0.051396075418531785, 'u1': 1.0759549814680651, 'u2': 3.996473207833402, 'lr': 0.01, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 64, 'batch_size': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 1.3 K  | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 65     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "5.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.6 K     Total params\n",
      "0.022     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8fc8f7b7ad54a3091d2e4918533ed7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03a286d6f60540a9bfdc5ee4c48198df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.01405690416906375, 'sle': 0.0008676392539843317, 'rmse': 0.06002707174938286, 'mse': 0.0036032493428055585, 'u1': 0.20489310454747617, 'u2': 1.1693668587809443, 'lr': 0.001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 64, 'batch_size': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 1.3 K  | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 65     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "5.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.6 K     Total params\n",
      "0.022     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17fee445df6545d28628146eaa36bd43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbbd55aa483f4b8da7c4968fd813c181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.015345977240474047, 'sle': 0.0010511463596229102, 'rmse': 0.06544066607304726, 'mse': 0.004282480776084078, 'u1': 0.22488416049768337, 'u2': 1.0112441908835283, 'lr': 0.0001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 64, 'batch_size': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 1.3 K  | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 65     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "5.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.6 K     Total params\n",
      "0.022     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eec889349cda46eaa2eda0e050bbff64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fefa398a7704930bc9a4c93a133c73c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.03899729639260006, 'sle': 0.006479158324479067, 'rmse': 0.15962580044121072, 'mse': 0.025480396166497228, 'u1': 0.701386185256128, 'u2': 2.5595846465785974, 'lr': 0.01, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 64, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 1.3 K  | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 65     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "5.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.6 K     Total params\n",
      "0.022     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "333e2e28ebbb44ac9ff26fa2f460fbe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3efca5a125474a5a95137a8b0c061ab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.014842608944254768, 'sle': 0.0014780139053617255, 'rmse': 0.07732901551597533, 'mse': 0.005979776640669953, 'u1': 0.28942630437938627, 'u2': 0.9194201279095952, 'lr': 0.001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 64, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 1.3 K  | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 65     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "5.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.6 K     Total params\n",
      "0.022     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07bb7477f4864056a96307e360015215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae0d85c9541b42d7a765a89142d2fc0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.015938141092943822, 'sle': 0.0010573453808601974, 'rmse': 0.06596625326232342, 'mse': 0.004351546569468994, 'u1': 0.21641150583380708, 'u2': 1.252811305800067, 'lr': 0.0001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 64, 'batch_size': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 1.3 K  | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 65     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "5.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.6 K     Total params\n",
      "0.022     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1b7cd3da14a4b7cacf96eb6d5cf7f21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eaba9856d954978901412a5e91e31e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.013072119386266042, 'sle': 0.0010384834196567082, 'rmse': 0.06511341346094802, 'mse': 0.004239756612536367, 'u1': 0.24324893323837293, 'u2': 0.8446584647207325, 'lr': 0.01, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 64, 'batch_size': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 1.3 K  | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 65     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "5.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.6 K     Total params\n",
      "0.022     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "998ab29e314144bea3bc0defde258203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd85e5330a5a4059acacef60b0bf795f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.01497071843836853, 'sle': 0.0010097691520916888, 'rmse': 0.0642127634683229, 'mse': 0.0041232789922387835, 'u1': 0.22352793604110888, 'u2': 0.976900450687613, 'lr': 0.001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 64, 'batch_size': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 1.3 K  | train\n",
      "2 | lin2    | Linear  | 4.2 K  | train\n",
      "3 | lin3    | Linear  | 65     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "5.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.6 K     Total params\n",
      "0.022     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "293d58ee579740a2b9806c7c468fbcd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06ee2496a70340a7a5fe73da57940437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.01635210675542626, 'sle': 0.0012207313804693557, 'rmse': 0.07025925427705046, 'mse': 0.004936362811567233, 'u1': 0.23647529721537916, 'u2': 1.0607210185637075, 'lr': 0.0001, 'input_chunk_length': 20, 'output_chunk_length': 1, 'takens_tau': 1, 'hidden_size': 64, 'batch_size': 64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 168    | train\n",
      "2 | lin2    | Linear  | 72     | train\n",
      "3 | lin3    | Linear  | 45     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "285       Trainable params\n",
      "0         Non-trainable params\n",
      "285       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ca452e5f51b4e15b92267354091cead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efe7d5c8a73d47809708272a924639e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 21\u001b[0m\n\u001b[1;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m NARX(\n\u001b[1;32m     10\u001b[0m     input_chunk_length\u001b[38;5;241m=\u001b[39minput_chunk_length,\n\u001b[1;32m     11\u001b[0m     output_chunk_length\u001b[38;5;241m=\u001b[39moutput_chunk_length,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     20\u001b[0m model\u001b[38;5;241m.\u001b[39mfit([train, soybean_oil\u001b[38;5;241m.\u001b[39mslice(soybean_oil\u001b[38;5;241m.\u001b[39mstart_time(), train\u001b[38;5;241m.\u001b[39mend_time())])\n\u001b[0;32m---> 21\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m({\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmape\u001b[39m\u001b[38;5;124m'\u001b[39m: metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmape\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msle\u001b[39m\u001b[38;5;124m'\u001b[39m: metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msle\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbatch_size,\n\u001b[1;32m     35\u001b[0m })\n\u001b[1;32m     36\u001b[0m models_narx\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmape\u001b[39m\u001b[38;5;124m'\u001b[39m: metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmape\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msle\u001b[39m\u001b[38;5;124m'\u001b[39m: metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msle\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbatch_size,\n\u001b[1;32m     49\u001b[0m })\n",
      "File \u001b[0;32m~/Documentos/Projeto-da-Graduacao/classes/models/torch_generic_model.py:308\u001b[0m, in \u001b[0;36mTorchGenericModel.evaluate\u001b[0;34m(self, val)\u001b[0m\n\u001b[1;32m    304\u001b[0m         predicted_outputs\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m    305\u001b[0m         progress_bar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m--> 308\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmape\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mmape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_outputs_original\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m\"\u001b[39m: mse([i[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m val], predicted_outputs_original),\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m\"\u001b[39m: rmse([i[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m val], predicted_outputs_original),\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msle\u001b[39m\u001b[38;5;124m\"\u001b[39m: sle([i[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m val], predicted_outputs_original),\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mu1\u001b[39m\u001b[38;5;124m\"\u001b[39m: UTheil()\u001b[38;5;241m.\u001b[39mcalculateU1([i[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m val_scaled], predicted_outputs),\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mu2\u001b[39m\u001b[38;5;124m\"\u001b[39m: UTheil()\u001b[38;5;241m.\u001b[39mcalculateU2([i[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m val_scaled], predicted_outputs),\n\u001b[1;32m    314\u001b[0m }\n",
      "File \u001b[0;32m~/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/sklearn/metrics/_regression.py:399\u001b[0m, in \u001b[0;36mmean_absolute_percentage_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m    322\u001b[0m     {\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    331\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    332\u001b[0m ):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Mean absolute percentage error (MAPE) regression loss.\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \n\u001b[1;32m    335\u001b[0m \u001b[38;5;124;03m    Note here that the output is not a percentage in the range [0, 100]\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;124;03m    112589990684262.48\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 399\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    402\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    403\u001b[0m     epsilon \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfinfo(np\u001b[38;5;241m.\u001b[39mfloat64)\u001b[38;5;241m.\u001b[39meps\n",
      "File \u001b[0;32m~/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/sklearn/metrics/_regression.py:112\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype, xp)\u001b[0m\n\u001b[1;32m    109\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred, multioutput, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[1;32m    111\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m--> 112\u001b[0m y_true \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/sklearn/utils/validation.py:1082\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1080\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[1;32m   1081\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[0;32m-> 1082\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1085\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[1;32m   1086\u001b[0m         )\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m   1089\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "models_narx = []\n",
    "\n",
    "for input_chunk_length in range(20, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "       for hidden_size in range(3, 7):\n",
    "           for batch_size in range(3, 7):\n",
    "               for lr in range(2, 5):\n",
    "                   for takens_tau in range(1,len(train)//(input_chunk_length - 1)):\n",
    "                        model = NARX(\n",
    "                            input_chunk_length=input_chunk_length,\n",
    "                            output_chunk_length=output_chunk_length,\n",
    "                            hidden_size=2**hidden_size,\n",
    "                            batch_size=2**batch_size,\n",
    "                            n_epochs=200,\n",
    "                            lr=10**(-lr),\n",
    "                            window_model = Takens(tau=takens_tau),\n",
    "                            preprocessing = [MinMaxScaler()],\n",
    "                            random_state = 0,\n",
    "                        )\n",
    "                        model.fit([train, soybean_oil.slice(soybean_oil.start_time(), train.end_time())])\n",
    "                        metrics = model.evaluate(val)\n",
    "                        print({\n",
    "                            'mape': metrics['mape'],\n",
    "                            'sle': metrics['sle'],\n",
    "                            'rmse': metrics['rmse'],\n",
    "                            'mse': metrics['mse'],\n",
    "                            'u1': metrics['u1'],\n",
    "                            'u2': metrics['u2'],\n",
    "                            'lr': 10**(-lr),\n",
    "                            'input_chunk_length': input_chunk_length,\n",
    "                            'output_chunk_length': output_chunk_length,\n",
    "                            'takens_tau': takens_tau,\n",
    "                            'hidden_size': 2**hidden_size,\n",
    "                            'batch_size': 2**batch_size,\n",
    "                        })\n",
    "                        models_narx.append({\n",
    "                            'mape': metrics['mape'],\n",
    "                            'sle': metrics['sle'],\n",
    "                            'rmse': metrics['rmse'],\n",
    "                            'mse': metrics['mse'],\n",
    "                            'u1': metrics['u1'],\n",
    "                            'u2': metrics['u2'],\n",
    "                            'lr': 10**(-lr),\n",
    "                            'input_chunk_length': input_chunk_length,\n",
    "                            'output_chunk_length': output_chunk_length,\n",
    "                            'hidden_size': 2**hidden_size,\n",
    "                            'takens_tau': takens_tau,\n",
    "                            'batch_size': 2**batch_size,\n",
    "                        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MAPE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 672    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 33     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "412c4678df16490e8f3919e3e50dca24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30a31112d3b44223b19dbb84b9ddbecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.008941665314196778, 'sle': 0.0005856823571491276, 'rmse': 0.04945003157718137, 'mse': 0.0024453056229842346, 'u1': 0.19102776487670997, 'u2': 0.7528795118640808, 'lr': 0.01, 'input_chunk_length': 20, 'output_chunk_length': 5, 'hidden_size': 8, 'batch_size': 8}\n",
      "Model:  NARX(training=True, prepare_data_per_node=True, allow_zero_length_dataloader_with_multiple_devices=False, n_epochs=200, input_chunk_length=20, output_chunk_length=1, batch_size=8, random_state=0, fit_called=True, optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), window_model=Takens(input_chunk_length=20, output_chunk_length=1, tau=1), preprocessing=[MinMaxScaler()], pl_trainer_kwargs={}, hidden_size=32)\n",
      "\n",
      "\n",
      "Best SLE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 672    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 33     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "690d7dd9cae04d6c803096329349ed81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1afaf0f27836491492462601118cc08f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.008941665314196778, 'sle': 0.0005856823571491276, 'rmse': 0.04945003157718137, 'mse': 0.0024453056229842346, 'u1': 0.19102776487670997, 'u2': 0.7528795118640808, 'lr': 0.01, 'input_chunk_length': 20, 'output_chunk_length': 5, 'hidden_size': 8, 'batch_size': 8}\n",
      "Model:  NARX(training=True, prepare_data_per_node=True, allow_zero_length_dataloader_with_multiple_devices=False, n_epochs=200, input_chunk_length=20, output_chunk_length=1, batch_size=8, random_state=0, fit_called=True, optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), window_model=Takens(input_chunk_length=20, output_chunk_length=1, tau=1), preprocessing=[MinMaxScaler()], pl_trainer_kwargs={}, hidden_size=32)\n",
      "\n",
      "\n",
      "Best U1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 672    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 33     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aee0d3643f84061a61751a4163ee980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "126b449b11044da78860f4773a5f1353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.012051243799418384, 'sle': 0.0006329794961058757, 'rmse': 0.0511352606352566, 'mse': 0.002614814880235623, 'u1': 0.17516524498652195, 'u2': 0.9520814778316232, 'lr': 0.01, 'input_chunk_length': 20, 'output_chunk_length': 5, 'hidden_size': 8, 'batch_size': 8}\n",
      "Model:  NARX(training=True, prepare_data_per_node=True, allow_zero_length_dataloader_with_multiple_devices=False, n_epochs=200, input_chunk_length=20, output_chunk_length=1, batch_size=8, random_state=0, fit_called=True, optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), window_model=Takens(input_chunk_length=20, output_chunk_length=1, tau=1), preprocessing=[MinMaxScaler()], pl_trainer_kwargs={}, hidden_size=32)\n",
      "\n",
      "\n",
      "Best U2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/home/ellizeu.sena/Documentos/Projeto-da-Graduacao/venv/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/ellizeu.sena/Documentos/Projeto-da-Graduacao/lightning_logs/version_3657/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | loss_fn | MSELoss | 0      | train\n",
      "1 | lin     | Linear  | 672    | train\n",
      "2 | lin2    | Linear  | 1.1 K  | train\n",
      "3 | lin3    | Linear  | 33     | train\n",
      "4 | tanh    | Tanh    | 0      | train\n",
      "--------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f0e14e072944225b125dc5a326c25ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2881a3c7b1b43d39f2ec4c7ffae6eb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mape': 0.014091842223243474, 'sle': 0.001467586086058348, 'rmse': 0.0753398377338885, 'mse': 0.00567609114976865, 'u1': 0.23786027299658152, 'u2': 0.4624666399896742, 'lr': 0.01, 'input_chunk_length': 20, 'output_chunk_length': 5, 'hidden_size': 8, 'batch_size': 8}\n",
      "Model:  NARX(training=True, prepare_data_per_node=True, allow_zero_length_dataloader_with_multiple_devices=False, n_epochs=200, input_chunk_length=20, output_chunk_length=1, batch_size=16, random_state=0, fit_called=True, optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), window_model=Takens(input_chunk_length=20, output_chunk_length=1, tau=1), preprocessing=[MinMaxScaler()], pl_trainer_kwargs={}, hidden_size=32)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_narx in [\n",
    "                            {\n",
    "                                'name': 'MAPE',\n",
    "                                'input_chunk_length': min(models_narx, key=lambda d: d['mape'])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_narx, key=lambda d: d['mape'])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_narx, key=lambda d: d['mape'])['hidden_size'],\n",
    "                                'batch_size': min(models_narx, key=lambda d: d['mape'])['batch_size'],\n",
    "                                'lr': min(models_narx, key=lambda d: d['mape'])['lr'],\n",
    "                                'takens_tau': min(models_narx, key=lambda d: d['mape'])['takens_tau'],\n",
    "                            },\n",
    "                            {\n",
    "                                'name': 'SLE',\n",
    "                                'input_chunk_length': min(models_narx, key=lambda d: d['sle'])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_narx, key=lambda d: d['sle'])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_narx, key=lambda d: d['sle'])['hidden_size'],\n",
    "                                'batch_size': min(models_narx, key=lambda d: d['sle'])['batch_size'],\n",
    "                                'lr': min(models_narx, key=lambda d: d['sle'])['lr'],\n",
    "                                'takens_tau': min(models_narx, key=lambda d: d['sle'])['takens_tau'],\n",
    "                            },\n",
    "                            {\n",
    "                                'name': 'U1',\n",
    "                                'input_chunk_length': min(models_narx, key=lambda d: d['u1'])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_narx, key=lambda d: d['u1'])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_narx, key=lambda d: d['u1'])['hidden_size'],\n",
    "                                'batch_size': min(models_narx, key=lambda d: d['u1'])['batch_size'],\n",
    "                                'lr': min(models_narx, key=lambda d: d['u1'])['lr'],\n",
    "                                'takens_tau': min(models_narx, key=lambda d: d['u1'])['takens_tau'],\n",
    "                            },\n",
    "                            {\n",
    "                                'name': 'U2',\n",
    "                                'input_chunk_length': min(models_narx, key=lambda d: d['u2'])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_narx, key=lambda d: d['u2'])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_narx, key=lambda d: d['u2'])['hidden_size'],\n",
    "                                'batch_size': min(models_narx, key=lambda d: d['u2'])['batch_size'],\n",
    "                                'lr': min(models_narx, key=lambda d: d['u2'])['lr'],\n",
    "                                'takens_tau': min(models_narx, key=lambda d: d['u2'])['takens_tau'],\n",
    "                            },\n",
    "                        ]:\n",
    "    print('Best', best_model_narx['name'])\n",
    "    model = NARX(\n",
    "        input_chunk_length=best_model_narx['input_chunk_length'],\n",
    "        output_chunk_length=best_model_narx['output_chunk_length'],\n",
    "        hidden_size=best_model_narx['hidden_size'],\n",
    "        batch_size=best_model_narx['batch_size'],\n",
    "        lr=best_model_narx['lr'],\n",
    "        window_model = Takens(tau=best_model_narx['takens_tau']),\n",
    "        n_epochs=200,\n",
    "        preprocessing = [MinMaxScaler()],\n",
    "        random_state = 0,\n",
    "    )\n",
    "    model.fit([train, soybean_oil.slice(soybean_oil.start_time(), train.end_time())])\n",
    "    metrics = model.evaluate(val)\n",
    "    print({\n",
    "        'mape': metrics['mape'],\n",
    "        'sle': metrics['sle'],\n",
    "        'rmse': metrics['rmse'],\n",
    "        'mse': metrics['mse'],\n",
    "        'u1': metrics['u1'],\n",
    "        'u2': metrics['u2'],\n",
    "        'lr': 10**(-lr),\n",
    "        'input_chunk_length': input_chunk_length,\n",
    "        'output_chunk_length': output_chunk_length,\n",
    "        'hidden_size': 2**hidden_size,\n",
    "        'batch_size': 2**batch_size,\n",
    "    })\n",
    "    print('Model: ', model)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, 3)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NARX(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        lr=lr,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        n_epochs=n_epochs,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NARX(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, 3)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NARX(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        lr=lr,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        n_epochs=n_epochs,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NARX(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando U2 e MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, 3)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NARX(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        lr=lr,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        n_epochs=n_epochs,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_scaled, preds)\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NARX(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DA-RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brasil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Janela Deslizante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_da_rnn = []\n",
    "\n",
    "for num_heads_attention in range(2,7):\n",
    "    for dropout in [i/100 for i in range(0,20,5)]:\n",
    "        for output_chunk_length in range(1, 20, 4):\n",
    "            for input_chunk_length in range(22, 30, 2):\n",
    "               for hidden_size in [2**i for i in range(3, 7)]:\n",
    "                   for batch_size in [2**i for i in range(3, 7)]:\n",
    "                       for lr in [10**(-i) for i in range(2, 5)]:\n",
    "                            try:\n",
    "                                model = DA_RNN(\n",
    "                                    input_chunk_length=input_chunk_length,\n",
    "                                    output_chunk_length=output_chunk_length,\n",
    "                                    hidden_size=hidden_size,\n",
    "                                    batch_size=batch_size,\n",
    "                                    num_heads_attention=num_heads_attention,\n",
    "                                    dropout=dropout,\n",
    "                                    n_epochs=400,\n",
    "                                    lr=lr,\n",
    "                                    device=\"cuda\",\n",
    "                                    random_state = 0\n",
    "                                )\n",
    "                                model.fit(train, val)\n",
    "                                metrics = model.evaluate(val)\n",
    "                                print({\n",
    "                                    'mape': metrics['mape'],\n",
    "                                    'sle': metrics['sle'],\n",
    "                                    'u1': u1_da_rnn,\n",
    "                                    'u2': u1_da_rnn,\n",
    "                                    'lr': lr,\n",
    "                                    'input_chunk_length': input_chunk_length,\n",
    "                                    'output_chunk_length': output_chunk_length,\n",
    "                                    'hidden_size': hidden_size,\n",
    "                                    'batch_size': batch_size,\n",
    "                                    'num_heads_attention': num_heads_attention,\n",
    "                                    'dropout': dropout,\n",
    "                                })\n",
    "                                models_da_rnn.append({\n",
    "                                    'mape': metrics['mape'],\n",
    "                                    'sle': metrics['sle'],\n",
    "                                    'u1': u1_da_rnn,\n",
    "                                    'u2': u1_da_rnn,\n",
    "                                    'lr': lr,\n",
    "                                    'input_chunk_length': input_chunk_length,\n",
    "                                    'output_chunk_length': output_chunk_length,\n",
    "                                    'hidden_size': hidden_size,\n",
    "                                    'batch_size': batch_size,\n",
    "                                    'num_heads_attention': num_heads_attention,\n",
    "                                    'dropout': dropout,\n",
    "                                })\n",
    "                            except:\n",
    "                                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_da_rnn in [\n",
    "                            {\n",
    "                                'name': 'MAPE',\n",
    "                                'input_chunk_length': min(models_da_rnn, key=lambda d: d['mape'])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_da_rnn, key=lambda d: d['mape'])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_da_rnn, key=lambda d: d['mape'])['hidden_size'],\n",
    "                                'batch_size': min(models_da_rnn, key=lambda d: d['mape'])['batch_size'],\n",
    "                                'lr': min(models_da_rnn, key=lambda d: d['mape'])['lr'],\n",
    "                                'num_heads_attention': min(models_da_rnn, key=lambda d: d['mape'])['num_heads_attention'],\n",
    "                                'dropout': min(models_da_rnn, key=lambda d: d['mape'])['dropout'],\n",
    "                            },\n",
    "                            {\n",
    "                                'name': 'SLE',\n",
    "                                'input_chunk_length': min(models_da_rnn, key=lambda d: d['sle'])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_da_rnn, key=lambda d: d['sle'])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_da_rnn, key=lambda d: d['sle'])['hidden_size'],\n",
    "                                'batch_size': min(models_da_rnn, key=lambda d: d['sle'])['batch_size'],\n",
    "                                'lr': min(models_da_rnn, key=lambda d: d['sle'])['lr'],\n",
    "                                'num_heads_attention': min(models_da_rnn, key=lambda d: d['sle'])['num_heads_attention'],\n",
    "                                'dropout': min(models_da_rnn, key=lambda d: d['sle'])['dropout'],\n",
    "                            },\n",
    "                            {\n",
    "                                'name': 'U1',\n",
    "                                'input_chunk_length': min(models_da_rnn, key=lambda d: d['u1'])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_da_rnn, key=lambda d: d['u1'])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_da_rnn, key=lambda d: d['u1'])['hidden_size'],\n",
    "                                'batch_size': min(models_da_rnn, key=lambda d: d['u1'])['batch_size'],\n",
    "                                'lr': min(models_da_rnn, key=lambda d: d['u1'])['lr'],\n",
    "                                'num_heads_attention': min(models_da_rnn, key=lambda d: d['u1'])['num_heads_attention'],\n",
    "                                'dropout': min(models_da_rnn, key=lambda d: d['u1'])['dropout'],\n",
    "                            },\n",
    "                            {\n",
    "                                'name': 'U2',\n",
    "                                'input_chunk_length': min(models_da_rnn, key=lambda d: d['u2'])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_da_rnn, key=lambda d: d['u2'])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_da_rnn, key=lambda d: d['u2'])['hidden_size'],\n",
    "                                'batch_size': min(models_da_rnn, key=lambda d: d['u2'])['batch_size'],\n",
    "                                'lr': min(models_da_rnn, key=lambda d: d['u2'])['lr'],\n",
    "                                'num_heads_attention': min(models_da_rnn, key=lambda d: d['u2'])['num_heads_attention'],\n",
    "                                'dropout': min(models_da_rnn, key=lambda d: d['u2'])['dropout'],\n",
    "                            },\n",
    "                        ]:\n",
    "    print('Best', best_model_da_rnn['name'])\n",
    "    model = DA_RNN(\n",
    "        input_chunk_length=best_model_da_rnn['input_chunk_length'],\n",
    "        output_chunk_length=best_model_da_rnn['output_chunk_length'],\n",
    "        hidden_size=best_model_da_rnn['hidden_size'],\n",
    "        batch_size=best_model_da_rnn['batch_size'],\n",
    "        lr=best_model_da_rnn['lr'],\n",
    "        num_heads_attention=best_model_da_rnn['num_heads_attention'],\n",
    "        dropout=best_model_da_rnn['dropout'],\n",
    "        n_epochs=400,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit(train_scaled)\n",
    "    pred_series, mape_da_rnn, sle_da_rnn = eval_model(\n",
    "        model,\n",
    "        len(val_scaled),\n",
    "        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_scaled,\n",
    "        target_series = train_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_da_rnn = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "    u2_da_rnn = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_da_rnn)\n",
    "    print('U2: ', u2_da_rnn)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    num_heads_attention = trial.suggest_int(\"num_heads_attention\", 0, 2)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.2)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = DA_RNN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        num_heads_attention=2**num_heads_attention,\n",
    "        dropout=dropout,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DA_RNN(\n",
    "    input_chunk_length=29,\n",
    "    output_chunk_length=2,\n",
    "    hidden_size=2**3,\n",
    "    batch_size=2**7,\n",
    "    num_heads_attention=2**0,\n",
    "    dropout=0.02818752616036449,\n",
    "    n_epochs=722,\n",
    "    lr=5.8838406863956746e-05,\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    num_heads_attention = trial.suggest_int(\"num_heads_attention\", 0, 2)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.2)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = DA_RNN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        num_heads_attention=2**num_heads_attention,\n",
    "        dropout=dropout,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DA_RNN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    num_heads_attention=2**study.best_trial.params['num_heads_attention'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando U2 e MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    num_heads_attention = trial.suggest_int(\"num_heads_attention\", 0, 2)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.2)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = DA_RNN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        num_heads_attention=2**num_heads_attention,\n",
    "        dropout=dropout,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_scaled, preds)\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DA_RNN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    num_heads_attention=2**study.best_trial.params['num_heads_attention'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Takens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Depois de mais de 1h os resultados ficaram ruins\n",
    "## Alterei a GRID para diminuir os parâmetros e continuou ruim\n",
    "models_da_rnn = []\n",
    "\n",
    "for input_chunk_length in range(24, 38, 2):\n",
    "    for output_chunk_length in range(1, 3):\n",
    "        for dropout in [i/100 for i in range(0,20,5)]:\n",
    "            for hidden_size in [2**i for i in range(3, 7)]:\n",
    "                for batch_size in [2**i for i in range(3, 7)]:\n",
    "                    for lr in [10**(-i) for i in range(2, 5)]:\n",
    "                        for takens_tau in range(1, len(train)//(input_chunk_length - 1)):\n",
    "                            for num_heads_attention in [2**i for i in range(4)]:\n",
    "                                try:\n",
    "                                    model = DA_RNN(\n",
    "                                        input_chunk_length=input_chunk_length,\n",
    "                                        output_chunk_length=output_chunk_length,\n",
    "                                        hidden_size=hidden_size,\n",
    "                                        batch_size=batch_size,\n",
    "                                        num_heads_attention=num_heads_attention,\n",
    "                                        dropout=dropout,\n",
    "                                        n_epochs=400,\n",
    "                                        window_model = Takens(tau=takens_tau),\n",
    "                                        lr=lr,\n",
    "                                        device=\"cuda\",\n",
    "                                        random_state = 0\n",
    "                                    )\n",
    "                                    model.fit(train_scaled)\n",
    "                                    pred_series, mape_da_rnn, sle_da_rnn = eval_model(\n",
    "                                        model,\n",
    "                                        len(val_scaled),\n",
    "                                        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                        val_scaled,\n",
    "                                        target_series = train_scaled,\n",
    "                                        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                        plot = False,\n",
    "                                    )\n",
    "                                    uTheil = UTheil()\n",
    "                                    u1_da_rnn = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "                                    u2_da_rnn = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "                                    print({\n",
    "                                        'MAPE': mape_da_rnn,\n",
    "                                        'SLE': sle_da_rnn,\n",
    "                                        'U1': u1_da_rnn,\n",
    "                                        'U2': u1_da_rnn,\n",
    "                                        'input_chunk_length': input_chunk_length,\n",
    "                                        'output_chunk_length': output_chunk_length,\n",
    "                                        'hidden_size': hidden_size,\n",
    "                                        'batch_size': batch_size,\n",
    "                                        'num_heads_attention': num_heads_attention,\n",
    "                                        'dropout': dropout,\n",
    "                                        'lr': lr,\n",
    "                                        'takens_tau': takens_tau,\n",
    "                                    })\n",
    "                                    models_da_rnn.append({\n",
    "                                        'MAPE': mape_da_rnn,\n",
    "                                        'SLE': sle_da_rnn,\n",
    "                                        'U1': u1_da_rnn,\n",
    "                                        'U2': u1_da_rnn,\n",
    "                                        'input_chunk_length': input_chunk_length,\n",
    "                                        'output_chunk_length': output_chunk_length,\n",
    "                                        'hidden_size': hidden_size,\n",
    "                                        'batch_size': batch_size,\n",
    "                                        'num_heads_attention': num_heads_attention,\n",
    "                                        'dropout': dropout,\n",
    "                                        'takens_tau': takens_tau,\n",
    "                                        'lr': lr,\n",
    "                                    })\n",
    "                                except:\n",
    "                                    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    num_heads_attention = trial.suggest_int(\"num_heads_attention\", 0, 2)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(in_len - 1))\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.2)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = DA_RNN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        num_heads_attention=2**num_heads_attention,\n",
    "        dropout=dropout,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DA_RNN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    num_heads_attention=2**study.best_trial.params['num_heads_attention'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    num_heads_attention = trial.suggest_int(\"num_heads_attention\", 0, 2)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(in_len - 1))\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.2)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = DA_RNN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        num_heads_attention=2**num_heads_attention,\n",
    "        dropout=dropout,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DA_RNN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    num_heads_attention=2**study.best_trial.params['num_heads_attention'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando U2 e MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    num_heads_attention = trial.suggest_int(\"num_heads_attention\", 0, 2)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(in_len - 1))\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.2)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = DA_RNN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        num_heads_attention=2**num_heads_attention,\n",
    "        dropout=dropout,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_scaled, preds)\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DA_RNN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    num_heads_attention=2**study.best_trial.params['num_heads_attention'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Brasil (detrend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Janela Deslizante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_da_rnn = []\n",
    "\n",
    "for num_heads_attention in range(2,7):\n",
    "    for dropout in [i/100 for i in range(0,20,5)]:\n",
    "        for output_chunk_length in range(1, 20, 4):\n",
    "            for input_chunk_length in range(22, 30, 2):\n",
    "               for hidden_size in [2**i for i in range(3, 7)]:\n",
    "                   for batch_size in [2**i for i in range(3, 7)]:\n",
    "                       for lr in [10**(-i) for i in range(2, 5)]:\n",
    "                            try:\n",
    "                                model = DA_RNN(\n",
    "                                    input_chunk_length=input_chunk_length,\n",
    "                                    output_chunk_length=output_chunk_length,\n",
    "                                    hidden_size=hidden_size,\n",
    "                                    batch_size=batch_size,\n",
    "                                    num_heads_attention=num_heads_attention,\n",
    "                                    dropout=dropout,\n",
    "                                    n_epochs=400,\n",
    "                                    lr=lr,\n",
    "                                    device=\"cuda\",\n",
    "                                    random_state = 0\n",
    "                                )\n",
    "                                model.fit(train_detrend_scaled)\n",
    "                                pred_series, mape_da_rnn, sle_da_rnn = eval_model(\n",
    "                                    model,\n",
    "                                    len(val_detrend_scaled),\n",
    "                                    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                    val_detrend_scaled,\n",
    "                                    target_series = train_detrend_scaled,\n",
    "                                    returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                    plot = False,\n",
    "                                )\n",
    "                                uTheil = UTheil()\n",
    "                                u1_da_rnn = uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)])\n",
    "                                u2_da_rnn = uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)])\n",
    "                                print({\n",
    "                                    'mape': mape_da_rnn,\n",
    "                                    'sle': sle_da_rnn,\n",
    "                                    'u1': u1_da_rnn,\n",
    "                                    'u2': u1_da_rnn,\n",
    "                                    'lr': lr,\n",
    "                                    'input_chunk_length': input_chunk_length,\n",
    "                                    'output_chunk_length': output_chunk_length,\n",
    "                                    'hidden_size': hidden_size,\n",
    "                                    'batch_size': batch_size,\n",
    "                                    'num_heads_attention': num_heads_attention,\n",
    "                                    'dropout': dropout,\n",
    "                                })\n",
    "                                models_da_rnn.append({\n",
    "                                    'mape': mape_da_rnn,\n",
    "                                    'sle': sle_da_rnn,\n",
    "                                    'u1': u1_da_rnn,\n",
    "                                    'u2': u1_da_rnn,\n",
    "                                    'lr': lr,\n",
    "                                    'input_chunk_length': input_chunk_length,\n",
    "                                    'output_chunk_length': output_chunk_length,\n",
    "                                    'hidden_size': hidden_size,\n",
    "                                    'batch_size': batch_size,\n",
    "                                    'num_heads_attention': num_heads_attention,\n",
    "                                    'dropout': dropout,\n",
    "                                })\n",
    "                            except:\n",
    "                                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_da_rnn in [\n",
    "                            {\n",
    "                                'name': 'MAPE',\n",
    "                                'input_chunk_length': min(models_da_rnn, key=lambda d: d['mape'])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_da_rnn, key=lambda d: d['mape'])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_da_rnn, key=lambda d: d['mape'])['hidden_size'],\n",
    "                                'batch_size': min(models_da_rnn, key=lambda d: d['mape'])['batch_size'],\n",
    "                                'lr': min(models_da_rnn, key=lambda d: d['mape'])['lr'],\n",
    "                                'num_heads_attention': min(models_da_rnn, key=lambda d: d['mape'])['num_heads_attention'],\n",
    "                                'dropout': min(models_da_rnn, key=lambda d: d['mape'])['dropout'],\n",
    "                            },\n",
    "                            {\n",
    "                                'name': 'SLE',\n",
    "                                'input_chunk_length': min(models_da_rnn, key=lambda d: d['sle'])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_da_rnn, key=lambda d: d['sle'])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_da_rnn, key=lambda d: d['sle'])['hidden_size'],\n",
    "                                'batch_size': min(models_da_rnn, key=lambda d: d['sle'])['batch_size'],\n",
    "                                'lr': min(models_da_rnn, key=lambda d: d['sle'])['lr'],\n",
    "                                'num_heads_attention': min(models_da_rnn, key=lambda d: d['sle'])['num_heads_attention'],\n",
    "                                'dropout': min(models_da_rnn, key=lambda d: d['sle'])['dropout'],\n",
    "                            },\n",
    "                            {\n",
    "                                'name': 'U1',\n",
    "                                'input_chunk_length': min(models_da_rnn, key=lambda d: d['u1'])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_da_rnn, key=lambda d: d['u1'])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_da_rnn, key=lambda d: d['u1'])['hidden_size'],\n",
    "                                'batch_size': min(models_da_rnn, key=lambda d: d['u1'])['batch_size'],\n",
    "                                'lr': min(models_da_rnn, key=lambda d: d['u1'])['lr'],\n",
    "                                'num_heads_attention': min(models_da_rnn, key=lambda d: d['u1'])['num_heads_attention'],\n",
    "                                'dropout': min(models_da_rnn, key=lambda d: d['u1'])['dropout'],\n",
    "                            },\n",
    "                            {\n",
    "                                'name': 'U2',\n",
    "                                'input_chunk_length': min(models_da_rnn, key=lambda d: d['u2'])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_da_rnn, key=lambda d: d['u2'])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_da_rnn, key=lambda d: d['u2'])['hidden_size'],\n",
    "                                'batch_size': min(models_da_rnn, key=lambda d: d['u2'])['batch_size'],\n",
    "                                'lr': min(models_da_rnn, key=lambda d: d['u2'])['lr'],\n",
    "                                'num_heads_attention': min(models_da_rnn, key=lambda d: d['u2'])['num_heads_attention'],\n",
    "                                'dropout': min(models_da_rnn, key=lambda d: d['u2'])['dropout'],\n",
    "                            },\n",
    "                        ]:\n",
    "    print('Best', best_model_da_rnn['name'])\n",
    "    model = DA_RNN(\n",
    "        input_chunk_length=best_model_da_rnn['input_chunk_length'],\n",
    "        output_chunk_length=best_model_da_rnn['output_chunk_length'],\n",
    "        hidden_size=best_model_da_rnn['hidden_size'],\n",
    "        batch_size=best_model_da_rnn['batch_size'],\n",
    "        lr=best_model_da_rnn['lr'],\n",
    "        num_heads_attention=best_model_da_rnn['num_heads_attention'],\n",
    "        dropout=best_model_da_rnn['dropout'],\n",
    "        n_epochs=400,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit(train_detrend_scaled)\n",
    "    pred_series, mape_da_rnn, sle_da_rnn = eval_model(\n",
    "        model,\n",
    "        len(val_detrend_scaled),\n",
    "        series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_detrend_scaled,\n",
    "        target_series = train_detrend_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_da_rnn = uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)])\n",
    "    u2_da_rnn = uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_da_rnn)\n",
    "    print('U2: ', u2_da_rnn)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    num_heads_attention = trial.suggest_int(\"num_heads_attention\", 0, 2)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.2)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = DA_RNN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        num_heads_attention=2**num_heads_attention,\n",
    "        dropout=dropout,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_detrend_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    mapes = mape(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DA_RNN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    num_heads_attention=2**study.best_trial.params['num_heads_attention'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_detrend_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    num_heads_attention = trial.suggest_int(\"num_heads_attention\", 0, 2)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.2)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = DA_RNN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        num_heads_attention=2**num_heads_attention,\n",
    "        dropout=dropout,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_detrend_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DA_RNN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    num_heads_attention=2**study.best_trial.params['num_heads_attention'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_detrend_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando U2 e MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    num_heads_attention = trial.suggest_int(\"num_heads_attention\", 0, 2)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.2)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = DA_RNN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        num_heads_attention=2**num_heads_attention,\n",
    "        dropout=dropout,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_detrend_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_detrend_scaled, preds)\n",
    "    mapes = mape(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DA_RNN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    num_heads_attention=2**study.best_trial.params['num_heads_attention'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_detrend_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Takens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Depois de mais de 1h os resultados ficaram ruins\n",
    "## Alterei a GRID para diminuir os parâmetros e continuou ruim\n",
    "models_da_rnn = []\n",
    "\n",
    "for input_chunk_length in range(24, 38, 2):\n",
    "    for output_chunk_length in range(1, 3):\n",
    "        for dropout in [i/100 for i in range(0,20,5)]:\n",
    "            for hidden_size in [2**i for i in range(3, 7)]:\n",
    "                for batch_size in [2**i for i in range(3, 7)]:\n",
    "                    for lr in [10**(-i) for i in range(2, 5)]:\n",
    "                        for takens_tau in range(1, len(train)//(input_chunk_length - 1)):\n",
    "                            for num_heads_attention in [2**i for i in range(4)]:\n",
    "                                try:\n",
    "                                    model = DA_RNN(\n",
    "                                        input_chunk_length=input_chunk_length,\n",
    "                                        output_chunk_length=output_chunk_length,\n",
    "                                        hidden_size=hidden_size,\n",
    "                                        batch_size=batch_size,\n",
    "                                        num_heads_attention=num_heads_attention,\n",
    "                                        dropout=dropout,\n",
    "                                        n_epochs=400,\n",
    "                                        window_model = Takens(tau=takens_tau),\n",
    "                                        lr=lr,\n",
    "                                        device=\"cuda\",\n",
    "                                        random_state = 0\n",
    "                                    )\n",
    "                                    model.fit(train_detrend_scaled)\n",
    "                                    pred_series, mape_da_rnn, sle_da_rnn = eval_model(\n",
    "                                        model,\n",
    "                                        len(val_detrend_scaled),\n",
    "                                        series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                        val_detrend_scaled,\n",
    "                                        target_series = train_detrend_scaled,\n",
    "                                        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                        plot = False,\n",
    "                                    )\n",
    "                                    uTheil = UTheil()\n",
    "                                    u1_da_rnn = uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)])\n",
    "                                    u2_da_rnn = uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)])\n",
    "                                    print({\n",
    "                                        'MAPE': mape_da_rnn,\n",
    "                                        'SLE': sle_da_rnn,\n",
    "                                        'U1': u1_da_rnn,\n",
    "                                        'U2': u1_da_rnn,\n",
    "                                        'input_chunk_length': input_chunk_length,\n",
    "                                        'output_chunk_length': output_chunk_length,\n",
    "                                        'hidden_size': hidden_size,\n",
    "                                        'batch_size': batch_size,\n",
    "                                        'num_heads_attention': num_heads_attention,\n",
    "                                        'dropout': dropout,\n",
    "                                        'lr': lr,\n",
    "                                        'takens_tau': takens_tau,\n",
    "                                    })\n",
    "                                    models_da_rnn.append({\n",
    "                                        'MAPE': mape_da_rnn,\n",
    "                                        'SLE': sle_da_rnn,\n",
    "                                        'U1': u1_da_rnn,\n",
    "                                        'U2': u1_da_rnn,\n",
    "                                        'input_chunk_length': input_chunk_length,\n",
    "                                        'output_chunk_length': output_chunk_length,\n",
    "                                        'hidden_size': hidden_size,\n",
    "                                        'batch_size': batch_size,\n",
    "                                        'num_heads_attention': num_heads_attention,\n",
    "                                        'dropout': dropout,\n",
    "                                        'takens_tau': takens_tau,\n",
    "                                        'lr': lr,\n",
    "                                    })\n",
    "                                except:\n",
    "                                    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    num_heads_attention = trial.suggest_int(\"num_heads_attention\", 0, 2)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(in_len - 1))\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.2)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = DA_RNN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        num_heads_attention=2**num_heads_attention,\n",
    "        dropout=dropout,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_detrend_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    mapes = mape(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DA_RNN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    num_heads_attention=2**study.best_trial.params['num_heads_attention'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_detrend_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    num_heads_attention = trial.suggest_int(\"num_heads_attention\", 0, 2)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(in_len - 1))\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.2)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = DA_RNN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        num_heads_attention=2**num_heads_attention,\n",
    "        dropout=dropout,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_detrend_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DA_RNN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    num_heads_attention=2**study.best_trial.params['num_heads_attention'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_detrend_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando U2 e MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    num_heads_attention = trial.suggest_int(\"num_heads_attention\", 0, 2)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(in_len - 1))\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.2)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = DA_RNN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        num_heads_attention=2**num_heads_attention,\n",
    "        dropout=dropout,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_detrend_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_detrend_scaled, preds)\n",
    "    mapes = mape(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DA_RNN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    num_heads_attention=2**study.best_trial.params['num_heads_attention'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_detrend_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Brasil + Sudeste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Janela Deslizante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_da_rnn = []\n",
    "\n",
    "for num_heads_attention in range(2,7):\n",
    "    for dropout in [i/100 for i in range(0,20,5)]:\n",
    "        for output_chunk_length in range(1, 20, 4):\n",
    "            for input_chunk_length in range(22, 30, 2):\n",
    "               for hidden_size in [2**i for i in range(3, 7)]:\n",
    "                   for batch_size in [2**i for i in range(3, 7)]:\n",
    "                       for lr in [10**(-i) for i in range(2, 5)]:\n",
    "                            try:\n",
    "                                model = DA_RNN(\n",
    "                                    input_chunk_length=input_chunk_length,\n",
    "                                    output_chunk_length=output_chunk_length,\n",
    "                                    hidden_size=hidden_size,\n",
    "                                    batch_size=batch_size,\n",
    "                                    num_heads_attention=num_heads_attention,\n",
    "                                    dropout=dropout,\n",
    "                                    n_epochs=400,\n",
    "                                    lr=lr,\n",
    "                                    device=\"cuda\",\n",
    "                                    random_state = 0\n",
    "                                )\n",
    "                                model.fit([train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())])\n",
    "                                pred_series, mape_da_rnn, sle_da_rnn = eval_model(\n",
    "                                    model,\n",
    "                                    len(val_scaled),\n",
    "                                    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                    val_scaled,\n",
    "                                    target_series = train_scaled,\n",
    "                                    returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                    plot = False,\n",
    "                                )\n",
    "                                uTheil = UTheil()\n",
    "                                u1_da_rnn = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "                                u2_da_rnn = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "                                print({\n",
    "                                    'mape': mape_da_rnn,\n",
    "                                    'sle': sle_da_rnn,\n",
    "                                    'u1': u1_da_rnn,\n",
    "                                    'u2': u1_da_rnn,\n",
    "                                    'lr': lr,\n",
    "                                    'input_chunk_length': input_chunk_length,\n",
    "                                    'output_chunk_length': output_chunk_length,\n",
    "                                    'hidden_size': hidden_size,\n",
    "                                    'batch_size': batch_size,\n",
    "                                    'num_heads_attention': num_heads_attention,\n",
    "                                    'dropout': dropout,\n",
    "                                })\n",
    "                                models_da_rnn.append({\n",
    "                                    'mape': mape_da_rnn,\n",
    "                                    'sle': sle_da_rnn,\n",
    "                                    'u1': u1_da_rnn,\n",
    "                                    'u2': u1_da_rnn,\n",
    "                                    'lr': lr,\n",
    "                                    'input_chunk_length': input_chunk_length,\n",
    "                                    'output_chunk_length': output_chunk_length,\n",
    "                                    'hidden_size': hidden_size,\n",
    "                                    'batch_size': batch_size,\n",
    "                                    'num_heads_attention': num_heads_attention,\n",
    "                                    'dropout': dropout,\n",
    "                                })\n",
    "                            except:\n",
    "                                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_da_rnn in [\n",
    "                            {\n",
    "                                'name': 'MAPE',\n",
    "                                'input_chunk_length': min(models_da_rnn, key=lambda d: d['mape'])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_da_rnn, key=lambda d: d['mape'])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_da_rnn, key=lambda d: d['mape'])['hidden_size'],\n",
    "                                'batch_size': min(models_da_rnn, key=lambda d: d['mape'])['batch_size'],\n",
    "                                'lr': min(models_da_rnn, key=lambda d: d['mape'])['lr'],\n",
    "                                'num_heads_attention': min(models_da_rnn, key=lambda d: d['mape'])['num_heads_attention'],\n",
    "                                'dropout': min(models_da_rnn, key=lambda d: d['mape'])['dropout'],\n",
    "                            },\n",
    "                            {\n",
    "                                'name': 'SLE',\n",
    "                                'input_chunk_length': min(models_da_rnn, key=lambda d: d['sle'])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_da_rnn, key=lambda d: d['sle'])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_da_rnn, key=lambda d: d['sle'])['hidden_size'],\n",
    "                                'batch_size': min(models_da_rnn, key=lambda d: d['sle'])['batch_size'],\n",
    "                                'lr': min(models_da_rnn, key=lambda d: d['sle'])['lr'],\n",
    "                                'num_heads_attention': min(models_da_rnn, key=lambda d: d['sle'])['num_heads_attention'],\n",
    "                                'dropout': min(models_da_rnn, key=lambda d: d['sle'])['dropout'],\n",
    "                            },\n",
    "                            {\n",
    "                                'name': 'U1',\n",
    "                                'input_chunk_length': min(models_da_rnn, key=lambda d: d['u1'])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_da_rnn, key=lambda d: d['u1'])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_da_rnn, key=lambda d: d['u1'])['hidden_size'],\n",
    "                                'batch_size': min(models_da_rnn, key=lambda d: d['u1'])['batch_size'],\n",
    "                                'lr': min(models_da_rnn, key=lambda d: d['u1'])['lr'],\n",
    "                                'num_heads_attention': min(models_da_rnn, key=lambda d: d['u1'])['num_heads_attention'],\n",
    "                                'dropout': min(models_da_rnn, key=lambda d: d['u1'])['dropout'],\n",
    "                            },\n",
    "                            {\n",
    "                                'name': 'U2',\n",
    "                                'input_chunk_length': min(models_da_rnn, key=lambda d: d['u2'])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_da_rnn, key=lambda d: d['u2'])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_da_rnn, key=lambda d: d['u2'])['hidden_size'],\n",
    "                                'batch_size': min(models_da_rnn, key=lambda d: d['u2'])['batch_size'],\n",
    "                                'lr': min(models_da_rnn, key=lambda d: d['u2'])['lr'],\n",
    "                                'num_heads_attention': min(models_da_rnn, key=lambda d: d['u2'])['num_heads_attention'],\n",
    "                                'dropout': min(models_da_rnn, key=lambda d: d['u2'])['dropout'],\n",
    "                            },\n",
    "                        ]:\n",
    "    print('Best', best_model_da_rnn['name'])\n",
    "    model = DA_RNN(\n",
    "        input_chunk_length=best_model_da_rnn['input_chunk_length'],\n",
    "        output_chunk_length=best_model_da_rnn['output_chunk_length'],\n",
    "        hidden_size=best_model_da_rnn['hidden_size'],\n",
    "        batch_size=best_model_da_rnn['batch_size'],\n",
    "        lr=best_model_da_rnn['lr'],\n",
    "        num_heads_attention=best_model_da_rnn['num_heads_attention'],\n",
    "        dropout=best_model_da_rnn['dropout'],\n",
    "        n_epochs=400,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit([train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())])\n",
    "    pred_series, mape_da_rnn, sle_da_rnn = eval_model(\n",
    "        model,\n",
    "        len(val_scaled),\n",
    "        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_scaled,\n",
    "        target_series = train_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_da_rnn = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "    u2_da_rnn = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_da_rnn)\n",
    "    print('U2: ', u2_da_rnn)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_da_rnn = []\n",
    "\n",
    "for input_chunk_length in range(24, 28, 2):\n",
    "    for output_chunk_length in range(1, 3):\n",
    "        for num_heads_attention in range(4):\n",
    "            for hidden_size in [9, 64]:\n",
    "                for batch_size in [2**i for i in range(4, 6)]:\n",
    "                    for dropout in [i/100 for i in range(0,25,5)]:\n",
    "                        for n_epochs in [200, 400, 600, 800]:\n",
    "                            try:\n",
    "                                model = DA_RNN(\n",
    "                                    input_chunk_length=input_chunk_length,\n",
    "                                    output_chunk_length=output_chunk_length,\n",
    "                                    hidden_size=hidden_size,\n",
    "                                    batch_size=batch_size,\n",
    "                                    num_heads_attention=num_heads_attention,\n",
    "                                    dropout=dropout,\n",
    "                                    n_epochs=n_epochs,\n",
    "                                    lr=1e-2,\n",
    "                                    device=\"cuda\",\n",
    "                                    random_state = 0\n",
    "                                )\n",
    "                                model.fit([train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())])\n",
    "                                pred_series, mape_da_rnn, sle_da_rnn = eval_model(\n",
    "                                    model,\n",
    "                                    len(val_scaled),\n",
    "                                    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                    val_scaled,\n",
    "                                    target_series = train_scaled,\n",
    "                                    returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                    plot = False,\n",
    "                                )\n",
    "                                uTheil = UTheil()\n",
    "                                u1_da_rnn = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "                                u2_da_rnn = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "                                print({\n",
    "                                    'MAPE': mape_da_rnn,\n",
    "                                    'SLE': sle_da_rnn,\n",
    "                                    'U1': u1_da_rnn,\n",
    "                                    'U2': u1_da_rnn,\n",
    "                                    'input_chunk_length': input_chunk_length,\n",
    "                                    'output_chunk_length': output_chunk_length,\n",
    "                                    'hidden_size': hidden_size,\n",
    "                                    'batch_size': batch_size,\n",
    "                                    'num_heads_attention': num_heads_attention,\n",
    "                                    'dropout': dropout,\n",
    "                                    'n_epochs': n_epochs,\n",
    "                                })\n",
    "                                models_da_rnn.append({\n",
    "                                    'MAPE': mape_da_rnn,\n",
    "                                    'SLE': sle_da_rnn,\n",
    "                                    'U1': u1_da_rnn,\n",
    "                                    'U2': u1_da_rnn,\n",
    "                                    'input_chunk_length': input_chunk_length,\n",
    "                                    'output_chunk_length': output_chunk_length,\n",
    "                                    'hidden_size': hidden_size,\n",
    "                                    'batch_size': batch_size,\n",
    "                                    'num_heads_attention': num_heads_attention,\n",
    "                                    'dropout': dropout,\n",
    "                                    'n_epochs': n_epochs,\n",
    "                                })\n",
    "                            except:\n",
    "                                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_da_rnn in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_da_rnn, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_da_rnn, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_da_rnn, key=lambda d: d[i])['hidden_size'],\n",
    "                                'batch_size': min(models_da_rnn, key=lambda d: d[i])['batch_size'],\n",
    "                                'n_epochs': min(models_da_rnn, key=lambda d: d[i])['n_epochs'],\n",
    "                                'num_heads_attention': min(models_da_rnn, key=lambda d: d[i])['num_heads_attention'],\n",
    "                                'dropout': min(models_da_rnn, key=lambda d: d[i])['dropout'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_da_rnn['name'])\n",
    "    model = DA_RNN(\n",
    "        input_chunk_length=best_model_da_rnn['input_chunk_length'],\n",
    "        output_chunk_length=best_model_da_rnn['output_chunk_length'],\n",
    "        hidden_size=best_model_da_rnn['hidden_size'],\n",
    "        batch_size=best_model_da_rnn['batch_size'],\n",
    "        num_heads_attention=best_model_da_rnn['num_heads_attention'],\n",
    "        dropout=best_model_da_rnn['dropout'],\n",
    "        n_epochs=best_model_da_rnn['n_epochs'],\n",
    "        lr=1e-2,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit([train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())])\n",
    "    pred_series, mape_da_rnn, sle_da_rnn = eval_model(\n",
    "        model,\n",
    "        len(val_scaled),\n",
    "        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_scaled,\n",
    "        target_series = train_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_da_rnn = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "    u2_da_rnn = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_da_rnn)\n",
    "    print('U2: ', u2_da_rnn)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    num_heads_attention = trial.suggest_int(\"num_heads_attention\", 0, 2)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.2)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = DA_RNN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        num_heads_attention=2**num_heads_attention,\n",
    "        dropout=dropout,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DA_RNN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    num_heads_attention=2**study.best_trial.params['num_heads_attention'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    num_heads_attention = trial.suggest_int(\"num_heads_attention\", 0, 2)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.2)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = DA_RNN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        num_heads_attention=2**num_heads_attention,\n",
    "        dropout=dropout,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DA_RNN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    num_heads_attention=2**study.best_trial.params['num_heads_attention'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando U2 e MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    num_heads_attention = trial.suggest_int(\"num_heads_attention\", 0, 2)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.2)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = DA_RNN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        num_heads_attention=2**num_heads_attention,\n",
    "        dropout=dropout,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_scaled, preds)\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DA_RNN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    num_heads_attention=2**study.best_trial.params['num_heads_attention'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Takens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Depois de mais de 1h os resultados ficaram ruins\n",
    "## Alterei a GRID para diminuir os parâmetros e continuou ruim\n",
    "models_da_rnn = []\n",
    "\n",
    "for input_chunk_length in range(24, 38, 2):\n",
    "    for output_chunk_length in range(1, 3):\n",
    "        for dropout in [i/100 for i in range(0,20,5)]:\n",
    "            for hidden_size in [2**i for i in range(3, 7)]:\n",
    "                for batch_size in [2**i for i in range(3, 7)]:\n",
    "                    for lr in [10**(-i) for i in range(2, 5)]:\n",
    "                        for takens_tau in range(1, len(train)//(input_chunk_length - 1)):\n",
    "                            for num_heads_attention in [2**i for i in range(4)]:\n",
    "                                try:\n",
    "                                    model = DA_RNN(\n",
    "                                        input_chunk_length=input_chunk_length,\n",
    "                                        output_chunk_length=output_chunk_length,\n",
    "                                        hidden_size=hidden_size,\n",
    "                                        batch_size=batch_size,\n",
    "                                        num_heads_attention=num_heads_attention,\n",
    "                                        dropout=dropout,\n",
    "                                        n_epochs=400,\n",
    "                                        window_model = Takens(tau=takens_tau),\n",
    "                                        lr=lr,\n",
    "                                        device=\"cuda\",\n",
    "                                        random_state = 0\n",
    "                                    )\n",
    "                                    model.fit([train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())])\n",
    "                                    pred_series, mape_da_rnn, sle_da_rnn = eval_model(\n",
    "                                        model,\n",
    "                                        len(val_scaled),\n",
    "                                        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                        val_scaled,\n",
    "                                        target_series = train_scaled,\n",
    "                                        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                        plot = False,\n",
    "                                    )\n",
    "                                    uTheil = UTheil()\n",
    "                                    u1_da_rnn = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "                                    u2_da_rnn = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "                                    print({\n",
    "                                        'MAPE': mape_da_rnn,\n",
    "                                        'SLE': sle_da_rnn,\n",
    "                                        'U1': u1_da_rnn,\n",
    "                                        'U2': u1_da_rnn,\n",
    "                                        'input_chunk_length': input_chunk_length,\n",
    "                                        'output_chunk_length': output_chunk_length,\n",
    "                                        'hidden_size': hidden_size,\n",
    "                                        'batch_size': batch_size,\n",
    "                                        'num_heads_attention': num_heads_attention,\n",
    "                                        'dropout': dropout,\n",
    "                                        'lr': lr,\n",
    "                                        'takens_tau': takens_tau,\n",
    "                                    })\n",
    "                                    models_da_rnn.append({\n",
    "                                        'MAPE': mape_da_rnn,\n",
    "                                        'SLE': sle_da_rnn,\n",
    "                                        'U1': u1_da_rnn,\n",
    "                                        'U2': u1_da_rnn,\n",
    "                                        'input_chunk_length': input_chunk_length,\n",
    "                                        'output_chunk_length': output_chunk_length,\n",
    "                                        'hidden_size': hidden_size,\n",
    "                                        'batch_size': batch_size,\n",
    "                                        'num_heads_attention': num_heads_attention,\n",
    "                                        'dropout': dropout,\n",
    "                                        'takens_tau': takens_tau,\n",
    "                                        'lr': lr,\n",
    "                                    })\n",
    "                                except:\n",
    "                                    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    num_heads_attention = trial.suggest_int(\"num_heads_attention\", 0, 2)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(in_len - 1))\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.2)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = DA_RNN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        num_heads_attention=2**num_heads_attention,\n",
    "        dropout=dropout,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DA_RNN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    num_heads_attention=2**study.best_trial.params['num_heads_attention'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    num_heads_attention = trial.suggest_int(\"num_heads_attention\", 0, 2)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(in_len - 1))\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.2)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = DA_RNN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        num_heads_attention=2**num_heads_attention,\n",
    "        dropout=dropout,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DA_RNN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    num_heads_attention=2**study.best_trial.params['num_heads_attention'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando U2 e MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    num_heads_attention = trial.suggest_int(\"num_heads_attention\", 0, 2)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(in_len - 1))\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.2)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = DA_RNN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        num_heads_attention=2**num_heads_attention,\n",
    "        dropout=dropout,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_scaled, preds)\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DA_RNN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    num_heads_attention=2**study.best_trial.params['num_heads_attention'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Brasil (detrend) + Sudeste (detrend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Janela Deslizante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_da_rnn = []\n",
    "\n",
    "for num_heads_attention in range(2,7):\n",
    "    for dropout in [i/100 for i in range(0,20,5)]:\n",
    "        for output_chunk_length in range(1, 20, 4):\n",
    "            for input_chunk_length in range(22, 30, 2):\n",
    "               for hidden_size in [2**i for i in range(3, 7)]:\n",
    "                   for batch_size in [2**i for i in range(3, 7)]:\n",
    "                       for lr in [10**(-i) for i in range(2, 5)]:\n",
    "                            try:\n",
    "                                model = DA_RNN(\n",
    "                                    input_chunk_length=input_chunk_length,\n",
    "                                    output_chunk_length=output_chunk_length,\n",
    "                                    hidden_size=hidden_size,\n",
    "                                    batch_size=batch_size,\n",
    "                                    num_heads_attention=num_heads_attention,\n",
    "                                    dropout=dropout,\n",
    "                                    n_epochs=400,\n",
    "                                    lr=lr,\n",
    "                                    device=\"cuda\",\n",
    "                                    random_state = 0\n",
    "                                )\n",
    "                                model.fit([train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())])\n",
    "                                pred_series, mape_da_rnn, sle_da_rnn = eval_model(\n",
    "                                    model,\n",
    "                                    len(val_detrend_scaled),\n",
    "                                    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                    val_detrend_scaled,\n",
    "                                    target_series = train_detrend_scaled,\n",
    "                                    returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                    plot = False,\n",
    "                                )\n",
    "                                uTheil = UTheil()\n",
    "                                u1_da_rnn = uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)])\n",
    "                                u2_da_rnn = uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)])\n",
    "                                print({\n",
    "                                    'mape': mape_da_rnn,\n",
    "                                    'sle': sle_da_rnn,\n",
    "                                    'u1': u1_da_rnn,\n",
    "                                    'u2': u1_da_rnn,\n",
    "                                    'lr': lr,\n",
    "                                    'input_chunk_length': input_chunk_length,\n",
    "                                    'output_chunk_length': output_chunk_length,\n",
    "                                    'hidden_size': hidden_size,\n",
    "                                    'batch_size': batch_size,\n",
    "                                    'num_heads_attention': num_heads_attention,\n",
    "                                    'dropout': dropout,\n",
    "                                })\n",
    "                                models_da_rnn.append({\n",
    "                                    'mape': mape_da_rnn,\n",
    "                                    'sle': sle_da_rnn,\n",
    "                                    'u1': u1_da_rnn,\n",
    "                                    'u2': u1_da_rnn,\n",
    "                                    'lr': lr,\n",
    "                                    'input_chunk_length': input_chunk_length,\n",
    "                                    'output_chunk_length': output_chunk_length,\n",
    "                                    'hidden_size': hidden_size,\n",
    "                                    'batch_size': batch_size,\n",
    "                                    'num_heads_attention': num_heads_attention,\n",
    "                                    'dropout': dropout,\n",
    "                                })\n",
    "                            except:\n",
    "                                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_da_rnn in [\n",
    "                            {\n",
    "                                'name': 'MAPE',\n",
    "                                'input_chunk_length': min(models_da_rnn, key=lambda d: d['mape'])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_da_rnn, key=lambda d: d['mape'])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_da_rnn, key=lambda d: d['mape'])['hidden_size'],\n",
    "                                'batch_size': min(models_da_rnn, key=lambda d: d['mape'])['batch_size'],\n",
    "                                'lr': min(models_da_rnn, key=lambda d: d['mape'])['lr'],\n",
    "                                'num_heads_attention': min(models_da_rnn, key=lambda d: d['mape'])['num_heads_attention'],\n",
    "                                'dropout': min(models_da_rnn, key=lambda d: d['mape'])['dropout'],\n",
    "                            },\n",
    "                            {\n",
    "                                'name': 'SLE',\n",
    "                                'input_chunk_length': min(models_da_rnn, key=lambda d: d['sle'])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_da_rnn, key=lambda d: d['sle'])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_da_rnn, key=lambda d: d['sle'])['hidden_size'],\n",
    "                                'batch_size': min(models_da_rnn, key=lambda d: d['sle'])['batch_size'],\n",
    "                                'lr': min(models_da_rnn, key=lambda d: d['sle'])['lr'],\n",
    "                                'num_heads_attention': min(models_da_rnn, key=lambda d: d['sle'])['num_heads_attention'],\n",
    "                                'dropout': min(models_da_rnn, key=lambda d: d['sle'])['dropout'],\n",
    "                            },\n",
    "                            {\n",
    "                                'name': 'U1',\n",
    "                                'input_chunk_length': min(models_da_rnn, key=lambda d: d['u1'])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_da_rnn, key=lambda d: d['u1'])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_da_rnn, key=lambda d: d['u1'])['hidden_size'],\n",
    "                                'batch_size': min(models_da_rnn, key=lambda d: d['u1'])['batch_size'],\n",
    "                                'lr': min(models_da_rnn, key=lambda d: d['u1'])['lr'],\n",
    "                                'num_heads_attention': min(models_da_rnn, key=lambda d: d['u1'])['num_heads_attention'],\n",
    "                                'dropout': min(models_da_rnn, key=lambda d: d['u1'])['dropout'],\n",
    "                            },\n",
    "                            {\n",
    "                                'name': 'U2',\n",
    "                                'input_chunk_length': min(models_da_rnn, key=lambda d: d['u2'])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_da_rnn, key=lambda d: d['u2'])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_da_rnn, key=lambda d: d['u2'])['hidden_size'],\n",
    "                                'batch_size': min(models_da_rnn, key=lambda d: d['u2'])['batch_size'],\n",
    "                                'lr': min(models_da_rnn, key=lambda d: d['u2'])['lr'],\n",
    "                                'num_heads_attention': min(models_da_rnn, key=lambda d: d['u2'])['num_heads_attention'],\n",
    "                                'dropout': min(models_da_rnn, key=lambda d: d['u2'])['dropout'],\n",
    "                            },\n",
    "                        ]:\n",
    "    print('Best', best_model_da_rnn['name'])\n",
    "    model = DA_RNN(\n",
    "        input_chunk_length=best_model_da_rnn['input_chunk_length'],\n",
    "        output_chunk_length=best_model_da_rnn['output_chunk_length'],\n",
    "        hidden_size=best_model_da_rnn['hidden_size'],\n",
    "        batch_size=best_model_da_rnn['batch_size'],\n",
    "        lr=best_model_da_rnn['lr'],\n",
    "        num_heads_attention=best_model_da_rnn['num_heads_attention'],\n",
    "        dropout=best_model_da_rnn['dropout'],\n",
    "        n_epochs=400,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit([train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())])\n",
    "    pred_series, mape_da_rnn, sle_da_rnn = eval_model(\n",
    "        model,\n",
    "        len(val_detrend_scaled),\n",
    "        series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_detrend_scaled,\n",
    "        target_series = train_detrend_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_da_rnn = uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)])\n",
    "    u2_da_rnn = uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_da_rnn)\n",
    "    print('U2: ', u2_da_rnn)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    num_heads_attention = trial.suggest_int(\"num_heads_attention\", 0, 2)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.2)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = DA_RNN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        num_heads_attention=2**num_heads_attention,\n",
    "        dropout=dropout,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    mapes = mape(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DA_RNN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    num_heads_attention=2**study.best_trial.params['num_heads_attention'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    num_heads_attention = trial.suggest_int(\"num_heads_attention\", 0, 2)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.2)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = DA_RNN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        num_heads_attention=2**num_heads_attention,\n",
    "        dropout=dropout,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DA_RNN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    num_heads_attention=2**study.best_trial.params['num_heads_attention'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando U2 e MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    num_heads_attention = trial.suggest_int(\"num_heads_attention\", 0, 2)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.2)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = DA_RNN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        num_heads_attention=2**num_heads_attention,\n",
    "        dropout=dropout,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_detrend_scaled, preds)\n",
    "    mapes = mape(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DA_RNN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    num_heads_attention=2**study.best_trial.params['num_heads_attention'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Takens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Depois de mais de 1h os resultados ficaram ruins\n",
    "## Alterei a GRID para diminuir os parâmetros e continuou ruim\n",
    "models_da_rnn = []\n",
    "\n",
    "for input_chunk_length in range(24, 38, 2):\n",
    "    for output_chunk_length in range(1, 3):\n",
    "        for dropout in [i/100 for i in range(0,20,5)]:\n",
    "            for hidden_size in [2**i for i in range(3, 7)]:\n",
    "                for batch_size in [2**i for i in range(3, 7)]:\n",
    "                    for lr in [10**(-i) for i in range(2, 5)]:\n",
    "                        for takens_tau in range(1, len(train)//(input_chunk_length - 1)):\n",
    "                            for num_heads_attention in [2**i for i in range(4)]:\n",
    "                                try:\n",
    "                                    model = DA_RNN(\n",
    "                                        input_chunk_length=input_chunk_length,\n",
    "                                        output_chunk_length=output_chunk_length,\n",
    "                                        hidden_size=hidden_size,\n",
    "                                        batch_size=batch_size,\n",
    "                                        num_heads_attention=num_heads_attention,\n",
    "                                        dropout=dropout,\n",
    "                                        n_epochs=400,\n",
    "                                        window_model = Takens(tau=takens_tau),\n",
    "                                        lr=lr,\n",
    "                                        device=\"cuda\",\n",
    "                                        random_state = 0\n",
    "                                    )\n",
    "                                    model.fit([train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())])\n",
    "                                    pred_series, mape_da_rnn, sle_da_rnn = eval_model(\n",
    "                                        model,\n",
    "                                        len(val_detrend_scaled),\n",
    "                                        series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                        val_detrend_scaled,\n",
    "                                        target_series = train_detrend_scaled,\n",
    "                                        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                        plot = False,\n",
    "                                    )\n",
    "                                    uTheil = UTheil()\n",
    "                                    u1_da_rnn = uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)])\n",
    "                                    u2_da_rnn = uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)])\n",
    "                                    print({\n",
    "                                        'MAPE': mape_da_rnn,\n",
    "                                        'SLE': sle_da_rnn,\n",
    "                                        'U1': u1_da_rnn,\n",
    "                                        'U2': u1_da_rnn,\n",
    "                                        'input_chunk_length': input_chunk_length,\n",
    "                                        'output_chunk_length': output_chunk_length,\n",
    "                                        'hidden_size': hidden_size,\n",
    "                                        'batch_size': batch_size,\n",
    "                                        'num_heads_attention': num_heads_attention,\n",
    "                                        'dropout': dropout,\n",
    "                                        'lr': lr,\n",
    "                                        'takens_tau': takens_tau,\n",
    "                                    })\n",
    "                                    models_da_rnn.append({\n",
    "                                        'MAPE': mape_da_rnn,\n",
    "                                        'SLE': sle_da_rnn,\n",
    "                                        'U1': u1_da_rnn,\n",
    "                                        'U2': u1_da_rnn,\n",
    "                                        'input_chunk_length': input_chunk_length,\n",
    "                                        'output_chunk_length': output_chunk_length,\n",
    "                                        'hidden_size': hidden_size,\n",
    "                                        'batch_size': batch_size,\n",
    "                                        'num_heads_attention': num_heads_attention,\n",
    "                                        'dropout': dropout,\n",
    "                                        'takens_tau': takens_tau,\n",
    "                                        'lr': lr,\n",
    "                                    })\n",
    "                                except:\n",
    "                                    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    num_heads_attention = trial.suggest_int(\"num_heads_attention\", 0, 2)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(in_len - 1))\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.2)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = DA_RNN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        num_heads_attention=2**num_heads_attention,\n",
    "        dropout=dropout,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    mapes = mape(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DA_RNN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    num_heads_attention=2**study.best_trial.params['num_heads_attention'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    num_heads_attention = trial.suggest_int(\"num_heads_attention\", 0, 2)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(in_len - 1))\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.2)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = DA_RNN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        num_heads_attention=2**num_heads_attention,\n",
    "        dropout=dropout,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DA_RNN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    num_heads_attention=2**study.best_trial.params['num_heads_attention'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando U2 e MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    num_heads_attention = trial.suggest_int(\"num_heads_attention\", 0, 2)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(in_len - 1))\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.2)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = DA_RNN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        num_heads_attention=2**num_heads_attention,\n",
    "        dropout=dropout,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_detrend_scaled, preds)\n",
    "    mapes = mape(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DA_RNN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    num_heads_attention=2**study.best_trial.params['num_heads_attention'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brasil + Óleo de Soja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Janela Deslizante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_da_rnn = []\n",
    "\n",
    "for num_heads_attention in range(2,7):\n",
    "    for dropout in [i/100 for i in range(0,20,5)]:\n",
    "        for output_chunk_length in range(1, 20, 4):\n",
    "            for input_chunk_length in range(22, 30, 2):\n",
    "               for hidden_size in [2**i for i in range(3, 7)]:\n",
    "                   for batch_size in [2**i for i in range(3, 7)]:\n",
    "                       for lr in [10**(-i) for i in range(2, 5)]:\n",
    "                            try:\n",
    "                                model = DA_RNN(\n",
    "                                    input_chunk_length=input_chunk_length,\n",
    "                                    output_chunk_length=output_chunk_length,\n",
    "                                    hidden_size=hidden_size,\n",
    "                                    batch_size=batch_size,\n",
    "                                    num_heads_attention=num_heads_attention,\n",
    "                                    dropout=dropout,\n",
    "                                    n_epochs=400,\n",
    "                                    lr=lr,\n",
    "                                    device=\"cuda\",\n",
    "                                    random_state = 0\n",
    "                                )\n",
    "                                model.fit([train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())])\n",
    "                                pred_series, mape_da_rnn, sle_da_rnn = eval_model(\n",
    "                                    model,\n",
    "                                    len(val_scaled),\n",
    "                                    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                    val_scaled,\n",
    "                                    target_series = train_scaled,\n",
    "                                    returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                    plot = False,\n",
    "                                )\n",
    "                                uTheil = UTheil()\n",
    "                                u1_da_rnn = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "                                u2_da_rnn = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "                                print({\n",
    "                                    'mape': mape_da_rnn,\n",
    "                                    'sle': sle_da_rnn,\n",
    "                                    'u1': u1_da_rnn,\n",
    "                                    'u2': u1_da_rnn,\n",
    "                                    'lr': lr,\n",
    "                                    'input_chunk_length': input_chunk_length,\n",
    "                                    'output_chunk_length': output_chunk_length,\n",
    "                                    'hidden_size': hidden_size,\n",
    "                                    'batch_size': batch_size,\n",
    "                                    'num_heads_attention': num_heads_attention,\n",
    "                                    'dropout': dropout,\n",
    "                                })\n",
    "                                models_da_rnn.append({\n",
    "                                    'mape': mape_da_rnn,\n",
    "                                    'sle': sle_da_rnn,\n",
    "                                    'u1': u1_da_rnn,\n",
    "                                    'u2': u1_da_rnn,\n",
    "                                    'lr': lr,\n",
    "                                    'input_chunk_length': input_chunk_length,\n",
    "                                    'output_chunk_length': output_chunk_length,\n",
    "                                    'hidden_size': hidden_size,\n",
    "                                    'batch_size': batch_size,\n",
    "                                    'num_heads_attention': num_heads_attention,\n",
    "                                    'dropout': dropout,\n",
    "                                })\n",
    "                            except:\n",
    "                                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_da_rnn in [\n",
    "                            {\n",
    "                                'name': 'MAPE',\n",
    "                                'input_chunk_length': min(models_da_rnn, key=lambda d: d['mape'])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_da_rnn, key=lambda d: d['mape'])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_da_rnn, key=lambda d: d['mape'])['hidden_size'],\n",
    "                                'batch_size': min(models_da_rnn, key=lambda d: d['mape'])['batch_size'],\n",
    "                                'lr': min(models_da_rnn, key=lambda d: d['mape'])['lr'],\n",
    "                                'num_heads_attention': min(models_da_rnn, key=lambda d: d['mape'])['num_heads_attention'],\n",
    "                                'dropout': min(models_da_rnn, key=lambda d: d['mape'])['dropout'],\n",
    "                            },\n",
    "                            {\n",
    "                                'name': 'SLE',\n",
    "                                'input_chunk_length': min(models_da_rnn, key=lambda d: d['sle'])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_da_rnn, key=lambda d: d['sle'])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_da_rnn, key=lambda d: d['sle'])['hidden_size'],\n",
    "                                'batch_size': min(models_da_rnn, key=lambda d: d['sle'])['batch_size'],\n",
    "                                'lr': min(models_da_rnn, key=lambda d: d['sle'])['lr'],\n",
    "                                'num_heads_attention': min(models_da_rnn, key=lambda d: d['sle'])['num_heads_attention'],\n",
    "                                'dropout': min(models_da_rnn, key=lambda d: d['sle'])['dropout'],\n",
    "                            },\n",
    "                            {\n",
    "                                'name': 'U1',\n",
    "                                'input_chunk_length': min(models_da_rnn, key=lambda d: d['u1'])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_da_rnn, key=lambda d: d['u1'])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_da_rnn, key=lambda d: d['u1'])['hidden_size'],\n",
    "                                'batch_size': min(models_da_rnn, key=lambda d: d['u1'])['batch_size'],\n",
    "                                'lr': min(models_da_rnn, key=lambda d: d['u1'])['lr'],\n",
    "                                'num_heads_attention': min(models_da_rnn, key=lambda d: d['u1'])['num_heads_attention'],\n",
    "                                'dropout': min(models_da_rnn, key=lambda d: d['u1'])['dropout'],\n",
    "                            },\n",
    "                            {\n",
    "                                'name': 'U2',\n",
    "                                'input_chunk_length': min(models_da_rnn, key=lambda d: d['u2'])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_da_rnn, key=lambda d: d['u2'])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_da_rnn, key=lambda d: d['u2'])['hidden_size'],\n",
    "                                'batch_size': min(models_da_rnn, key=lambda d: d['u2'])['batch_size'],\n",
    "                                'lr': min(models_da_rnn, key=lambda d: d['u2'])['lr'],\n",
    "                                'num_heads_attention': min(models_da_rnn, key=lambda d: d['u2'])['num_heads_attention'],\n",
    "                                'dropout': min(models_da_rnn, key=lambda d: d['u2'])['dropout'],\n",
    "                            },\n",
    "                        ]:\n",
    "    print('Best', best_model_da_rnn['name'])\n",
    "    model = DA_RNN(\n",
    "        input_chunk_length=best_model_da_rnn['input_chunk_length'],\n",
    "        output_chunk_length=best_model_da_rnn['output_chunk_length'],\n",
    "        hidden_size=best_model_da_rnn['hidden_size'],\n",
    "        batch_size=best_model_da_rnn['batch_size'],\n",
    "        lr=best_model_da_rnn['lr'],\n",
    "        num_heads_attention=best_model_da_rnn['num_heads_attention'],\n",
    "        dropout=best_model_da_rnn['dropout'],\n",
    "        n_epochs=400,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit([train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())])\n",
    "    pred_series, mape_da_rnn, sle_da_rnn = eval_model(\n",
    "        model,\n",
    "        len(val_scaled),\n",
    "        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_scaled,\n",
    "        target_series = train_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_da_rnn = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "    u2_da_rnn = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_da_rnn)\n",
    "    print('U2: ', u2_da_rnn)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    num_heads_attention = trial.suggest_int(\"num_heads_attention\", 0, 2)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.2)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = DA_RNN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        num_heads_attention=2**num_heads_attention,\n",
    "        dropout=dropout,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DA_RNN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    num_heads_attention=2**study.best_trial.params['num_heads_attention'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    num_heads_attention = trial.suggest_int(\"num_heads_attention\", 0, 2)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.2)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = DA_RNN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        num_heads_attention=2**num_heads_attention,\n",
    "        dropout=dropout,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DA_RNN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    num_heads_attention=2**study.best_trial.params['num_heads_attention'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando U2 e MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    num_heads_attention = trial.suggest_int(\"num_heads_attention\", 0, 2)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.2)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = DA_RNN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        num_heads_attention=2**num_heads_attention,\n",
    "        dropout=dropout,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_scaled, preds)\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DA_RNN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    num_heads_attention=2**study.best_trial.params['num_heads_attention'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Takens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Depois de mais de 1h os resultados ficaram ruins\n",
    "## Alterei a GRID para diminuir os parâmetros e continuou ruim\n",
    "models_da_rnn = []\n",
    "\n",
    "for input_chunk_length in range(24, 38, 2):\n",
    "    for output_chunk_length in range(1, 3):\n",
    "        for dropout in [i/100 for i in range(0,20,5)]:\n",
    "            for hidden_size in [2**i for i in range(3, 7)]:\n",
    "                for batch_size in [2**i for i in range(3, 7)]:\n",
    "                    for lr in [10**(-i) for i in range(2, 5)]:\n",
    "                        for takens_tau in range(1, len(train)//(input_chunk_length - 1)):\n",
    "                            for num_heads_attention in [2**i for i in range(4)]:\n",
    "                                try:\n",
    "                                    model = DA_RNN(\n",
    "                                        input_chunk_length=input_chunk_length,\n",
    "                                        output_chunk_length=output_chunk_length,\n",
    "                                        hidden_size=hidden_size,\n",
    "                                        batch_size=batch_size,\n",
    "                                        num_heads_attention=num_heads_attention,\n",
    "                                        dropout=dropout,\n",
    "                                        n_epochs=400,\n",
    "                                        window_model = Takens(tau=takens_tau),\n",
    "                                        lr=lr,\n",
    "                                        device=\"cuda\",\n",
    "                                        random_state = 0\n",
    "                                    )\n",
    "                                    model.fit([train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())])\n",
    "                                    pred_series, mape_da_rnn, sle_da_rnn = eval_model(\n",
    "                                        model,\n",
    "                                        len(val_scaled),\n",
    "                                        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                        val_scaled,\n",
    "                                        target_series = train_scaled,\n",
    "                                        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                        plot = False,\n",
    "                                    )\n",
    "                                    uTheil = UTheil()\n",
    "                                    u1_da_rnn = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "                                    u2_da_rnn = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "                                    print({\n",
    "                                        'MAPE': mape_da_rnn,\n",
    "                                        'SLE': sle_da_rnn,\n",
    "                                        'U1': u1_da_rnn,\n",
    "                                        'U2': u1_da_rnn,\n",
    "                                        'input_chunk_length': input_chunk_length,\n",
    "                                        'output_chunk_length': output_chunk_length,\n",
    "                                        'hidden_size': hidden_size,\n",
    "                                        'batch_size': batch_size,\n",
    "                                        'num_heads_attention': num_heads_attention,\n",
    "                                        'dropout': dropout,\n",
    "                                        'lr': lr,\n",
    "                                        'takens_tau': takens_tau,\n",
    "                                    })\n",
    "                                    models_da_rnn.append({\n",
    "                                        'MAPE': mape_da_rnn,\n",
    "                                        'SLE': sle_da_rnn,\n",
    "                                        'U1': u1_da_rnn,\n",
    "                                        'U2': u1_da_rnn,\n",
    "                                        'input_chunk_length': input_chunk_length,\n",
    "                                        'output_chunk_length': output_chunk_length,\n",
    "                                        'hidden_size': hidden_size,\n",
    "                                        'batch_size': batch_size,\n",
    "                                        'num_heads_attention': num_heads_attention,\n",
    "                                        'dropout': dropout,\n",
    "                                        'takens_tau': takens_tau,\n",
    "                                        'lr': lr,\n",
    "                                    })\n",
    "                                except:\n",
    "                                    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    num_heads_attention = trial.suggest_int(\"num_heads_attention\", 0, 2)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(in_len - 1))\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.2)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = DA_RNN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        num_heads_attention=2**num_heads_attention,\n",
    "        dropout=dropout,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DA_RNN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    num_heads_attention=2**study.best_trial.params['num_heads_attention'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    num_heads_attention = trial.suggest_int(\"num_heads_attention\", 0, 2)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(in_len - 1))\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.2)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = DA_RNN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        num_heads_attention=2**num_heads_attention,\n",
    "        dropout=dropout,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DA_RNN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    num_heads_attention=2**study.best_trial.params['num_heads_attention'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando U2 e MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 800)\n",
    "    num_heads_attention = trial.suggest_int(\"num_heads_attention\", 0, 2)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(in_len - 1))\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.2)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = DA_RNN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        num_heads_attention=2**num_heads_attention,\n",
    "        dropout=dropout,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_scaled, preds)\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DA_RNN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    num_heads_attention=2**study.best_trial.params['num_heads_attention'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Brasil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Janela deslizante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_mlp = []\n",
    "\n",
    "for input_chunk_length in range(20, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "       for hidden_size in [2**i for i in range(3, 7)]:\n",
    "           for batch_size in [2**i for i in range(3, 7)]:\n",
    "               for lr in [10**(-i) for i in range(2, 5)]:\n",
    "                    try:\n",
    "                        model = MLP(\n",
    "                            input_chunk_length=input_chunk_length,\n",
    "                            output_chunk_length=output_chunk_length,\n",
    "                            hidden_size=hidden_size,\n",
    "                            batch_size=batch_size,\n",
    "                            n_epochs=400,\n",
    "                            lr=lr,\n",
    "                            device=\"cuda\",\n",
    "                            random_state = 0\n",
    "                        )\n",
    "                        model.fit(train_scaled)\n",
    "                        pred_series, mape_mlp, sle_mlp = eval_model(\n",
    "                            model,\n",
    "                            len(val_scaled),\n",
    "                            series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "                            val_scaled,\n",
    "                            target_series = train_scaled,\n",
    "                            returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                            plot = False,\n",
    "                        )\n",
    "                        uTheil = UTheil()\n",
    "                        u1_mlp = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "                        u2_mlp = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "                        print({\n",
    "                            'MAPE': mape_mlp,\n",
    "                            'SLE': sle_mlp,\n",
    "                            'U1': u1_mlp,\n",
    "                            'U2': u1_mlp,\n",
    "                            'lr': lr,\n",
    "                            'input_chunk_length': input_chunk_length,\n",
    "                            'output_chunk_length': output_chunk_length,\n",
    "                            'hidden_size': hidden_size,\n",
    "                            'batch_size': batch_size,\n",
    "                        })\n",
    "                        models_mlp.append({\n",
    "                            'MAPE': mape_mlp,\n",
    "                            'SLE': sle_mlp,\n",
    "                            'U1': u1_mlp,\n",
    "                            'U2': u1_mlp,\n",
    "                            'lr': lr,\n",
    "                            'input_chunk_length': input_chunk_length,\n",
    "                            'output_chunk_length': output_chunk_length,\n",
    "                            'hidden_size': hidden_size,\n",
    "                            'batch_size': batch_size,\n",
    "                        })\n",
    "                    except:\n",
    "                        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_mlp in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_mlp, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_mlp, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_mlp, key=lambda d: d[i])['hidden_size'],\n",
    "                                'batch_size': min(models_mlp, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_mlp, key=lambda d: d[i])['lr'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_mlp['name'])\n",
    "    model = MLP(\n",
    "        input_chunk_length=best_model_mlp['input_chunk_length'],\n",
    "        output_chunk_length=best_model_mlp['output_chunk_length'],\n",
    "        hidden_size=best_model_mlp['hidden_size'],\n",
    "        batch_size=best_model_mlp['batch_size'],\n",
    "        n_epochs=400,\n",
    "        lr=best_model_mlp['lr'],\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit(train_scaled)\n",
    "    pred_series, mape_mlp, sle_mlp = eval_model(\n",
    "        model,\n",
    "        len(val_scaled),\n",
    "        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_scaled,\n",
    "        target_series = train_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_mlp = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "    u2_mlp = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_mlp)\n",
    "    print('U2: ', u2_mlp)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = MLP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        n_epochs=400,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    n_epochs=400,\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = MLP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        n_epochs=400,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    n_epochs=400,\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando MAPE e U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = MLP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        n_epochs=400,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_scaled, preds)\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    n_epochs=400,\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Takens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_mlp = []\n",
    "\n",
    "for input_chunk_length in range(20, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "       for hidden_size in [2**i for i in range(3, 7)]:\n",
    "           for batch_size in [2**i for i in range(3, 7)]:\n",
    "               for lr in [10**(-i) for i in range(2, 5)]:\n",
    "                   for takens_tau in range(1, len(train)//(input_chunk_length - 1)):\n",
    "                        try:\n",
    "                            model = MLP(\n",
    "                                input_chunk_length=input_chunk_length,\n",
    "                                output_chunk_length=output_chunk_length,\n",
    "                                hidden_size=hidden_size,\n",
    "                                batch_size=batch_size,\n",
    "                                window_model = Takens(tau=takens_tau),\n",
    "                                n_epochs=400,\n",
    "                                lr=lr,\n",
    "                                device=\"cuda\",\n",
    "                                random_state = 0\n",
    "                            )\n",
    "                            model.fit(train_scaled)\n",
    "                            pred_series, mape_mlp, sle_mlp = eval_model(\n",
    "                                model,\n",
    "                                len(val_scaled),\n",
    "                                series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                val_scaled,\n",
    "                                target_series = train_scaled,\n",
    "                                returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                plot = False,\n",
    "                            )\n",
    "                            uTheil = UTheil()\n",
    "                            u1_mlp = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "                            u2_mlp = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "                            print({\n",
    "                                'MAPE': mape_mlp,\n",
    "                                'SLE': sle_mlp,\n",
    "                                'U1': u1_mlp,\n",
    "                                'U2': u1_mlp,\n",
    "                                'lr': lr,\n",
    "                                'input_chunk_length': input_chunk_length,\n",
    "                                'output_chunk_length': output_chunk_length,\n",
    "                                'hidden_size': hidden_size,\n",
    "                                'batch_size': batch_size,\n",
    "                                'takens_tau': takens_tau,\n",
    "                            })\n",
    "                            models_mlp.append({\n",
    "                                'MAPE': mape_mlp,\n",
    "                                'SLE': sle_mlp,\n",
    "                                'U1': u1_mlp,\n",
    "                                'U2': u1_mlp,\n",
    "                                'lr': lr,\n",
    "                                'input_chunk_length': input_chunk_length,\n",
    "                                'output_chunk_length': output_chunk_length,\n",
    "                                'hidden_size': hidden_size,\n",
    "                                'batch_size': batch_size,\n",
    "                                'takens_tau': takens_tau,\n",
    "                            })\n",
    "                        except:\n",
    "                            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_mlp in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_mlp, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_mlp, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_mlp, key=lambda d: d[i])['hidden_size'],\n",
    "                                'batch_size': min(models_mlp, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_mlp, key=lambda d: d[i])['lr'],\n",
    "                                'takens_tau': min(models_mlp, key=lambda d: d[i])['takens_tau'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_mlp['name'])\n",
    "    model = MLP(\n",
    "        input_chunk_length=best_model_mlp['input_chunk_length'],\n",
    "        output_chunk_length=best_model_mlp['output_chunk_length'],\n",
    "        hidden_size=best_model_mlp['hidden_size'],\n",
    "        batch_size=best_model_mlp['batch_size'],\n",
    "        n_epochs=400,\n",
    "        lr=best_model_mlp['lr'],\n",
    "        window_model = Takens(tau=best_model_mlp['takens_tau']),\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit(train_scaled)\n",
    "    pred_series, mape_mlp, sle_mlp = eval_model(\n",
    "        model,\n",
    "        len(val_scaled),\n",
    "        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_scaled,\n",
    "        target_series = train_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_mlp = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "    u2_mlp = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_mlp)\n",
    "    print('U2: ', u2_mlp)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(in_len - 1))\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = MLP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(in_len - 1))\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = MLP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando MAPE e U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(in_len - 1))\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = MLP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_scaled, preds)\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Brasil (detrend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Janela deslizante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_mlp = []\n",
    "\n",
    "for input_chunk_length in range(20, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "       for hidden_size in [2**i for i in range(3, 7)]:\n",
    "           for batch_size in [2**i for i in range(3, 7)]:\n",
    "               for lr in [10**(-i) for i in range(2, 5)]:\n",
    "                    try:\n",
    "                        model = MLP(\n",
    "                            input_chunk_length=input_chunk_length,\n",
    "                            output_chunk_length=output_chunk_length,\n",
    "                            hidden_size=hidden_size,\n",
    "                            batch_size=batch_size,\n",
    "                            n_epochs=400,\n",
    "                            lr=lr,\n",
    "                            device=\"cuda\",\n",
    "                            random_state = 0\n",
    "                        )\n",
    "                        model.fit(train_detrend_scaled)\n",
    "                        pred_series, mape_mlp, sle_mlp = eval_model(\n",
    "                            model,\n",
    "                            len(val_detrend_scaled),\n",
    "                            series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "                            val_detrend_scaled,\n",
    "                            target_series = train_detrend_scaled,\n",
    "                            returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                            plot = False,\n",
    "                        )\n",
    "                        uTheil = UTheil()\n",
    "                        u1_mlp = uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)])\n",
    "                        u2_mlp = uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)])\n",
    "                        print({\n",
    "                            'MAPE': mape_mlp,\n",
    "                            'SLE': sle_mlp,\n",
    "                            'U1': u1_mlp,\n",
    "                            'U2': u1_mlp,\n",
    "                            'lr': lr,\n",
    "                            'input_chunk_length': input_chunk_length,\n",
    "                            'output_chunk_length': output_chunk_length,\n",
    "                            'hidden_size': hidden_size,\n",
    "                            'batch_size': batch_size,\n",
    "                        })\n",
    "                        models_mlp.append({\n",
    "                            'MAPE': mape_mlp,\n",
    "                            'SLE': sle_mlp,\n",
    "                            'U1': u1_mlp,\n",
    "                            'U2': u1_mlp,\n",
    "                            'lr': lr,\n",
    "                            'input_chunk_length': input_chunk_length,\n",
    "                            'output_chunk_length': output_chunk_length,\n",
    "                            'hidden_size': hidden_size,\n",
    "                            'batch_size': batch_size,\n",
    "                        })\n",
    "                    except:\n",
    "                        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_mlp in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_mlp, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_mlp, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_mlp, key=lambda d: d[i])['hidden_size'],\n",
    "                                'batch_size': min(models_mlp, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_mlp, key=lambda d: d[i])['lr'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_mlp['name'])\n",
    "    model = MLP(\n",
    "        input_chunk_length=best_model_mlp['input_chunk_length'],\n",
    "        output_chunk_length=best_model_mlp['output_chunk_length'],\n",
    "        hidden_size=best_model_mlp['hidden_size'],\n",
    "        batch_size=best_model_mlp['batch_size'],\n",
    "        n_epochs=400,\n",
    "        lr=best_model_mlp['lr'],\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit(train_detrend_scaled)\n",
    "    pred_series, mape_mlp, sle_mlp = eval_model(\n",
    "        model,\n",
    "        len(val_detrend_scaled),\n",
    "        series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_detrend_scaled,\n",
    "        target_series = train_detrend_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_mlp = uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)])\n",
    "    u2_mlp = uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_mlp)\n",
    "    print('U2: ', u2_mlp)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = MLP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        n_epochs=400,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_detrend_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    mapes = mape(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    n_epochs=400,\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_detrend_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = MLP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        n_epochs=400,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_detrend_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    n_epochs=400,\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_detrend_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando MAPE e U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = MLP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        n_epochs=400,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_detrend_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_detrend_scaled, preds)\n",
    "    mapes = mape(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    n_epochs=400,\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_detrend_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Takens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_mlp = []\n",
    "\n",
    "for input_chunk_length in range(20, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "       for hidden_size in [2**i for i in range(3, 7)]:\n",
    "           for batch_size in [2**i for i in range(3, 7)]:\n",
    "               for lr in [10**(-i) for i in range(2, 5)]:\n",
    "                   for takens_tau in range(1, len(train)//(input_chunk_length - 1)):\n",
    "                        try:\n",
    "                            model = MLP(\n",
    "                                input_chunk_length=input_chunk_length,\n",
    "                                output_chunk_length=output_chunk_length,\n",
    "                                hidden_size=hidden_size,\n",
    "                                batch_size=batch_size,\n",
    "                                window_model = Takens(tau=takens_tau),\n",
    "                                n_epochs=400,\n",
    "                                lr=lr,\n",
    "                                device=\"cuda\",\n",
    "                                random_state = 0\n",
    "                            )\n",
    "                            model.fit(train_detrend_scaled)\n",
    "                            pred_series, mape_mlp, sle_mlp = eval_model(\n",
    "                                model,\n",
    "                                len(val_detrend_scaled),\n",
    "                                series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                val_detrend_scaled,\n",
    "                                target_series = train_detrend_scaled,\n",
    "                                returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                plot = False,\n",
    "                            )\n",
    "                            uTheil = UTheil()\n",
    "                            u1_mlp = uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)])\n",
    "                            u2_mlp = uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)])\n",
    "                            print({\n",
    "                                'MAPE': mape_mlp,\n",
    "                                'SLE': sle_mlp,\n",
    "                                'U1': u1_mlp,\n",
    "                                'U2': u1_mlp,\n",
    "                                'lr': lr,\n",
    "                                'input_chunk_length': input_chunk_length,\n",
    "                                'output_chunk_length': output_chunk_length,\n",
    "                                'hidden_size': hidden_size,\n",
    "                                'batch_size': batch_size,\n",
    "                                'takens_tau': takens_tau,\n",
    "                            })\n",
    "                            models_mlp.append({\n",
    "                                'MAPE': mape_mlp,\n",
    "                                'SLE': sle_mlp,\n",
    "                                'U1': u1_mlp,\n",
    "                                'U2': u1_mlp,\n",
    "                                'lr': lr,\n",
    "                                'input_chunk_length': input_chunk_length,\n",
    "                                'output_chunk_length': output_chunk_length,\n",
    "                                'hidden_size': hidden_size,\n",
    "                                'batch_size': batch_size,\n",
    "                                'takens_tau': takens_tau,\n",
    "                            })\n",
    "                        except:\n",
    "                            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_mlp in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_mlp, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_mlp, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_mlp, key=lambda d: d[i])['hidden_size'],\n",
    "                                'batch_size': min(models_mlp, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_mlp, key=lambda d: d[i])['lr'],\n",
    "                                'takens_tau': min(models_mlp, key=lambda d: d[i])['takens_tau'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_mlp['name'])\n",
    "    model = MLP(\n",
    "        input_chunk_length=best_model_mlp['input_chunk_length'],\n",
    "        output_chunk_length=best_model_mlp['output_chunk_length'],\n",
    "        hidden_size=best_model_mlp['hidden_size'],\n",
    "        batch_size=best_model_mlp['batch_size'],\n",
    "        n_epochs=400,\n",
    "        lr=best_model_mlp['lr'],\n",
    "        window_model = Takens(tau=best_model_mlp['takens_tau']),\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit(train_detrend_scaled)\n",
    "    pred_series, mape_mlp, sle_mlp = eval_model(\n",
    "        model,\n",
    "        len(val_detrend_scaled),\n",
    "        series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_detrend_scaled,\n",
    "        target_series = train_detrend_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_mlp = uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)])\n",
    "    u2_mlp = uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_mlp)\n",
    "    print('U2: ', u2_mlp)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(in_len - 1))\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = MLP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_detrend_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    mapes = mape(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_detrend_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(in_len - 1))\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = MLP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_detrend_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_detrend_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando MAPE e U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(in_len - 1))\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = MLP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_detrend_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_detrend_scaled, preds)\n",
    "    mapes = mape(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_detrend_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Brasil + Sudeste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Janela deslizante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_mlp = []\n",
    "\n",
    "for input_chunk_length in range(20, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "       for hidden_size in [2**i for i in range(3, 7)]:\n",
    "           for batch_size in [2**i for i in range(3, 7)]:\n",
    "               for lr in [10**(-i) for i in range(2, 5)]:\n",
    "                    try:\n",
    "                        model = MLP(\n",
    "                            input_chunk_length=input_chunk_length,\n",
    "                            output_chunk_length=output_chunk_length,\n",
    "                            hidden_size=hidden_size,\n",
    "                            batch_size=batch_size,\n",
    "                            n_epochs=400,\n",
    "                            lr=lr,\n",
    "                            device=\"cuda\",\n",
    "                            random_state = 0\n",
    "                        )\n",
    "                        model.fit([train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())])\n",
    "                        pred_series, mape_mlp, sle_mlp = eval_model(\n",
    "                            model,\n",
    "                            len(val_scaled),\n",
    "                            series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "                            val_scaled,\n",
    "                            target_series = train_scaled,\n",
    "                            returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                            plot = False,\n",
    "                        )\n",
    "                        uTheil = UTheil()\n",
    "                        u1_mlp = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "                        u2_mlp = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "                        print({\n",
    "                            'MAPE': mape_mlp,\n",
    "                            'SLE': sle_mlp,\n",
    "                            'U1': u1_mlp,\n",
    "                            'U2': u1_mlp,\n",
    "                            'lr': lr,\n",
    "                            'input_chunk_length': input_chunk_length,\n",
    "                            'output_chunk_length': output_chunk_length,\n",
    "                            'hidden_size': hidden_size,\n",
    "                            'batch_size': batch_size,\n",
    "                        })\n",
    "                        models_mlp.append({\n",
    "                            'MAPE': mape_mlp,\n",
    "                            'SLE': sle_mlp,\n",
    "                            'U1': u1_mlp,\n",
    "                            'U2': u1_mlp,\n",
    "                            'lr': lr,\n",
    "                            'input_chunk_length': input_chunk_length,\n",
    "                            'output_chunk_length': output_chunk_length,\n",
    "                            'hidden_size': hidden_size,\n",
    "                            'batch_size': batch_size,\n",
    "                        })\n",
    "                    except:\n",
    "                        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_mlp in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_mlp, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_mlp, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_mlp, key=lambda d: d[i])['hidden_size'],\n",
    "                                'batch_size': min(models_mlp, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_mlp, key=lambda d: d[i])['lr'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_mlp['name'])\n",
    "    model = MLP(\n",
    "        input_chunk_length=best_model_mlp['input_chunk_length'],\n",
    "        output_chunk_length=best_model_mlp['output_chunk_length'],\n",
    "        hidden_size=best_model_mlp['hidden_size'],\n",
    "        batch_size=best_model_mlp['batch_size'],\n",
    "        n_epochs=400,\n",
    "        lr=best_model_mlp['lr'],\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit([train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())])\n",
    "    pred_series, mape_mlp, sle_mlp = eval_model(\n",
    "        model,\n",
    "        len(val_scaled),\n",
    "        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_scaled,\n",
    "        target_series = train_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_mlp = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "    u2_mlp = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_mlp)\n",
    "    print('U2: ', u2_mlp)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = MLP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        n_epochs=400,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    n_epochs=400,\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = MLP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        n_epochs=400,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    n_epochs=400,\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando MAPE e U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = MLP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        n_epochs=400,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_scaled, preds)\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    n_epochs=400,\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Takens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_mlp = []\n",
    "\n",
    "for input_chunk_length in range(20, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "       for hidden_size in [2**i for i in range(3, 7)]:\n",
    "           for batch_size in [2**i for i in range(3, 7)]:\n",
    "               for lr in [10**(-i) for i in range(2, 5)]:\n",
    "                   for takens_tau in range(1, len(train)//(input_chunk_length - 1)):\n",
    "                        try:\n",
    "                            model = MLP(\n",
    "                                input_chunk_length=input_chunk_length,\n",
    "                                output_chunk_length=output_chunk_length,\n",
    "                                hidden_size=hidden_size,\n",
    "                                batch_size=batch_size,\n",
    "                                window_model = Takens(tau=takens_tau),\n",
    "                                n_epochs=400,\n",
    "                                lr=lr,\n",
    "                                device=\"cuda\",\n",
    "                                random_state = 0\n",
    "                            )\n",
    "                            model.fit([train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())])\n",
    "                            pred_series, mape_mlp, sle_mlp = eval_model(\n",
    "                                model,\n",
    "                                len(val_scaled),\n",
    "                                series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                val_scaled,\n",
    "                                target_series = train_scaled,\n",
    "                                returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                plot = False,\n",
    "                            )\n",
    "                            uTheil = UTheil()\n",
    "                            u1_mlp = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "                            u2_mlp = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "                            print({\n",
    "                                'MAPE': mape_mlp,\n",
    "                                'SLE': sle_mlp,\n",
    "                                'U1': u1_mlp,\n",
    "                                'U2': u1_mlp,\n",
    "                                'lr': lr,\n",
    "                                'input_chunk_length': input_chunk_length,\n",
    "                                'output_chunk_length': output_chunk_length,\n",
    "                                'hidden_size': hidden_size,\n",
    "                                'batch_size': batch_size,\n",
    "                                'takens_tau': takens_tau,\n",
    "                            })\n",
    "                            models_mlp.append({\n",
    "                                'MAPE': mape_mlp,\n",
    "                                'SLE': sle_mlp,\n",
    "                                'U1': u1_mlp,\n",
    "                                'U2': u1_mlp,\n",
    "                                'lr': lr,\n",
    "                                'input_chunk_length': input_chunk_length,\n",
    "                                'output_chunk_length': output_chunk_length,\n",
    "                                'hidden_size': hidden_size,\n",
    "                                'batch_size': batch_size,\n",
    "                                'takens_tau': takens_tau,\n",
    "                            })\n",
    "                        except:\n",
    "                            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_mlp in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_mlp, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_mlp, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_mlp, key=lambda d: d[i])['hidden_size'],\n",
    "                                'batch_size': min(models_mlp, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_mlp, key=lambda d: d[i])['lr'],\n",
    "                                'takens_tau': min(models_mlp, key=lambda d: d[i])['takens_tau'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_mlp['name'])\n",
    "    model = MLP(\n",
    "        input_chunk_length=best_model_mlp['input_chunk_length'],\n",
    "        output_chunk_length=best_model_mlp['output_chunk_length'],\n",
    "        hidden_size=best_model_mlp['hidden_size'],\n",
    "        batch_size=best_model_mlp['batch_size'],\n",
    "        n_epochs=400,\n",
    "        lr=best_model_mlp['lr'],\n",
    "        window_model = Takens(tau=best_model_mlp['takens_tau']),\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit([train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())])\n",
    "    pred_series, mape_mlp, sle_mlp = eval_model(\n",
    "        model,\n",
    "        len(val_scaled),\n",
    "        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_scaled,\n",
    "        target_series = train_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_mlp = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "    u2_mlp = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_mlp)\n",
    "    print('U2: ', u2_mlp)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(input_chunk_length - 1))\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = MLP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(input_chunk_length - 1))\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = MLP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando MAPE e U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(input_chunk_length - 1))\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = MLP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_scaled, preds)\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Brasil (detrend) + Sudeste (detrend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Janela deslizante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_mlp = []\n",
    "\n",
    "for input_chunk_length in range(20, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "       for hidden_size in [2**i for i in range(3, 7)]:\n",
    "           for batch_size in [2**i for i in range(3, 7)]:\n",
    "               for lr in [10**(-i) for i in range(2, 5)]:\n",
    "                    try:\n",
    "                        model = MLP(\n",
    "                            input_chunk_length=input_chunk_length,\n",
    "                            output_chunk_length=output_chunk_length,\n",
    "                            hidden_size=hidden_size,\n",
    "                            batch_size=batch_size,\n",
    "                            n_epochs=400,\n",
    "                            lr=lr,\n",
    "                            device=\"cuda\",\n",
    "                            random_state = 0\n",
    "                        )\n",
    "                        model.fit([train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())])\n",
    "                        pred_series, mape_mlp, sle_mlp = eval_model(\n",
    "                            model,\n",
    "                            len(val_detrend_scaled),\n",
    "                            series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "                            val_detrend_scaled,\n",
    "                            target_series = train_detrend_scaled,\n",
    "                            returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                            plot = False,\n",
    "                        )\n",
    "                        uTheil = UTheil()\n",
    "                        u1_mlp = uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)])\n",
    "                        u2_mlp = uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)])\n",
    "                        print({\n",
    "                            'MAPE': mape_mlp,\n",
    "                            'SLE': sle_mlp,\n",
    "                            'U1': u1_mlp,\n",
    "                            'U2': u1_mlp,\n",
    "                            'lr': lr,\n",
    "                            'input_chunk_length': input_chunk_length,\n",
    "                            'output_chunk_length': output_chunk_length,\n",
    "                            'hidden_size': hidden_size,\n",
    "                            'batch_size': batch_size,\n",
    "                        })\n",
    "                        models_mlp.append({\n",
    "                            'MAPE': mape_mlp,\n",
    "                            'SLE': sle_mlp,\n",
    "                            'U1': u1_mlp,\n",
    "                            'U2': u1_mlp,\n",
    "                            'lr': lr,\n",
    "                            'input_chunk_length': input_chunk_length,\n",
    "                            'output_chunk_length': output_chunk_length,\n",
    "                            'hidden_size': hidden_size,\n",
    "                            'batch_size': batch_size,\n",
    "                        })\n",
    "                    except:\n",
    "                        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_mlp in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_mlp, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_mlp, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_mlp, key=lambda d: d[i])['hidden_size'],\n",
    "                                'batch_size': min(models_mlp, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_mlp, key=lambda d: d[i])['lr'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_mlp['name'])\n",
    "    model = MLP(\n",
    "        input_chunk_length=best_model_mlp['input_chunk_length'],\n",
    "        output_chunk_length=best_model_mlp['output_chunk_length'],\n",
    "        hidden_size=best_model_mlp['hidden_size'],\n",
    "        batch_size=best_model_mlp['batch_size'],\n",
    "        n_epochs=400,\n",
    "        lr=best_model_mlp['lr'],\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit([train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())])\n",
    "    pred_series, mape_mlp, sle_mlp = eval_model(\n",
    "        model,\n",
    "        len(val_detrend_scaled),\n",
    "        series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_detrend_scaled,\n",
    "        target_series = train_detrend_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_mlp = uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)])\n",
    "    u2_mlp = uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_mlp)\n",
    "    print('U2: ', u2_mlp)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = MLP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        n_epochs=400,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    mapes = mape(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    n_epochs=400,\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = MLP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        n_epochs=400,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    n_epochs=400,\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando MAPE e U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = MLP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        n_epochs=400,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_detrend_scaled, preds)\n",
    "    mapes = mape(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    n_epochs=400,\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Takens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_mlp = []\n",
    "\n",
    "for input_chunk_length in range(20, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "       for hidden_size in [2**i for i in range(3, 7)]:\n",
    "           for batch_size in [2**i for i in range(3, 7)]:\n",
    "               for lr in [10**(-i) for i in range(2, 5)]:\n",
    "                   for takens_tau in range(1, len(train)//(input_chunk_length - 1)):\n",
    "                        try:\n",
    "                            model = MLP(\n",
    "                                input_chunk_length=input_chunk_length,\n",
    "                                output_chunk_length=output_chunk_length,\n",
    "                                hidden_size=hidden_size,\n",
    "                                batch_size=batch_size,\n",
    "                                window_model = Takens(tau=takens_tau),\n",
    "                                n_epochs=400,\n",
    "                                lr=lr,\n",
    "                                device=\"cuda\",\n",
    "                                random_state = 0\n",
    "                            )\n",
    "                            model.fit([train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())])\n",
    "                            pred_series, mape_mlp, sle_mlp = eval_model(\n",
    "                                model,\n",
    "                                len(val_detrend_scaled),\n",
    "                                series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                val_detrend_scaled,\n",
    "                                target_series = train_detrend_scaled,\n",
    "                                returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                plot = False,\n",
    "                            )\n",
    "                            uTheil = UTheil()\n",
    "                            u1_mlp = uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)])\n",
    "                            u2_mlp = uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)])\n",
    "                            print({\n",
    "                                'MAPE': mape_mlp,\n",
    "                                'SLE': sle_mlp,\n",
    "                                'U1': u1_mlp,\n",
    "                                'U2': u1_mlp,\n",
    "                                'lr': lr,\n",
    "                                'input_chunk_length': input_chunk_length,\n",
    "                                'output_chunk_length': output_chunk_length,\n",
    "                                'hidden_size': hidden_size,\n",
    "                                'batch_size': batch_size,\n",
    "                                'takens_tau': takens_tau,\n",
    "                            })\n",
    "                            models_mlp.append({\n",
    "                                'MAPE': mape_mlp,\n",
    "                                'SLE': sle_mlp,\n",
    "                                'U1': u1_mlp,\n",
    "                                'U2': u1_mlp,\n",
    "                                'lr': lr,\n",
    "                                'input_chunk_length': input_chunk_length,\n",
    "                                'output_chunk_length': output_chunk_length,\n",
    "                                'hidden_size': hidden_size,\n",
    "                                'batch_size': batch_size,\n",
    "                                'takens_tau': takens_tau,\n",
    "                            })\n",
    "                        except:\n",
    "                            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_mlp in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_mlp, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_mlp, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_mlp, key=lambda d: d[i])['hidden_size'],\n",
    "                                'batch_size': min(models_mlp, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_mlp, key=lambda d: d[i])['lr'],\n",
    "                                'takens_tau': min(models_mlp, key=lambda d: d[i])['takens_tau'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_mlp['name'])\n",
    "    model = MLP(\n",
    "        input_chunk_length=best_model_mlp['input_chunk_length'],\n",
    "        output_chunk_length=best_model_mlp['output_chunk_length'],\n",
    "        hidden_size=best_model_mlp['hidden_size'],\n",
    "        batch_size=best_model_mlp['batch_size'],\n",
    "        n_epochs=400,\n",
    "        lr=best_model_mlp['lr'],\n",
    "        window_model = Takens(tau=best_model_mlp['takens_tau']),\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit([train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())])\n",
    "    pred_series, mape_mlp, sle_mlp = eval_model(\n",
    "        model,\n",
    "        len(val_detrend_scaled),\n",
    "        series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_detrend_scaled,\n",
    "        target_series = train_detrend_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_mlp = uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)])\n",
    "    u2_mlp = uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_mlp)\n",
    "    print('U2: ', u2_mlp)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(in_len - 1))\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = MLP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    mapes = mape(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(in_len - 1))\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = MLP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando MAPE e U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(in_len - 1))\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = MLP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_detrend_scaled, preds)\n",
    "    mapes = mape(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Brasil + Óleo de Soja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Janela deslizante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_mlp = []\n",
    "\n",
    "for input_chunk_length in range(20, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "       for hidden_size in [2**i for i in range(3, 7)]:\n",
    "           for batch_size in [2**i for i in range(3, 7)]:\n",
    "               for lr in [10**(-i) for i in range(2, 5)]:\n",
    "                    try:\n",
    "                        model = MLP(\n",
    "                            input_chunk_length=input_chunk_length,\n",
    "                            output_chunk_length=output_chunk_length,\n",
    "                            hidden_size=hidden_size,\n",
    "                            batch_size=batch_size,\n",
    "                            n_epochs=400,\n",
    "                            lr=lr,\n",
    "                            device=\"cuda\",\n",
    "                            random_state = 0\n",
    "                        )\n",
    "                        model.fit([train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())])\n",
    "                        pred_series, mape_mlp, sle_mlp = eval_model(\n",
    "                            model,\n",
    "                            len(val_scaled),\n",
    "                            series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "                            val_scaled,\n",
    "                            target_series = train_scaled,\n",
    "                            returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                            plot = False,\n",
    "                        )\n",
    "                        uTheil = UTheil()\n",
    "                        u1_mlp = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "                        u2_mlp = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "                        print({\n",
    "                            'MAPE': mape_mlp,\n",
    "                            'SLE': sle_mlp,\n",
    "                            'U1': u1_mlp,\n",
    "                            'U2': u1_mlp,\n",
    "                            'lr': lr,\n",
    "                            'input_chunk_length': input_chunk_length,\n",
    "                            'output_chunk_length': output_chunk_length,\n",
    "                            'hidden_size': hidden_size,\n",
    "                            'batch_size': batch_size,\n",
    "                        })\n",
    "                        models_mlp.append({\n",
    "                            'MAPE': mape_mlp,\n",
    "                            'SLE': sle_mlp,\n",
    "                            'U1': u1_mlp,\n",
    "                            'U2': u1_mlp,\n",
    "                            'lr': lr,\n",
    "                            'input_chunk_length': input_chunk_length,\n",
    "                            'output_chunk_length': output_chunk_length,\n",
    "                            'hidden_size': hidden_size,\n",
    "                            'batch_size': batch_size,\n",
    "                        })\n",
    "                    except:\n",
    "                        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_mlp in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_mlp, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_mlp, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_mlp, key=lambda d: d[i])['hidden_size'],\n",
    "                                'batch_size': min(models_mlp, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_mlp, key=lambda d: d[i])['lr'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_mlp['name'])\n",
    "    model = MLP(\n",
    "        input_chunk_length=best_model_mlp['input_chunk_length'],\n",
    "        output_chunk_length=best_model_mlp['output_chunk_length'],\n",
    "        hidden_size=best_model_mlp['hidden_size'],\n",
    "        batch_size=best_model_mlp['batch_size'],\n",
    "        n_epochs=400,\n",
    "        lr=best_model_mlp['lr'],\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit([train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())])\n",
    "    pred_series, mape_mlp, sle_mlp = eval_model(\n",
    "        model,\n",
    "        len(val_scaled),\n",
    "        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_scaled,\n",
    "        target_series = train_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_mlp = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "    u2_mlp = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_mlp)\n",
    "    print('U2: ', u2_mlp)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = MLP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        n_epochs=400,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    n_epochs=400,\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = MLP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        n_epochs=400,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    n_epochs=400,\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando MAPE e U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = MLP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        n_epochs=400,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_scaled, preds)\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    n_epochs=400,\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Takens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_mlp = []\n",
    "\n",
    "for input_chunk_length in range(20, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "       for hidden_size in [2**i for i in range(3, 7)]:\n",
    "           for batch_size in [2**i for i in range(3, 7)]:\n",
    "               for lr in [10**(-i) for i in range(2, 5)]:\n",
    "                   for takens_tau in range(1, len(train)//(input_chunk_length - 1)):\n",
    "                        try:\n",
    "                            model = MLP(\n",
    "                                input_chunk_length=input_chunk_length,\n",
    "                                output_chunk_length=output_chunk_length,\n",
    "                                hidden_size=hidden_size,\n",
    "                                batch_size=batch_size,\n",
    "                                window_model = Takens(tau=takens_tau),\n",
    "                                n_epochs=400,\n",
    "                                lr=lr,\n",
    "                                device=\"cuda\",\n",
    "                                random_state = 0\n",
    "                            )\n",
    "                            model.fit([train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())])\n",
    "                            pred_series, mape_mlp, sle_mlp = eval_model(\n",
    "                                model,\n",
    "                                len(val_scaled),\n",
    "                                series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                val_scaled,\n",
    "                                target_series = train_scaled,\n",
    "                                returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                plot = False,\n",
    "                            )\n",
    "                            uTheil = UTheil()\n",
    "                            u1_mlp = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "                            u2_mlp = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "                            print({\n",
    "                                'MAPE': mape_mlp,\n",
    "                                'SLE': sle_mlp,\n",
    "                                'U1': u1_mlp,\n",
    "                                'U2': u1_mlp,\n",
    "                                'lr': lr,\n",
    "                                'input_chunk_length': input_chunk_length,\n",
    "                                'output_chunk_length': output_chunk_length,\n",
    "                                'hidden_size': hidden_size,\n",
    "                                'batch_size': batch_size,\n",
    "                                'takens_tau': takens_tau,\n",
    "                            })\n",
    "                            models_mlp.append({\n",
    "                                'MAPE': mape_mlp,\n",
    "                                'SLE': sle_mlp,\n",
    "                                'U1': u1_mlp,\n",
    "                                'U2': u1_mlp,\n",
    "                                'lr': lr,\n",
    "                                'input_chunk_length': input_chunk_length,\n",
    "                                'output_chunk_length': output_chunk_length,\n",
    "                                'hidden_size': hidden_size,\n",
    "                                'batch_size': batch_size,\n",
    "                                'takens_tau': takens_tau,\n",
    "                            })\n",
    "                        except:\n",
    "                            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_mlp in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_mlp, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_mlp, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_mlp, key=lambda d: d[i])['hidden_size'],\n",
    "                                'batch_size': min(models_mlp, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_mlp, key=lambda d: d[i])['lr'],\n",
    "                                'takens_tau': min(models_mlp, key=lambda d: d[i])['takens_tau'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_mlp['name'])\n",
    "    model = MLP(\n",
    "        input_chunk_length=best_model_mlp['input_chunk_length'],\n",
    "        output_chunk_length=best_model_mlp['output_chunk_length'],\n",
    "        hidden_size=best_model_mlp['hidden_size'],\n",
    "        batch_size=best_model_mlp['batch_size'],\n",
    "        n_epochs=400,\n",
    "        lr=best_model_mlp['lr'],\n",
    "        window_model = Takens(tau=best_model_mlp['takens_tau']),\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit([train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())])\n",
    "    pred_series, mape_mlp, sle_mlp = eval_model(\n",
    "        model,\n",
    "        len(val_scaled),\n",
    "        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_scaled,\n",
    "        target_series = train_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_mlp = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "    u2_mlp = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_mlp)\n",
    "    print('U2: ', u2_mlp)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(input_chunk_length - 1))\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = MLP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(input_chunk_length - 1))\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = MLP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando MAPE e U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(input_chunk_length - 1))\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = MLP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_scaled, preds)\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## IMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Brasil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Janela deslizante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_imp = []\n",
    "\n",
    "for input_chunk_length in range(20, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "       for hidden_size in [2**i for i in range(2, 7)]:\n",
    "           for batch_size in [2**i for i in range(2, 7)]:\n",
    "               for lr in [10**(-i) for i in range(2, 5)]:\n",
    "                   for padding in range(1,5):\n",
    "                       for kernel_size in range(1,6):\n",
    "                            try:\n",
    "                                model = IMP(\n",
    "                                    input_chunk_length=input_chunk_length,\n",
    "                                    output_chunk_length=output_chunk_length,\n",
    "                                    hidden_size=hidden_size,\n",
    "                                    batch_size=batch_size,\n",
    "                                    kernel_size=kernel_size,\n",
    "                                    padding=padding,\n",
    "                                    n_epochs=400,\n",
    "                                    lr=lr,\n",
    "                                    device=\"cuda\",\n",
    "                                    random_state = 0\n",
    "                                )\n",
    "                                model.fit(train_scaled)\n",
    "                                pred_series, mape_imp, sle_imp = eval_model(\n",
    "                                    model,\n",
    "                                    len(val_scaled),\n",
    "                                    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                    val_scaled,\n",
    "                                    target_series = train_scaled,\n",
    "                                    returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                    plot = False,\n",
    "                                )\n",
    "                                uTheil = UTheil()\n",
    "                                u1_imp = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "                                u2_imp = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "                                print({\n",
    "                                    'MAPE': mape_imp,\n",
    "                                    'SLE': sle_imp,\n",
    "                                    'U1': u1_imp,\n",
    "                                    'U2': u1_imp,\n",
    "                                    'lr': lr,\n",
    "                                    'input_chunk_length': input_chunk_length,\n",
    "                                    'output_chunk_length': output_chunk_length,\n",
    "                                    'hidden_size': hidden_size,\n",
    "                                    'batch_size': batch_size,\n",
    "                                    'padding': padding,\n",
    "                                    'kernel_size': kernel_size,\n",
    "                                })\n",
    "                                models_imp.append({\n",
    "                                    'MAPE': mape_imp,\n",
    "                                    'SLE': sle_imp,\n",
    "                                    'U1': u1_imp,\n",
    "                                    'U2': u1_imp,\n",
    "                                    'lr': lr,\n",
    "                                    'input_chunk_length': input_chunk_length,\n",
    "                                    'output_chunk_length': output_chunk_length,\n",
    "                                    'hidden_size': hidden_size,\n",
    "                                    'batch_size': batch_size,\n",
    "                                    'padding': padding,\n",
    "                                    'kernel_size': kernel_size,\n",
    "                                })\n",
    "                            except:\n",
    "                                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_imp in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_imp, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_imp, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_imp, key=lambda d: d[i])['hidden_size'],\n",
    "                                'batch_size': min(models_imp, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_imp, key=lambda d: d[i])['lr'],\n",
    "                                'padding': min(models_imp, key=lambda d: d[i])['padding'],\n",
    "                                'kernel_size': min(models_imp, key=lambda d: d[i])['kernel_size'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_imp['name'])\n",
    "    model = IMP(\n",
    "        input_chunk_length=best_model_imp['input_chunk_length'],\n",
    "        output_chunk_length=best_model_imp['output_chunk_length'],\n",
    "        hidden_size=best_model_imp['hidden_size'],\n",
    "        batch_size=best_model_imp['batch_size'],\n",
    "        kernel_size=best_model_imp['kernel_size'],\n",
    "        padding=best_model_imp['padding'],\n",
    "        n_epochs=400,\n",
    "        lr=best_model_imp['lr'],\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit(train_scaled)\n",
    "    pred_series, mape_imp, sle_imp = eval_model(\n",
    "        model,\n",
    "        len(val_scaled),\n",
    "        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_scaled,\n",
    "        target_series = train_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_imp = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "    u2_imp = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_imp)\n",
    "    print('U2: ', u2_imp)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    kernel_size = trial.suggest_int(\"kernel_size\", 1, 4)\n",
    "    padding = trial.suggest_int(\"padding\", 1, 3)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "    model = IMP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        kernel_size=kernel_size,\n",
    "        padding=padding,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IMP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    kernel_size=study.best_trial.params['kernel_size'],\n",
    "    padding=study.best_trial.params['padding'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    kernel_size = trial.suggest_int(\"kernel_size\", 1, 4)\n",
    "    padding = trial.suggest_int(\"padding\", 1, 3)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "    model = IMP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        kernel_size=kernel_size,\n",
    "        padding=padding,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IMP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    kernel_size=study.best_trial.params['kernel_size'],\n",
    "    padding=study.best_trial.params['padding'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando MAPE e U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    kernel_size = trial.suggest_int(\"kernel_size\", 1, 4)\n",
    "    padding = trial.suggest_int(\"padding\", 1, 3)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "    model = IMP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        kernel_size=kernel_size,\n",
    "        padding=padding,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_scaled, preds)\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IMP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    kernel_size=study.best_trial.params['kernel_size'],\n",
    "    padding=study.best_trial.params['padding'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Takens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_imp = []\n",
    "\n",
    "\n",
    "for input_chunk_length in range(20, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "       for hidden_size in [2**i for i in range(2, 7)]:\n",
    "           for batch_size in [2**i for i in range(2, 7)]:\n",
    "               for lr in [10**(-i) for i in range(2, 5)]:\n",
    "                   for padding in range(1,5):\n",
    "                       for kernel_size in range(1,6):\n",
    "                           for takens_tau in range(1, len(train)//(input_chunk_length - 1)):\n",
    "                                try:\n",
    "                                    model = IMP(\n",
    "                                        input_chunk_length=input_chunk_length,\n",
    "                                        output_chunk_length=output_chunk_length,\n",
    "                                        hidden_size=hidden_size,\n",
    "                                        batch_size=batch_size,\n",
    "                                        kernel_size=kernel_size,\n",
    "                                        padding=padding,\n",
    "                                        n_epochs=400,\n",
    "                                        lr=lr,\n",
    "                                        window_model = Takens(tau=takens_tau),\n",
    "                                        device=\"cuda\",\n",
    "                                        random_state = 0\n",
    "                                    )\n",
    "                                    model.fit(train_scaled)\n",
    "                                    pred_series, mape_imp, sle_imp = eval_model(\n",
    "                                        model,\n",
    "                                        len(val_scaled),\n",
    "                                        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                        val_scaled,\n",
    "                                        target_series = train_scaled,\n",
    "                                        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                        plot = False,\n",
    "                                    )\n",
    "                                    uTheil = UTheil()\n",
    "                                    u1_imp = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "                                    u2_imp = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "                                    print({\n",
    "                                        'MAPE': mape_imp,\n",
    "                                        'SLE': sle_imp,\n",
    "                                        'U1': u1_imp,\n",
    "                                        'U2': u1_imp,\n",
    "                                        'lr': lr,\n",
    "                                        'input_chunk_length': input_chunk_length,\n",
    "                                        'output_chunk_length': output_chunk_length,\n",
    "                                        'hidden_size': hidden_size,\n",
    "                                        'batch_size': batch_size,\n",
    "                                        'takens_tau': takens_tau,\n",
    "                                        'padding': padding,\n",
    "                                        'kernel_size': kernel_size,\n",
    "                                    })\n",
    "                                    models_imp.append({\n",
    "                                        'MAPE': mape_imp,\n",
    "                                        'SLE': sle_imp,\n",
    "                                        'U1': u1_imp,\n",
    "                                        'U2': u1_imp,\n",
    "                                        'lr': lr,\n",
    "                                        'input_chunk_length': input_chunk_length,\n",
    "                                        'output_chunk_length': output_chunk_length,\n",
    "                                        'hidden_size': hidden_size,\n",
    "                                        'batch_size': batch_size,\n",
    "                                        'takens_tau': takens_tau,\n",
    "                                        'padding': padding,\n",
    "                                        'kernel_size': kernel_size,\n",
    "                                    })\n",
    "                                except:\n",
    "                                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_imp in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_imp, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_imp, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_imp, key=lambda d: d[i])['hidden_size'],\n",
    "                                'batch_size': min(models_imp, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_imp, key=lambda d: d[i])['lr'],\n",
    "                                'takens_tau': min(models_imp, key=lambda d: d[i])['takens_tau'],\n",
    "                                'padding': min(models_imp, key=lambda d: d[i])['padding'],\n",
    "                                'kernel_size': min(models_imp, key=lambda d: d[i])['kernel_size'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_imp['name'])\n",
    "    model = IMP(\n",
    "        input_chunk_length=best_model_imp['input_chunk_length'],\n",
    "        output_chunk_length=best_model_imp['output_chunk_length'],\n",
    "        hidden_size=best_model_imp['hidden_size'],\n",
    "        batch_size=best_model_imp['batch_size'],\n",
    "        kernel_size=best_model_imp['kernel_size'],\n",
    "        padding=best_model_imp['padding'],\n",
    "        n_epochs=400,\n",
    "        lr=best_model_imp['lr'],\n",
    "        window_model = Takens(tau=best_model_imp['takens_tau']),\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "\n",
    "    model.fit(train_scaled)\n",
    "    pred_series, mape_imp, sle_imp = eval_model(\n",
    "        model,\n",
    "        len(val_scaled),\n",
    "        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_scaled,\n",
    "        target_series = train_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_imp = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "    u2_imp = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_imp)\n",
    "    print('U2: ', u2_imp)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(in_len - 1))\n",
    "    kernel_size = trial.suggest_int(\"kernel_size\", 1, 4)\n",
    "    padding = trial.suggest_int(\"padding\", 1, 4)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    model = IMP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        kernel_size=kernel_size,\n",
    "        padding=padding,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IMP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    kernel_size=study.best_trial.params['kernel_size'],\n",
    "    padding=study.best_trial.params['padding'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(in_len - 1))\n",
    "    kernel_size = trial.suggest_int(\"kernel_size\", 1, 4)\n",
    "    padding = trial.suggest_int(\"padding\", 1, 4)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    model = IMP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        kernel_size=kernel_size,\n",
    "        padding=padding,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IMP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    kernel_size=study.best_trial.params['kernel_size'],\n",
    "    padding=study.best_trial.params['padding'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando MAPE e U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(in_len - 1))\n",
    "    kernel_size = trial.suggest_int(\"kernel_size\", 1, 4)\n",
    "    padding = trial.suggest_int(\"padding\", 1, 4)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    model = IMP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        kernel_size=kernel_size,\n",
    "        padding=padding,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_scaled, preds)\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IMP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    kernel_size=study.best_trial.params['kernel_size'],\n",
    "    padding=study.best_trial.params['padding'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Brasil (detrend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Janela deslizante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_imp = []\n",
    "\n",
    "for input_chunk_length in range(20, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "       for hidden_size in [2**i for i in range(2, 7)]:\n",
    "           for batch_size in [2**i for i in range(2, 7)]:\n",
    "               for lr in [10**(-i) for i in range(2, 5)]:\n",
    "                   for padding in range(1,5):\n",
    "                       for kernel_size in range(1,6):\n",
    "                            try:\n",
    "                                model = IMP(\n",
    "                                    input_chunk_length=input_chunk_length,\n",
    "                                    output_chunk_length=output_chunk_length,\n",
    "                                    hidden_size=hidden_size,\n",
    "                                    batch_size=batch_size,\n",
    "                                    kernel_size=kernel_size,\n",
    "                                    padding=padding,\n",
    "                                    n_epochs=400,\n",
    "                                    lr=lr,\n",
    "                                    device=\"cuda\",\n",
    "                                    random_state = 0\n",
    "                                )\n",
    "                                model.fit(train_detrend_scaled)\n",
    "                                pred_series, mape_imp, sle_imp = eval_model(\n",
    "                                    model,\n",
    "                                    len(val_detrend_scaled),\n",
    "                                    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                    val_detrend_scaled,\n",
    "                                    target_series = train_detrend_scaled,\n",
    "                                    returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                    plot = False,\n",
    "                                )\n",
    "                                uTheil = UTheil()\n",
    "                                u1_imp = uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)])\n",
    "                                u2_imp = uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)])\n",
    "                                print({\n",
    "                                    'MAPE': mape_imp,\n",
    "                                    'SLE': sle_imp,\n",
    "                                    'U1': u1_imp,\n",
    "                                    'U2': u1_imp,\n",
    "                                    'lr': lr,\n",
    "                                    'input_chunk_length': input_chunk_length,\n",
    "                                    'output_chunk_length': output_chunk_length,\n",
    "                                    'hidden_size': hidden_size,\n",
    "                                    'batch_size': batch_size,\n",
    "                                    'padding': padding,\n",
    "                                    'kernel_size': kernel_size,\n",
    "                                })\n",
    "                                models_imp.append({\n",
    "                                    'MAPE': mape_imp,\n",
    "                                    'SLE': sle_imp,\n",
    "                                    'U1': u1_imp,\n",
    "                                    'U2': u1_imp,\n",
    "                                    'lr': lr,\n",
    "                                    'input_chunk_length': input_chunk_length,\n",
    "                                    'output_chunk_length': output_chunk_length,\n",
    "                                    'hidden_size': hidden_size,\n",
    "                                    'batch_size': batch_size,\n",
    "                                    'padding': padding,\n",
    "                                    'kernel_size': kernel_size,\n",
    "                                })\n",
    "                            except:\n",
    "                                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_imp in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_imp, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_imp, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_imp, key=lambda d: d[i])['hidden_size'],\n",
    "                                'batch_size': min(models_imp, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_imp, key=lambda d: d[i])['lr'],\n",
    "                                'padding': min(models_imp, key=lambda d: d[i])['padding'],\n",
    "                                'kernel_size': min(models_imp, key=lambda d: d[i])['kernel_size'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_imp['name'])\n",
    "    model = IMP(\n",
    "        input_chunk_length=best_model_imp['input_chunk_length'],\n",
    "        output_chunk_length=best_model_imp['output_chunk_length'],\n",
    "        hidden_size=best_model_imp['hidden_size'],\n",
    "        batch_size=best_model_imp['batch_size'],\n",
    "        kernel_size=best_model_imp['kernel_size'],\n",
    "        padding=best_model_imp['padding'],\n",
    "        n_epochs=400,\n",
    "        lr=best_model_imp['lr'],\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit(train_detrend_scaled)\n",
    "    pred_series, mape_imp, sle_imp = eval_model(\n",
    "        model,\n",
    "        len(val_detrend_scaled),\n",
    "        series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_detrend_scaled,\n",
    "        target_series = train_detrend_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_imp = uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)])\n",
    "    u2_imp = uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_imp)\n",
    "    print('U2: ', u2_imp)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    kernel_size = trial.suggest_int(\"kernel_size\", 1, 4)\n",
    "    padding = trial.suggest_int(\"padding\", 1, 3)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "    model = IMP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        kernel_size=kernel_size,\n",
    "        padding=padding,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_detrend_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    mapes = mape(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IMP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    kernel_size=study.best_trial.params['kernel_size'],\n",
    "    padding=study.best_trial.params['padding'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_detrend_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    kernel_size = trial.suggest_int(\"kernel_size\", 1, 4)\n",
    "    padding = trial.suggest_int(\"padding\", 1, 3)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "    model = IMP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        kernel_size=kernel_size,\n",
    "        padding=padding,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_detrend_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IMP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    kernel_size=study.best_trial.params['kernel_size'],\n",
    "    padding=study.best_trial.params['padding'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_detrend_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando MAPE e U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    kernel_size = trial.suggest_int(\"kernel_size\", 1, 4)\n",
    "    padding = trial.suggest_int(\"padding\", 1, 3)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "    model = IMP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        kernel_size=kernel_size,\n",
    "        padding=padding,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_detrend_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_detrend_scaled, preds)\n",
    "    mapes = mape(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IMP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    kernel_size=study.best_trial.params['kernel_size'],\n",
    "    padding=study.best_trial.params['padding'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_detrend_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Takens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_imp = []\n",
    "\n",
    "\n",
    "for input_chunk_length in range(20, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "       for hidden_size in [2**i for i in range(2, 7)]:\n",
    "           for batch_size in [2**i for i in range(2, 7)]:\n",
    "               for lr in [10**(-i) for i in range(2, 5)]:\n",
    "                   for padding in range(1,5):\n",
    "                       for kernel_size in range(1,6):\n",
    "                           for takens_tau in range(1, len(train)//(input_chunk_length - 1)):\n",
    "                                try:\n",
    "                                    model = IMP(\n",
    "                                        input_chunk_length=input_chunk_length,\n",
    "                                        output_chunk_length=output_chunk_length,\n",
    "                                        hidden_size=hidden_size,\n",
    "                                        batch_size=batch_size,\n",
    "                                        kernel_size=kernel_size,\n",
    "                                        padding=padding,\n",
    "                                        n_epochs=400,\n",
    "                                        lr=lr,\n",
    "                                        window_model = Takens(tau=takens_tau),\n",
    "                                        device=\"cuda\",\n",
    "                                        random_state = 0\n",
    "                                    )\n",
    "                                    model.fit(train_detrend_scaled)\n",
    "                                    pred_series, mape_imp, sle_imp = eval_model(\n",
    "                                        model,\n",
    "                                        len(val_detrend_scaled),\n",
    "                                        series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                        val_detrend_scaled,\n",
    "                                        target_series = train_detrend_scaled,\n",
    "                                        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                        plot = False,\n",
    "                                    )\n",
    "                                    uTheil = UTheil()\n",
    "                                    u1_imp = uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)])\n",
    "                                    u2_imp = uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)])\n",
    "                                    print({\n",
    "                                        'MAPE': mape_imp,\n",
    "                                        'SLE': sle_imp,\n",
    "                                        'U1': u1_imp,\n",
    "                                        'U2': u1_imp,\n",
    "                                        'lr': lr,\n",
    "                                        'input_chunk_length': input_chunk_length,\n",
    "                                        'output_chunk_length': output_chunk_length,\n",
    "                                        'hidden_size': hidden_size,\n",
    "                                        'batch_size': batch_size,\n",
    "                                        'takens_tau': takens_tau,\n",
    "                                        'padding': padding,\n",
    "                                        'kernel_size': kernel_size,\n",
    "                                    })\n",
    "                                    models_imp.append({\n",
    "                                        'MAPE': mape_imp,\n",
    "                                        'SLE': sle_imp,\n",
    "                                        'U1': u1_imp,\n",
    "                                        'U2': u1_imp,\n",
    "                                        'lr': lr,\n",
    "                                        'input_chunk_length': input_chunk_length,\n",
    "                                        'output_chunk_length': output_chunk_length,\n",
    "                                        'hidden_size': hidden_size,\n",
    "                                        'batch_size': batch_size,\n",
    "                                        'takens_tau': takens_tau,\n",
    "                                        'padding': padding,\n",
    "                                        'kernel_size': kernel_size,\n",
    "                                    })\n",
    "                                except:\n",
    "                                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_imp in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_imp, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_imp, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_imp, key=lambda d: d[i])['hidden_size'],\n",
    "                                'batch_size': min(models_imp, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_imp, key=lambda d: d[i])['lr'],\n",
    "                                'takens_tau': min(models_imp, key=lambda d: d[i])['takens_tau'],\n",
    "                                'padding': min(models_imp, key=lambda d: d[i])['padding'],\n",
    "                                'kernel_size': min(models_imp, key=lambda d: d[i])['kernel_size'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_imp['name'])\n",
    "    model = IMP(\n",
    "        input_chunk_length=best_model_imp['input_chunk_length'],\n",
    "        output_chunk_length=best_model_imp['output_chunk_length'],\n",
    "        hidden_size=best_model_imp['hidden_size'],\n",
    "        batch_size=best_model_imp['batch_size'],\n",
    "        kernel_size=best_model_imp['kernel_size'],\n",
    "        padding=best_model_imp['padding'],\n",
    "        n_epochs=400,\n",
    "        lr=best_model_imp['lr'],\n",
    "        window_model = Takens(tau=best_model_imp['takens_tau']),\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "\n",
    "    model.fit(train_detrend_scaled)\n",
    "    pred_series, mape_imp, sle_imp = eval_model(\n",
    "        model,\n",
    "        len(val_detrend_scaled),\n",
    "        series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_detrend_scaled,\n",
    "        target_series = train_detrend_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_imp = uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)])\n",
    "    u2_imp = uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_imp)\n",
    "    print('U2: ', u2_imp)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(in_len - 1))\n",
    "    kernel_size = trial.suggest_int(\"kernel_size\", 1, 4)\n",
    "    padding = trial.suggest_int(\"padding\", 1, 4)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    model = IMP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        kernel_size=kernel_size,\n",
    "        padding=padding,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_detrend_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    mapes = mape(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IMP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    kernel_size=study.best_trial.params['kernel_size'],\n",
    "    padding=study.best_trial.params['padding'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_detrend_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(in_len - 1))\n",
    "    kernel_size = trial.suggest_int(\"kernel_size\", 1, 4)\n",
    "    padding = trial.suggest_int(\"padding\", 1, 4)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    model = IMP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        kernel_size=kernel_size,\n",
    "        padding=padding,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_detrend_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IMP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    kernel_size=study.best_trial.params['kernel_size'],\n",
    "    padding=study.best_trial.params['padding'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_detrend_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando MAPE e U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(in_len - 1))\n",
    "    kernel_size = trial.suggest_int(\"kernel_size\", 1, 4)\n",
    "    padding = trial.suggest_int(\"padding\", 1, 4)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    model = IMP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        kernel_size=kernel_size,\n",
    "        padding=padding,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_detrend_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_detrend_scaled, preds)\n",
    "    mapes = mape(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IMP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    kernel_size=study.best_trial.params['kernel_size'],\n",
    "    padding=study.best_trial.params['padding'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_detrend_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Brasil + Sudeste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Janela deslizante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_imp = []\n",
    "\n",
    "for input_chunk_length in range(20, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "       for hidden_size in [2**i for i in range(2, 7)]:\n",
    "           for batch_size in [2**i for i in range(2, 7)]:\n",
    "               for lr in [10**(-i) for i in range(2, 5)]:\n",
    "                   for padding in range(1,5):\n",
    "                       for kernel_size in range(1,6):\n",
    "                            try:\n",
    "                                model = IMP(\n",
    "                                    input_chunk_length=input_chunk_length,\n",
    "                                    output_chunk_length=output_chunk_length,\n",
    "                                    hidden_size=hidden_size,\n",
    "                                    batch_size=batch_size,\n",
    "                                    kernel_size=kernel_size,\n",
    "                                    padding=padding,\n",
    "                                    n_epochs=400,\n",
    "                                    lr=lr,\n",
    "                                    device=\"cuda\",\n",
    "                                    random_state = 0\n",
    "                                )\n",
    "                                model.fit([train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())])\n",
    "                                pred_series, mape_imp, sle_imp = eval_model(\n",
    "                                    model,\n",
    "                                    len(val_scaled),\n",
    "                                    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                    val_scaled,\n",
    "                                    target_series = train_scaled,\n",
    "                                    returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                    plot = False,\n",
    "                                )\n",
    "                                uTheil = UTheil()\n",
    "                                u1_imp = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "                                u2_imp = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "                                print({\n",
    "                                    'MAPE': mape_imp,\n",
    "                                    'SLE': sle_imp,\n",
    "                                    'U1': u1_imp,\n",
    "                                    'U2': u1_imp,\n",
    "                                    'lr': lr,\n",
    "                                    'input_chunk_length': input_chunk_length,\n",
    "                                    'output_chunk_length': output_chunk_length,\n",
    "                                    'hidden_size': hidden_size,\n",
    "                                    'batch_size': batch_size,\n",
    "                                    'padding': padding,\n",
    "                                    'kernel_size': kernel_size,\n",
    "                                })\n",
    "                                models_imp.append({\n",
    "                                    'MAPE': mape_imp,\n",
    "                                    'SLE': sle_imp,\n",
    "                                    'U1': u1_imp,\n",
    "                                    'U2': u1_imp,\n",
    "                                    'lr': lr,\n",
    "                                    'input_chunk_length': input_chunk_length,\n",
    "                                    'output_chunk_length': output_chunk_length,\n",
    "                                    'hidden_size': hidden_size,\n",
    "                                    'batch_size': batch_size,\n",
    "                                    'padding': padding,\n",
    "                                    'kernel_size': kernel_size,\n",
    "                                })\n",
    "                            except:\n",
    "                                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_imp in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_imp, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_imp, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_imp, key=lambda d: d[i])['hidden_size'],\n",
    "                                'batch_size': min(models_imp, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_imp, key=lambda d: d[i])['lr'],\n",
    "                                'padding': min(models_imp, key=lambda d: d[i])['padding'],\n",
    "                                'kernel_size': min(models_imp, key=lambda d: d[i])['kernel_size'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_imp['name'])\n",
    "    model = IMP(\n",
    "        input_chunk_length=best_model_imp['input_chunk_length'],\n",
    "        output_chunk_length=best_model_imp['output_chunk_length'],\n",
    "        hidden_size=best_model_imp['hidden_size'],\n",
    "        batch_size=best_model_imp['batch_size'],\n",
    "        kernel_size=best_model_imp['kernel_size'],\n",
    "        padding=best_model_imp['padding'],\n",
    "        n_epochs=400,\n",
    "        lr=best_model_imp['lr'],\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit([train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())])\n",
    "    pred_series, mape_imp, sle_imp = eval_model(\n",
    "        model,\n",
    "        len(val_scaled),\n",
    "        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_scaled,\n",
    "        target_series = train_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_imp = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "    u2_imp = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_imp)\n",
    "    print('U2: ', u2_imp)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    kernel_size = trial.suggest_int(\"kernel_size\", 1, 4)\n",
    "    padding = trial.suggest_int(\"padding\", 1, 3)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "    model = IMP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        kernel_size=kernel_size,\n",
    "        padding=padding,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IMP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    kernel_size=study.best_trial.params['kernel_size'],\n",
    "    padding=study.best_trial.params['padding'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    kernel_size = trial.suggest_int(\"kernel_size\", 1, 4)\n",
    "    padding = trial.suggest_int(\"padding\", 1, 3)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "    model = IMP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        kernel_size=kernel_size,\n",
    "        padding=padding,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IMP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    kernel_size=study.best_trial.params['kernel_size'],\n",
    "    padding=study.best_trial.params['padding'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando MAPE e U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    kernel_size = trial.suggest_int(\"kernel_size\", 1, 4)\n",
    "    padding = trial.suggest_int(\"padding\", 1, 3)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "    model = IMP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        kernel_size=kernel_size,\n",
    "        padding=padding,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_scaled, preds)\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IMP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    kernel_size=study.best_trial.params['kernel_size'],\n",
    "    padding=study.best_trial.params['padding'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Takens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_imp = []\n",
    "\n",
    "\n",
    "for input_chunk_length in range(20, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "       for hidden_size in [2**i for i in range(2, 7)]:\n",
    "           for batch_size in [2**i for i in range(2, 7)]:\n",
    "               for lr in [10**(-i) for i in range(2, 5)]:\n",
    "                   for padding in range(1,5):\n",
    "                       for kernel_size in range(1,6):\n",
    "                           for takens_tau in range(1, len(train)//(input_chunk_length - 1)):\n",
    "                                try:\n",
    "                                    model = IMP(\n",
    "                                        input_chunk_length=input_chunk_length,\n",
    "                                        output_chunk_length=output_chunk_length,\n",
    "                                        hidden_size=hidden_size,\n",
    "                                        batch_size=batch_size,\n",
    "                                        kernel_size=kernel_size,\n",
    "                                        padding=padding,\n",
    "                                        n_epochs=400,\n",
    "                                        lr=lr,\n",
    "                                        window_model = Takens(tau=takens_tau),\n",
    "                                        device=\"cuda\",\n",
    "                                        random_state = 0\n",
    "                                    )\n",
    "                                    model.fit([train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())])\n",
    "                                    pred_series, mape_imp, sle_imp = eval_model(\n",
    "                                        model,\n",
    "                                        len(val_scaled),\n",
    "                                        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                        val_scaled,\n",
    "                                        target_series = train_scaled,\n",
    "                                        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                        plot = False,\n",
    "                                    )\n",
    "                                    uTheil = UTheil()\n",
    "                                    u1_imp = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "                                    u2_imp = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "                                    print({\n",
    "                                        'MAPE': mape_imp,\n",
    "                                        'SLE': sle_imp,\n",
    "                                        'U1': u1_imp,\n",
    "                                        'U2': u1_imp,\n",
    "                                        'lr': lr,\n",
    "                                        'input_chunk_length': input_chunk_length,\n",
    "                                        'output_chunk_length': output_chunk_length,\n",
    "                                        'hidden_size': hidden_size,\n",
    "                                        'batch_size': batch_size,\n",
    "                                        'takens_tau': takens_tau,\n",
    "                                        'padding': padding,\n",
    "                                        'kernel_size': kernel_size,\n",
    "                                    })\n",
    "                                    models_imp.append({\n",
    "                                        'MAPE': mape_imp,\n",
    "                                        'SLE': sle_imp,\n",
    "                                        'U1': u1_imp,\n",
    "                                        'U2': u1_imp,\n",
    "                                        'lr': lr,\n",
    "                                        'input_chunk_length': input_chunk_length,\n",
    "                                        'output_chunk_length': output_chunk_length,\n",
    "                                        'hidden_size': hidden_size,\n",
    "                                        'batch_size': batch_size,\n",
    "                                        'takens_tau': takens_tau,\n",
    "                                        'padding': padding,\n",
    "                                        'kernel_size': kernel_size,\n",
    "                                    })\n",
    "                                except:\n",
    "                                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_imp in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_imp, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_imp, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_imp, key=lambda d: d[i])['hidden_size'],\n",
    "                                'batch_size': min(models_imp, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_imp, key=lambda d: d[i])['lr'],\n",
    "                                'takens_tau': min(models_imp, key=lambda d: d[i])['takens_tau'],\n",
    "                                'padding': min(models_imp, key=lambda d: d[i])['padding'],\n",
    "                                'kernel_size': min(models_imp, key=lambda d: d[i])['kernel_size'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_imp['name'])\n",
    "    model = IMP(\n",
    "        input_chunk_length=best_model_imp['input_chunk_length'],\n",
    "        output_chunk_length=best_model_imp['output_chunk_length'],\n",
    "        hidden_size=best_model_imp['hidden_size'],\n",
    "        batch_size=best_model_imp['batch_size'],\n",
    "        kernel_size=best_model_imp['kernel_size'],\n",
    "        padding=best_model_imp['padding'],\n",
    "        n_epochs=400,\n",
    "        lr=best_model_imp['lr'],\n",
    "        window_model = Takens(tau=best_model_imp['takens_tau']),\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "\n",
    "    model.fit([train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())])\n",
    "    pred_series, mape_imp, sle_imp = eval_model(\n",
    "        model,\n",
    "        len(val_scaled),\n",
    "        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_scaled,\n",
    "        target_series = train_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_imp = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "    u2_imp = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_imp)\n",
    "    print('U2: ', u2_imp)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(input_chunk_length - 1))\n",
    "    kernel_size = trial.suggest_int(\"kernel_size\", 1, 4)\n",
    "    padding = trial.suggest_int(\"padding\", 1, 4)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    model = IMP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        kernel_size=kernel_size,\n",
    "        padding=padding,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IMP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    kernel_size=study.best_trial.params['kernel_size'],\n",
    "    padding=study.best_trial.params['padding'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(input_chunk_length - 1))\n",
    "    kernel_size = trial.suggest_int(\"kernel_size\", 1, 4)\n",
    "    padding = trial.suggest_int(\"padding\", 1, 4)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    model = IMP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        kernel_size=kernel_size,\n",
    "        padding=padding,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IMP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    kernel_size=study.best_trial.params['kernel_size'],\n",
    "    padding=study.best_trial.params['padding'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando MAPE e U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(input_chunk_length - 1))\n",
    "    kernel_size = trial.suggest_int(\"kernel_size\", 1, 4)\n",
    "    padding = trial.suggest_int(\"padding\", 1, 4)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    model = IMP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        kernel_size=kernel_size,\n",
    "        padding=padding,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_scaled, preds)\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IMP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    kernel_size=study.best_trial.params['kernel_size'],\n",
    "    padding=study.best_trial.params['padding'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Brasil (detrend) + Sudeste (detrend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Janela deslizante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_imp = []\n",
    "\n",
    "for input_chunk_length in range(20, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "       for hidden_size in [2**i for i in range(2, 7)]:\n",
    "           for batch_size in [2**i for i in range(2, 7)]:\n",
    "               for lr in [10**(-i) for i in range(2, 5)]:\n",
    "                   for padding in range(1,5):\n",
    "                       for kernel_size in range(1,6):\n",
    "                            try:\n",
    "                                model = IMP(\n",
    "                                    input_chunk_length=input_chunk_length,\n",
    "                                    output_chunk_length=output_chunk_length,\n",
    "                                    hidden_size=hidden_size,\n",
    "                                    batch_size=batch_size,\n",
    "                                    kernel_size=kernel_size,\n",
    "                                    padding=padding,\n",
    "                                    n_epochs=400,\n",
    "                                    lr=lr,\n",
    "                                    device=\"cuda\",\n",
    "                                    random_state = 0\n",
    "                                )\n",
    "                                model.fit([train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())])\n",
    "                                pred_series, mape_imp, sle_imp = eval_model(\n",
    "                                    model,\n",
    "                                    len(val_detrend_scaled),\n",
    "                                    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                    val_detrend_scaled,\n",
    "                                    target_series = train_detrend_scaled,\n",
    "                                    returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                    plot = False,\n",
    "                                )\n",
    "                                uTheil = UTheil()\n",
    "                                u1_imp = uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)])\n",
    "                                u2_imp = uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)])\n",
    "                                print({\n",
    "                                    'MAPE': mape_imp,\n",
    "                                    'SLE': sle_imp,\n",
    "                                    'U1': u1_imp,\n",
    "                                    'U2': u1_imp,\n",
    "                                    'lr': lr,\n",
    "                                    'input_chunk_length': input_chunk_length,\n",
    "                                    'output_chunk_length': output_chunk_length,\n",
    "                                    'hidden_size': hidden_size,\n",
    "                                    'batch_size': batch_size,\n",
    "                                    'padding': padding,\n",
    "                                    'kernel_size': kernel_size,\n",
    "                                })\n",
    "                                models_imp.append({\n",
    "                                    'MAPE': mape_imp,\n",
    "                                    'SLE': sle_imp,\n",
    "                                    'U1': u1_imp,\n",
    "                                    'U2': u1_imp,\n",
    "                                    'lr': lr,\n",
    "                                    'input_chunk_length': input_chunk_length,\n",
    "                                    'output_chunk_length': output_chunk_length,\n",
    "                                    'hidden_size': hidden_size,\n",
    "                                    'batch_size': batch_size,\n",
    "                                    'padding': padding,\n",
    "                                    'kernel_size': kernel_size,\n",
    "                                })\n",
    "                            except:\n",
    "                                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_imp in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_imp, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_imp, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_imp, key=lambda d: d[i])['hidden_size'],\n",
    "                                'batch_size': min(models_imp, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_imp, key=lambda d: d[i])['lr'],\n",
    "                                'padding': min(models_imp, key=lambda d: d[i])['padding'],\n",
    "                                'kernel_size': min(models_imp, key=lambda d: d[i])['kernel_size'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_imp['name'])\n",
    "    model = IMP(\n",
    "        input_chunk_length=best_model_imp['input_chunk_length'],\n",
    "        output_chunk_length=best_model_imp['output_chunk_length'],\n",
    "        hidden_size=best_model_imp['hidden_size'],\n",
    "        batch_size=best_model_imp['batch_size'],\n",
    "        kernel_size=best_model_imp['kernel_size'],\n",
    "        padding=best_model_imp['padding'],\n",
    "        n_epochs=400,\n",
    "        lr=best_model_imp['lr'],\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit([train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())])\n",
    "    pred_series, mape_imp, sle_imp = eval_model(\n",
    "        model,\n",
    "        len(val_detrend_scaled),\n",
    "        series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_detrend_scaled,\n",
    "        target_series = train_detrend_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_imp = uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)])\n",
    "    u2_imp = uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_imp)\n",
    "    print('U2: ', u2_imp)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    kernel_size = trial.suggest_int(\"kernel_size\", 1, 4)\n",
    "    padding = trial.suggest_int(\"padding\", 1, 3)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "    model = IMP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        kernel_size=kernel_size,\n",
    "        padding=padding,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    mapes = mape(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IMP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    kernel_size=study.best_trial.params['kernel_size'],\n",
    "    padding=study.best_trial.params['padding'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    kernel_size = trial.suggest_int(\"kernel_size\", 1, 4)\n",
    "    padding = trial.suggest_int(\"padding\", 1, 3)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "    model = IMP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        kernel_size=kernel_size,\n",
    "        padding=padding,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IMP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    kernel_size=study.best_trial.params['kernel_size'],\n",
    "    padding=study.best_trial.params['padding'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando MAPE e U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    kernel_size = trial.suggest_int(\"kernel_size\", 1, 4)\n",
    "    padding = trial.suggest_int(\"padding\", 1, 3)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "    model = IMP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        kernel_size=kernel_size,\n",
    "        padding=padding,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_detrend_scaled, preds)\n",
    "    mapes = mape(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IMP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    kernel_size=study.best_trial.params['kernel_size'],\n",
    "    padding=study.best_trial.params['padding'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Takens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_imp = []\n",
    "\n",
    "\n",
    "for input_chunk_length in range(20, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "       for hidden_size in [2**i for i in range(2, 7)]:\n",
    "           for batch_size in [2**i for i in range(2, 7)]:\n",
    "               for lr in [10**(-i) for i in range(2, 5)]:\n",
    "                   for padding in range(1,5):\n",
    "                       for kernel_size in range(1,6):\n",
    "                           for takens_tau in range(1, len(train)//(input_chunk_length - 1)):\n",
    "                                try:\n",
    "                                    model = IMP(\n",
    "                                        input_chunk_length=input_chunk_length,\n",
    "                                        output_chunk_length=output_chunk_length,\n",
    "                                        hidden_size=hidden_size,\n",
    "                                        batch_size=batch_size,\n",
    "                                        kernel_size=kernel_size,\n",
    "                                        padding=padding,\n",
    "                                        n_epochs=400,\n",
    "                                        lr=lr,\n",
    "                                        window_model = Takens(tau=takens_tau),\n",
    "                                        device=\"cuda\",\n",
    "                                        random_state = 0\n",
    "                                    )\n",
    "                                    model.fit([train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())])\n",
    "                                    pred_series, mape_imp, sle_imp = eval_model(\n",
    "                                        model,\n",
    "                                        len(val_detrend_scaled),\n",
    "                                        series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                        val_detrend_scaled,\n",
    "                                        target_series = train_detrend_scaled,\n",
    "                                        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                        plot = False,\n",
    "                                    )\n",
    "                                    uTheil = UTheil()\n",
    "                                    u1_imp = uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)])\n",
    "                                    u2_imp = uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)])\n",
    "                                    print({\n",
    "                                        'MAPE': mape_imp,\n",
    "                                        'SLE': sle_imp,\n",
    "                                        'U1': u1_imp,\n",
    "                                        'U2': u1_imp,\n",
    "                                        'lr': lr,\n",
    "                                        'input_chunk_length': input_chunk_length,\n",
    "                                        'output_chunk_length': output_chunk_length,\n",
    "                                        'hidden_size': hidden_size,\n",
    "                                        'batch_size': batch_size,\n",
    "                                        'takens_tau': takens_tau,\n",
    "                                        'padding': padding,\n",
    "                                        'kernel_size': kernel_size,\n",
    "                                    })\n",
    "                                    models_imp.append({\n",
    "                                        'MAPE': mape_imp,\n",
    "                                        'SLE': sle_imp,\n",
    "                                        'U1': u1_imp,\n",
    "                                        'U2': u1_imp,\n",
    "                                        'lr': lr,\n",
    "                                        'input_chunk_length': input_chunk_length,\n",
    "                                        'output_chunk_length': output_chunk_length,\n",
    "                                        'hidden_size': hidden_size,\n",
    "                                        'batch_size': batch_size,\n",
    "                                        'takens_tau': takens_tau,\n",
    "                                        'padding': padding,\n",
    "                                        'kernel_size': kernel_size,\n",
    "                                    })\n",
    "                                except:\n",
    "                                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_imp in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_imp, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_imp, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_imp, key=lambda d: d[i])['hidden_size'],\n",
    "                                'batch_size': min(models_imp, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_imp, key=lambda d: d[i])['lr'],\n",
    "                                'takens_tau': min(models_imp, key=lambda d: d[i])['takens_tau'],\n",
    "                                'padding': min(models_imp, key=lambda d: d[i])['padding'],\n",
    "                                'kernel_size': min(models_imp, key=lambda d: d[i])['kernel_size'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_imp['name'])\n",
    "    model = IMP(\n",
    "        input_chunk_length=best_model_imp['input_chunk_length'],\n",
    "        output_chunk_length=best_model_imp['output_chunk_length'],\n",
    "        hidden_size=best_model_imp['hidden_size'],\n",
    "        batch_size=best_model_imp['batch_size'],\n",
    "        kernel_size=best_model_imp['kernel_size'],\n",
    "        padding=best_model_imp['padding'],\n",
    "        n_epochs=400,\n",
    "        lr=best_model_imp['lr'],\n",
    "        window_model = Takens(tau=best_model_imp['takens_tau']),\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "\n",
    "    model.fit([train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())])\n",
    "    pred_series, mape_imp, sle_imp = eval_model(\n",
    "        model,\n",
    "        len(val_detrend_scaled),\n",
    "        series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_detrend_scaled,\n",
    "        target_series = train_detrend_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_imp = uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)])\n",
    "    u2_imp = uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_imp)\n",
    "    print('U2: ', u2_imp)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(in_len - 1))\n",
    "    kernel_size = trial.suggest_int(\"kernel_size\", 1, 4)\n",
    "    padding = trial.suggest_int(\"padding\", 1, 4)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    model = IMP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        kernel_size=kernel_size,\n",
    "        padding=padding,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    mapes = mape(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IMP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    kernel_size=study.best_trial.params['kernel_size'],\n",
    "    padding=study.best_trial.params['padding'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(in_len - 1))\n",
    "    kernel_size = trial.suggest_int(\"kernel_size\", 1, 4)\n",
    "    padding = trial.suggest_int(\"padding\", 1, 4)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    model = IMP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        kernel_size=kernel_size,\n",
    "        padding=padding,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IMP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    kernel_size=study.best_trial.params['kernel_size'],\n",
    "    padding=study.best_trial.params['padding'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando MAPE e U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(in_len - 1))\n",
    "    kernel_size = trial.suggest_int(\"kernel_size\", 1, 4)\n",
    "    padding = trial.suggest_int(\"padding\", 1, 4)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    model = IMP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        kernel_size=kernel_size,\n",
    "        padding=padding,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_detrend_scaled, preds)\n",
    "    mapes = mape(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IMP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    kernel_size=study.best_trial.params['kernel_size'],\n",
    "    padding=study.best_trial.params['padding'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Brasil + Óleo de Soja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Janela deslizante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_imp = []\n",
    "\n",
    "for input_chunk_length in range(20, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "       for hidden_size in [2**i for i in range(2, 7)]:\n",
    "           for batch_size in [2**i for i in range(2, 7)]:\n",
    "               for lr in [10**(-i) for i in range(2, 5)]:\n",
    "                   for padding in range(1,5):\n",
    "                       for kernel_size in range(1,6):\n",
    "                            try:\n",
    "                                model = IMP(\n",
    "                                    input_chunk_length=input_chunk_length,\n",
    "                                    output_chunk_length=output_chunk_length,\n",
    "                                    hidden_size=hidden_size,\n",
    "                                    batch_size=batch_size,\n",
    "                                    kernel_size=kernel_size,\n",
    "                                    padding=padding,\n",
    "                                    n_epochs=400,\n",
    "                                    lr=lr,\n",
    "                                    device=\"cuda\",\n",
    "                                    random_state = 0\n",
    "                                )\n",
    "                                model.fit([train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())])\n",
    "                                pred_series, mape_imp, sle_imp = eval_model(\n",
    "                                    model,\n",
    "                                    len(val_scaled),\n",
    "                                    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                    val_scaled,\n",
    "                                    target_series = train_scaled,\n",
    "                                    returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                    plot = False,\n",
    "                                )\n",
    "                                uTheil = UTheil()\n",
    "                                u1_imp = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "                                u2_imp = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "                                print({\n",
    "                                    'MAPE': mape_imp,\n",
    "                                    'SLE': sle_imp,\n",
    "                                    'U1': u1_imp,\n",
    "                                    'U2': u1_imp,\n",
    "                                    'lr': lr,\n",
    "                                    'input_chunk_length': input_chunk_length,\n",
    "                                    'output_chunk_length': output_chunk_length,\n",
    "                                    'hidden_size': hidden_size,\n",
    "                                    'batch_size': batch_size,\n",
    "                                    'padding': padding,\n",
    "                                    'kernel_size': kernel_size,\n",
    "                                })\n",
    "                                models_imp.append({\n",
    "                                    'MAPE': mape_imp,\n",
    "                                    'SLE': sle_imp,\n",
    "                                    'U1': u1_imp,\n",
    "                                    'U2': u1_imp,\n",
    "                                    'lr': lr,\n",
    "                                    'input_chunk_length': input_chunk_length,\n",
    "                                    'output_chunk_length': output_chunk_length,\n",
    "                                    'hidden_size': hidden_size,\n",
    "                                    'batch_size': batch_size,\n",
    "                                    'padding': padding,\n",
    "                                    'kernel_size': kernel_size,\n",
    "                                })\n",
    "                            except:\n",
    "                                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_imp in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_imp, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_imp, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_imp, key=lambda d: d[i])['hidden_size'],\n",
    "                                'batch_size': min(models_imp, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_imp, key=lambda d: d[i])['lr'],\n",
    "                                'padding': min(models_imp, key=lambda d: d[i])['padding'],\n",
    "                                'kernel_size': min(models_imp, key=lambda d: d[i])['kernel_size'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_imp['name'])\n",
    "    model = IMP(\n",
    "        input_chunk_length=best_model_imp['input_chunk_length'],\n",
    "        output_chunk_length=best_model_imp['output_chunk_length'],\n",
    "        hidden_size=best_model_imp['hidden_size'],\n",
    "        batch_size=best_model_imp['batch_size'],\n",
    "        kernel_size=best_model_imp['kernel_size'],\n",
    "        padding=best_model_imp['padding'],\n",
    "        n_epochs=400,\n",
    "        lr=best_model_imp['lr'],\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit([train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())])\n",
    "    pred_series, mape_imp, sle_imp = eval_model(\n",
    "        model,\n",
    "        len(val_scaled),\n",
    "        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_scaled,\n",
    "        target_series = train_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_imp = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "    u2_imp = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_imp)\n",
    "    print('U2: ', u2_imp)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    kernel_size = trial.suggest_int(\"kernel_size\", 1, 4)\n",
    "    padding = trial.suggest_int(\"padding\", 1, 3)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "    model = IMP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        kernel_size=kernel_size,\n",
    "        padding=padding,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IMP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    kernel_size=study.best_trial.params['kernel_size'],\n",
    "    padding=study.best_trial.params['padding'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    kernel_size = trial.suggest_int(\"kernel_size\", 1, 4)\n",
    "    padding = trial.suggest_int(\"padding\", 1, 3)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "    model = IMP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        kernel_size=kernel_size,\n",
    "        padding=padding,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IMP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    kernel_size=study.best_trial.params['kernel_size'],\n",
    "    padding=study.best_trial.params['padding'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando MAPE e U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    kernel_size = trial.suggest_int(\"kernel_size\", 1, 4)\n",
    "    padding = trial.suggest_int(\"padding\", 1, 3)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "    model = IMP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        kernel_size=kernel_size,\n",
    "        padding=padding,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_scaled, preds)\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IMP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    kernel_size=study.best_trial.params['kernel_size'],\n",
    "    padding=study.best_trial.params['padding'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Takens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_imp = []\n",
    "\n",
    "\n",
    "for input_chunk_length in range(20, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "       for hidden_size in [2**i for i in range(2, 7)]:\n",
    "           for batch_size in [2**i for i in range(2, 7)]:\n",
    "               for lr in [10**(-i) for i in range(2, 5)]:\n",
    "                   for padding in range(1,5):\n",
    "                       for kernel_size in range(1,6):\n",
    "                           for takens_tau in range(1, len(train)//(input_chunk_length - 1)):\n",
    "                                try:\n",
    "                                    model = IMP(\n",
    "                                        input_chunk_length=input_chunk_length,\n",
    "                                        output_chunk_length=output_chunk_length,\n",
    "                                        hidden_size=hidden_size,\n",
    "                                        batch_size=batch_size,\n",
    "                                        kernel_size=kernel_size,\n",
    "                                        padding=padding,\n",
    "                                        n_epochs=400,\n",
    "                                        lr=lr,\n",
    "                                        window_model = Takens(tau=takens_tau),\n",
    "                                        device=\"cuda\",\n",
    "                                        random_state = 0\n",
    "                                    )\n",
    "                                    model.fit([train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())])\n",
    "                                    pred_series, mape_imp, sle_imp = eval_model(\n",
    "                                        model,\n",
    "                                        len(val_scaled),\n",
    "                                        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                        val_scaled,\n",
    "                                        target_series = train_scaled,\n",
    "                                        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                        plot = False,\n",
    "                                    )\n",
    "                                    uTheil = UTheil()\n",
    "                                    u1_imp = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "                                    u2_imp = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "                                    print({\n",
    "                                        'MAPE': mape_imp,\n",
    "                                        'SLE': sle_imp,\n",
    "                                        'U1': u1_imp,\n",
    "                                        'U2': u1_imp,\n",
    "                                        'lr': lr,\n",
    "                                        'input_chunk_length': input_chunk_length,\n",
    "                                        'output_chunk_length': output_chunk_length,\n",
    "                                        'hidden_size': hidden_size,\n",
    "                                        'batch_size': batch_size,\n",
    "                                        'takens_tau': takens_tau,\n",
    "                                        'padding': padding,\n",
    "                                        'kernel_size': kernel_size,\n",
    "                                    })\n",
    "                                    models_imp.append({\n",
    "                                        'MAPE': mape_imp,\n",
    "                                        'SLE': sle_imp,\n",
    "                                        'U1': u1_imp,\n",
    "                                        'U2': u1_imp,\n",
    "                                        'lr': lr,\n",
    "                                        'input_chunk_length': input_chunk_length,\n",
    "                                        'output_chunk_length': output_chunk_length,\n",
    "                                        'hidden_size': hidden_size,\n",
    "                                        'batch_size': batch_size,\n",
    "                                        'takens_tau': takens_tau,\n",
    "                                        'padding': padding,\n",
    "                                        'kernel_size': kernel_size,\n",
    "                                    })\n",
    "                                except:\n",
    "                                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_imp in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_imp, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_imp, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_imp, key=lambda d: d[i])['hidden_size'],\n",
    "                                'batch_size': min(models_imp, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_imp, key=lambda d: d[i])['lr'],\n",
    "                                'takens_tau': min(models_imp, key=lambda d: d[i])['takens_tau'],\n",
    "                                'padding': min(models_imp, key=lambda d: d[i])['padding'],\n",
    "                                'kernel_size': min(models_imp, key=lambda d: d[i])['kernel_size'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_imp['name'])\n",
    "    model = IMP(\n",
    "        input_chunk_length=best_model_imp['input_chunk_length'],\n",
    "        output_chunk_length=best_model_imp['output_chunk_length'],\n",
    "        hidden_size=best_model_imp['hidden_size'],\n",
    "        batch_size=best_model_imp['batch_size'],\n",
    "        kernel_size=best_model_imp['kernel_size'],\n",
    "        padding=best_model_imp['padding'],\n",
    "        n_epochs=400,\n",
    "        lr=best_model_imp['lr'],\n",
    "        window_model = Takens(tau=best_model_imp['takens_tau']),\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "\n",
    "    model.fit([train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())])\n",
    "    pred_series, mape_imp, sle_imp = eval_model(\n",
    "        model,\n",
    "        len(val_scaled),\n",
    "        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_scaled,\n",
    "        target_series = train_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_imp = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "    u2_imp = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_imp)\n",
    "    print('U2: ', u2_imp)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(input_chunk_length - 1))\n",
    "    kernel_size = trial.suggest_int(\"kernel_size\", 1, 4)\n",
    "    padding = trial.suggest_int(\"padding\", 1, 4)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    model = IMP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        kernel_size=kernel_size,\n",
    "        padding=padding,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IMP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    kernel_size=study.best_trial.params['kernel_size'],\n",
    "    padding=study.best_trial.params['padding'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(input_chunk_length - 1))\n",
    "    kernel_size = trial.suggest_int(\"kernel_size\", 1, 4)\n",
    "    padding = trial.suggest_int(\"padding\", 1, 4)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    model = IMP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        kernel_size=kernel_size,\n",
    "        padding=padding,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IMP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    kernel_size=study.best_trial.params['kernel_size'],\n",
    "    padding=study.best_trial.params['padding'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando MAPE e U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(input_chunk_length - 1))\n",
    "    kernel_size = trial.suggest_int(\"kernel_size\", 1, 4)\n",
    "    padding = trial.suggest_int(\"padding\", 1, 4)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    model = IMP(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        kernel_size=kernel_size,\n",
    "        padding=padding,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_scaled, preds)\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IMP(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    kernel_size=study.best_trial.params['kernel_size'],\n",
    "    padding=study.best_trial.params['padding'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## IDLN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Brasil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Janela deslizante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_idln = []\n",
    "\n",
    "for input_chunk_length in range(20, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "       for batch_size in [2**i for i in range(3, 7)]:\n",
    "           for lr in [10**(-i) for i in range(2, 5)]:\n",
    "               for bias in [True, False]:\n",
    "                    try:\n",
    "                        model = IDLN(\n",
    "                            input_chunk_length=input_chunk_length,\n",
    "                            output_chunk_length=output_chunk_length,\n",
    "                            batch_size=batch_size,\n",
    "                            bias=bias,\n",
    "                            n_epochs=400,\n",
    "                            lr=lr,\n",
    "                            device=\"cuda\",\n",
    "                            random_state = 0\n",
    "                        )\n",
    "                        model.fit(train_scaled)\n",
    "                        pred_series, mape_idln, sle_idln = eval_model(\n",
    "                            model,\n",
    "                            len(val_scaled),\n",
    "                            series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "                            val_scaled,\n",
    "                            target_series = train_scaled,\n",
    "                            returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                            plot = False,\n",
    "                        )\n",
    "                        uTheil = UTheil()\n",
    "                        u1_idln = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "                        u2_idln = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "                        print({\n",
    "                            'MAPE': mape_idln,\n",
    "                            'SLE': sle_idln,\n",
    "                            'U1': u1_idln,\n",
    "                            'U2': u1_idln,\n",
    "                            'lr': lr,\n",
    "                            'input_chunk_length': input_chunk_length,\n",
    "                            'output_chunk_length': output_chunk_length,\n",
    "                            'bias': bias,\n",
    "                            'batch_size': batch_size,\n",
    "                        })\n",
    "                        models_idln.append({\n",
    "                            'MAPE': mape_idln,\n",
    "                            'SLE': sle_idln,\n",
    "                            'U1': u1_idln,\n",
    "                            'U2': u1_idln,\n",
    "                            'lr': lr,\n",
    "                            'input_chunk_length': input_chunk_length,\n",
    "                            'output_chunk_length': output_chunk_length,\n",
    "                            'bias': bias,\n",
    "                            'batch_size': batch_size,\n",
    "                        })\n",
    "                    except:\n",
    "                        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_idln in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_idln, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_idln, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'bias': min(models_idln, key=lambda d: d[i])['bias'],\n",
    "                                'batch_size': min(models_idln, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_idln, key=lambda d: d[i])['lr'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_idln['name'])\n",
    "    model = IDLN(\n",
    "        input_chunk_length=best_model_idln['input_chunk_length'],\n",
    "        output_chunk_length=best_model_idln['output_chunk_length'],\n",
    "        batch_size=best_model_idln['batch_size'],\n",
    "        bias=best_model_idln['bias'],\n",
    "        n_epochs=400,\n",
    "        lr=best_model_idln['lr'],\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit(train_scaled)\n",
    "    pred_series, mape_idln, sle_idln = eval_model(\n",
    "        model,\n",
    "        len(val_scaled),\n",
    "        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_scaled,\n",
    "        target_series = train_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_idln = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "    u2_idln = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_idln)\n",
    "    print('U2: ', u2_idln)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    bias = trial.suggest_categorical(\"bias\", [True, False])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = IDLN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        batch_size=2**batch_size,\n",
    "        bias=bias,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IDLN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    bias=study.best_trial.params['bias'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    bias = trial.suggest_categorical(\"bias\", [True, False])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = IDLN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        batch_size=2**batch_size,\n",
    "        bias=bias,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IDLN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    bias=study.best_trial.params['bias'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando MAPE e U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    bias = trial.suggest_categorical(\"bias\", [True, False])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = IDLN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        batch_size=2**batch_size,\n",
    "        bias=bias,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_scaled, preds)\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IDLN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    bias=study.best_trial.params['bias'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Takens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_idln = []\n",
    "\n",
    "for input_chunk_length in range(20, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "       for batch_size in [2**i for i in range(3, 7)]:\n",
    "           for lr in [10**(-i) for i in range(2, 5)]:\n",
    "               for bias in [True, False]:\n",
    "                   for takens_tau in range(1, len(train)//(input_chunk_length - 1)):\n",
    "                        try:\n",
    "                            model = IDLN(\n",
    "                                input_chunk_length=input_chunk_length,\n",
    "                                output_chunk_length=output_chunk_length,\n",
    "                                batch_size=batch_size,\n",
    "                                bias=bias,\n",
    "                                window_model = Takens(tau=takens_tau),\n",
    "                                n_epochs=400,\n",
    "                                lr=lr,\n",
    "                                device=\"cuda\",\n",
    "                                random_state = 0\n",
    "                            )\n",
    "                            model.fit(train_scaled)\n",
    "                            pred_series, mape_idln, sle_idln = eval_model(\n",
    "                                model,\n",
    "                                len(val_scaled),\n",
    "                                series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                val_scaled,\n",
    "                                target_series = train_scaled,\n",
    "                                returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                plot = False,\n",
    "                            )\n",
    "                            uTheil = UTheil()\n",
    "                            u1_idln = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "                            u2_idln = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "                            print({\n",
    "                                'MAPE': mape_idln,\n",
    "                                'SLE': sle_idln,\n",
    "                                'U1': u1_idln,\n",
    "                                'U2': u1_idln,\n",
    "                                'lr': lr,\n",
    "                                'input_chunk_length': input_chunk_length,\n",
    "                                'output_chunk_length': output_chunk_length,\n",
    "                                'bias': bias,\n",
    "                                'batch_size': batch_size,\n",
    "                                'takens_tau': takens_tau,\n",
    "                            })\n",
    "                            models_idln.append({\n",
    "                                'MAPE': mape_idln,\n",
    "                                'SLE': sle_idln,\n",
    "                                'U1': u1_idln,\n",
    "                                'U2': u1_idln,\n",
    "                                'lr': lr,\n",
    "                                'input_chunk_length': input_chunk_length,\n",
    "                                'output_chunk_length': output_chunk_length,\n",
    "                                'bias': bias,\n",
    "                                'batch_size': batch_size,\n",
    "                                'takens_tau': takens_tau,\n",
    "                            })\n",
    "                        except:\n",
    "                            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_idln in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_idln, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_idln, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'bias': min(models_idln, key=lambda d: d[i])['bias'],\n",
    "                                'batch_size': min(models_idln, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_idln, key=lambda d: d[i])['lr'],\n",
    "                                'takens_tau': min(models_idln, key=lambda d: d[i])['takens_tau'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_idln['name'])\n",
    "    model = IDLN(\n",
    "        input_chunk_length=best_model_idln['input_chunk_length'],\n",
    "        output_chunk_length=best_model_idln['output_chunk_length'],\n",
    "        batch_size=best_model_idln['batch_size'],\n",
    "        bias=best_model_idln['bias'],\n",
    "        window_model = Takens(tau=best_model_idln['takens_tau']),\n",
    "        n_epochs=400,\n",
    "        lr=best_model_idln['lr'],\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit(train_scaled)\n",
    "    pred_series, mape_idln, sle_idln = eval_model(\n",
    "        model,\n",
    "        len(val_scaled),\n",
    "        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_scaled,\n",
    "        target_series = train_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_idln = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "    u2_idln = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_idln)\n",
    "    print('U2: ', u2_idln)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    bias = trial.suggest_categorical(\"bias\", [True, False])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(in_len - 1))\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = IDLN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        batch_size=2**batch_size,\n",
    "        bias=bias,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IDLN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    bias=study.best_trial.params['bias'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    bias = trial.suggest_categorical(\"bias\", [True, False])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(in_len - 1))\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = IDLN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        batch_size=2**batch_size,\n",
    "        bias=bias,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IDLN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    bias=study.best_trial.params['bias'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando MAPE e U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    bias = trial.suggest_categorical(\"bias\", [True, False])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(in_len - 1))\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = IDLN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        batch_size=2**batch_size,\n",
    "        bias=bias,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_scaled, preds)\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IDLN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    bias=study.best_trial.params['bias'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Brasil (detrend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Janela deslizante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_idln = []\n",
    "\n",
    "for input_chunk_length in range(20, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "       for batch_size in [2**i for i in range(3, 7)]:\n",
    "           for lr in [10**(-i) for i in range(2, 5)]:\n",
    "               for bias in [True, False]:\n",
    "                    try:\n",
    "                        model = IDLN(\n",
    "                            input_chunk_length=input_chunk_length,\n",
    "                            output_chunk_length=output_chunk_length,\n",
    "                            batch_size=batch_size,\n",
    "                            bias=bias,\n",
    "                            n_epochs=400,\n",
    "                            lr=lr,\n",
    "                            device=\"cuda\",\n",
    "                            random_state = 0\n",
    "                        )\n",
    "                        model.fit(train_detrend_scaled)\n",
    "                        pred_series, mape_idln, sle_idln = eval_model(\n",
    "                            model,\n",
    "                            len(val_detrend_scaled),\n",
    "                            series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "                            val_detrend_scaled,\n",
    "                            target_series = train_detrend_scaled,\n",
    "                            returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                            plot = False,\n",
    "                        )\n",
    "                        uTheil = UTheil()\n",
    "                        u1_idln = uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)])\n",
    "                        u2_idln = uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)])\n",
    "                        print({\n",
    "                            'MAPE': mape_idln,\n",
    "                            'SLE': sle_idln,\n",
    "                            'U1': u1_idln,\n",
    "                            'U2': u1_idln,\n",
    "                            'lr': lr,\n",
    "                            'input_chunk_length': input_chunk_length,\n",
    "                            'output_chunk_length': output_chunk_length,\n",
    "                            'bias': bias,\n",
    "                            'batch_size': batch_size,\n",
    "                        })\n",
    "                        models_idln.append({\n",
    "                            'MAPE': mape_idln,\n",
    "                            'SLE': sle_idln,\n",
    "                            'U1': u1_idln,\n",
    "                            'U2': u1_idln,\n",
    "                            'lr': lr,\n",
    "                            'input_chunk_length': input_chunk_length,\n",
    "                            'output_chunk_length': output_chunk_length,\n",
    "                            'bias': bias,\n",
    "                            'batch_size': batch_size,\n",
    "                        })\n",
    "                    except:\n",
    "                        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_idln in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_idln, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_idln, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'bias': min(models_idln, key=lambda d: d[i])['bias'],\n",
    "                                'batch_size': min(models_idln, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_idln, key=lambda d: d[i])['lr'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_idln['name'])\n",
    "    model = IDLN(\n",
    "        input_chunk_length=best_model_idln['input_chunk_length'],\n",
    "        output_chunk_length=best_model_idln['output_chunk_length'],\n",
    "        batch_size=best_model_idln['batch_size'],\n",
    "        bias=best_model_idln['bias'],\n",
    "        n_epochs=400,\n",
    "        lr=best_model_idln['lr'],\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit(train_detrend_scaled)\n",
    "    pred_series, mape_idln, sle_idln = eval_model(\n",
    "        model,\n",
    "        len(val_detrend_scaled),\n",
    "        series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_detrend_scaled,\n",
    "        target_series = train_detrend_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_idln = uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)])\n",
    "    u2_idln = uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_idln)\n",
    "    print('U2: ', u2_idln)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    bias = trial.suggest_categorical(\"bias\", [True, False])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = IDLN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        batch_size=2**batch_size,\n",
    "        bias=bias,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_detrend_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    mapes = mape(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IDLN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    bias=study.best_trial.params['bias'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_detrend_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    bias = trial.suggest_categorical(\"bias\", [True, False])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = IDLN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        batch_size=2**batch_size,\n",
    "        bias=bias,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_detrend_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IDLN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    bias=study.best_trial.params['bias'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_detrend_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando MAPE e U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    bias = trial.suggest_categorical(\"bias\", [True, False])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = IDLN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        batch_size=2**batch_size,\n",
    "        bias=bias,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_detrend_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_detrend_scaled, preds)\n",
    "    mapes = mape(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IDLN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    bias=study.best_trial.params['bias'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_detrend_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Takens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_idln = []\n",
    "\n",
    "for input_chunk_length in range(20, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "       for batch_size in [2**i for i in range(3, 7)]:\n",
    "           for lr in [10**(-i) for i in range(2, 5)]:\n",
    "               for bias in [True, False]:\n",
    "                   for takens_tau in range(1, len(train)//(input_chunk_length - 1)):\n",
    "                        try:\n",
    "                            model = IDLN(\n",
    "                                input_chunk_length=input_chunk_length,\n",
    "                                output_chunk_length=output_chunk_length,\n",
    "                                batch_size=batch_size,\n",
    "                                bias=bias,\n",
    "                                window_model = Takens(tau=takens_tau),\n",
    "                                n_epochs=400,\n",
    "                                lr=lr,\n",
    "                                device=\"cuda\",\n",
    "                                random_state = 0\n",
    "                            )\n",
    "                            model.fit(train_detrend_scaled)\n",
    "                            pred_series, mape_idln, sle_idln = eval_model(\n",
    "                                model,\n",
    "                                len(val_detrend_scaled),\n",
    "                                series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                val_detrend_scaled,\n",
    "                                target_series = train_detrend_scaled,\n",
    "                                returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                plot = False,\n",
    "                            )\n",
    "                            uTheil = UTheil()\n",
    "                            u1_idln = uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)])\n",
    "                            u2_idln = uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)])\n",
    "                            print({\n",
    "                                'MAPE': mape_idln,\n",
    "                                'SLE': sle_idln,\n",
    "                                'U1': u1_idln,\n",
    "                                'U2': u1_idln,\n",
    "                                'lr': lr,\n",
    "                                'input_chunk_length': input_chunk_length,\n",
    "                                'output_chunk_length': output_chunk_length,\n",
    "                                'bias': bias,\n",
    "                                'batch_size': batch_size,\n",
    "                                'takens_tau': takens_tau,\n",
    "                            })\n",
    "                            models_idln.append({\n",
    "                                'MAPE': mape_idln,\n",
    "                                'SLE': sle_idln,\n",
    "                                'U1': u1_idln,\n",
    "                                'U2': u1_idln,\n",
    "                                'lr': lr,\n",
    "                                'input_chunk_length': input_chunk_length,\n",
    "                                'output_chunk_length': output_chunk_length,\n",
    "                                'bias': bias,\n",
    "                                'batch_size': batch_size,\n",
    "                                'takens_tau': takens_tau,\n",
    "                            })\n",
    "                        except:\n",
    "                            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_idln in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_idln, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_idln, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'bias': min(models_idln, key=lambda d: d[i])['bias'],\n",
    "                                'batch_size': min(models_idln, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_idln, key=lambda d: d[i])['lr'],\n",
    "                                'takens_tau': min(models_idln, key=lambda d: d[i])['takens_tau'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_idln['name'])\n",
    "    model = IDLN(\n",
    "        input_chunk_length=best_model_idln['input_chunk_length'],\n",
    "        output_chunk_length=best_model_idln['output_chunk_length'],\n",
    "        batch_size=best_model_idln['batch_size'],\n",
    "        bias=best_model_idln['bias'],\n",
    "        window_model = Takens(tau=best_model_idln['takens_tau']),\n",
    "        n_epochs=400,\n",
    "        lr=best_model_idln['lr'],\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit(train_detrend_scaled)\n",
    "    pred_series, mape_idln, sle_idln = eval_model(\n",
    "        model,\n",
    "        len(val_detrend_scaled),\n",
    "        series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_detrend_scaled,\n",
    "        target_series = train_detrend_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_idln = uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)])\n",
    "    u2_idln = uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_idln)\n",
    "    print('U2: ', u2_idln)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    bias = trial.suggest_categorical(\"bias\", [True, False])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(in_len - 1))\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = IDLN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        batch_size=2**batch_size,\n",
    "        bias=bias,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_detrend_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    mapes = mape(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IDLN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    bias=study.best_trial.params['bias'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_detrend_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    bias = trial.suggest_categorical(\"bias\", [True, False])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(in_len - 1))\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = IDLN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        batch_size=2**batch_size,\n",
    "        bias=bias,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_detrend_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IDLN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    bias=study.best_trial.params['bias'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_detrend_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando MAPE e U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    bias = trial.suggest_categorical(\"bias\", [True, False])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(in_len - 1))\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = IDLN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        batch_size=2**batch_size,\n",
    "        bias=bias,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_detrend_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_detrend_scaled, preds)\n",
    "    mapes = mape(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IDLN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    bias=study.best_trial.params['bias'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_detrend_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Brasil + Sudeste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Janela deslizante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_idln = []\n",
    "\n",
    "for input_chunk_length in range(20, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "       for batch_size in [2**i for i in range(3, 7)]:\n",
    "           for lr in [10**(-i) for i in range(2, 5)]:\n",
    "               for bias in [True, False]:\n",
    "                    try:\n",
    "                        model = IDLN(\n",
    "                            input_chunk_length=input_chunk_length,\n",
    "                            output_chunk_length=output_chunk_length,\n",
    "                            batch_size=batch_size,\n",
    "                            bias=bias,\n",
    "                            n_epochs=400,\n",
    "                            lr=lr,\n",
    "                            device=\"cuda\",\n",
    "                            random_state = 0\n",
    "                        )\n",
    "                        model.fit([train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())])\n",
    "                        pred_series, mape_idln, sle_idln = eval_model(\n",
    "                            model,\n",
    "                            len(val_scaled),\n",
    "                            series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "                            val_scaled,\n",
    "                            target_series = train_scaled,\n",
    "                            returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                            plot = False,\n",
    "                        )\n",
    "                        uTheil = UTheil()\n",
    "                        u1_idln = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "                        u2_idln = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "                        print({\n",
    "                            'MAPE': mape_idln,\n",
    "                            'SLE': sle_idln,\n",
    "                            'U1': u1_idln,\n",
    "                            'U2': u1_idln,\n",
    "                            'lr': lr,\n",
    "                            'input_chunk_length': input_chunk_length,\n",
    "                            'output_chunk_length': output_chunk_length,\n",
    "                            'bias': bias,\n",
    "                            'batch_size': batch_size,\n",
    "                        })\n",
    "                        models_idln.append({\n",
    "                            'MAPE': mape_idln,\n",
    "                            'SLE': sle_idln,\n",
    "                            'U1': u1_idln,\n",
    "                            'U2': u1_idln,\n",
    "                            'lr': lr,\n",
    "                            'input_chunk_length': input_chunk_length,\n",
    "                            'output_chunk_length': output_chunk_length,\n",
    "                            'bias': bias,\n",
    "                            'batch_size': batch_size,\n",
    "                        })\n",
    "                    except:\n",
    "                        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_idln in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_idln, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_idln, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'bias': min(models_idln, key=lambda d: d[i])['bias'],\n",
    "                                'batch_size': min(models_idln, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_idln, key=lambda d: d[i])['lr'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_idln['name'])\n",
    "    model = IDLN(\n",
    "        input_chunk_length=best_model_idln['input_chunk_length'],\n",
    "        output_chunk_length=best_model_idln['output_chunk_length'],\n",
    "        batch_size=best_model_idln['batch_size'],\n",
    "        bias=best_model_idln['bias'],\n",
    "        n_epochs=400,\n",
    "        lr=best_model_idln['lr'],\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit([train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())])\n",
    "    pred_series, mape_idln, sle_idln = eval_model(\n",
    "        model,\n",
    "        len(val_scaled),\n",
    "        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_scaled,\n",
    "        target_series = train_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_idln = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "    u2_idln = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_idln)\n",
    "    print('U2: ', u2_idln)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    bias = trial.suggest_categorical(\"bias\", [True, False])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = IDLN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        batch_size=2**batch_size,\n",
    "        bias=bias,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IDLN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    bias=study.best_trial.params['bias'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    bias = trial.suggest_categorical(\"bias\", [True, False])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = IDLN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        batch_size=2**batch_size,\n",
    "        bias=bias,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IDLN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    bias=study.best_trial.params['bias'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando MAPE e U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    bias = trial.suggest_categorical(\"bias\", [True, False])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = IDLN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        batch_size=2**batch_size,\n",
    "        bias=bias,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_scaled, preds)\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IDLN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    bias=study.best_trial.params['bias'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Takens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_idln = []\n",
    "\n",
    "for input_chunk_length in range(20, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "       for batch_size in [2**i for i in range(3, 7)]:\n",
    "           for lr in [10**(-i) for i in range(2, 5)]:\n",
    "               for bias in [True, False]:\n",
    "                   for takens_tau in range(1, len(train)//(input_chunk_length - 1)):\n",
    "                        try:\n",
    "                            model = IDLN(\n",
    "                                input_chunk_length=input_chunk_length,\n",
    "                                output_chunk_length=output_chunk_length,\n",
    "                                batch_size=batch_size,\n",
    "                                bias=bias,\n",
    "                                window_model = Takens(tau=takens_tau),\n",
    "                                n_epochs=400,\n",
    "                                lr=lr,\n",
    "                                device=\"cuda\",\n",
    "                                random_state = 0\n",
    "                            )\n",
    "                            model.fit([train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())])\n",
    "                            pred_series, mape_idln, sle_idln = eval_model(\n",
    "                                model,\n",
    "                                len(val_scaled),\n",
    "                                series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                val_scaled,\n",
    "                                target_series = train_scaled,\n",
    "                                returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                plot = False,\n",
    "                            )\n",
    "                            uTheil = UTheil()\n",
    "                            u1_idln = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "                            u2_idln = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "                            print({\n",
    "                                'MAPE': mape_idln,\n",
    "                                'SLE': sle_idln,\n",
    "                                'U1': u1_idln,\n",
    "                                'U2': u1_idln,\n",
    "                                'lr': lr,\n",
    "                                'input_chunk_length': input_chunk_length,\n",
    "                                'output_chunk_length': output_chunk_length,\n",
    "                                'bias': bias,\n",
    "                                'batch_size': batch_size,\n",
    "                                'takens_tau': takens_tau,\n",
    "                            })\n",
    "                            models_idln.append({\n",
    "                                'MAPE': mape_idln,\n",
    "                                'SLE': sle_idln,\n",
    "                                'U1': u1_idln,\n",
    "                                'U2': u1_idln,\n",
    "                                'lr': lr,\n",
    "                                'input_chunk_length': input_chunk_length,\n",
    "                                'output_chunk_length': output_chunk_length,\n",
    "                                'bias': bias,\n",
    "                                'batch_size': batch_size,\n",
    "                                'takens_tau': takens_tau,\n",
    "                            })\n",
    "                        except:\n",
    "                            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_idln in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_idln, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_idln, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'bias': min(models_idln, key=lambda d: d[i])['bias'],\n",
    "                                'batch_size': min(models_idln, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_idln, key=lambda d: d[i])['lr'],\n",
    "                                'takens_tau': min(models_idln, key=lambda d: d[i])['takens_tau'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_idln['name'])\n",
    "    model = IDLN(\n",
    "        input_chunk_length=best_model_idln['input_chunk_length'],\n",
    "        output_chunk_length=best_model_idln['output_chunk_length'],\n",
    "        batch_size=best_model_idln['batch_size'],\n",
    "        bias=best_model_idln['bias'],\n",
    "        window_model = Takens(tau=best_model_idln['takens_tau']),\n",
    "        n_epochs=400,\n",
    "        lr=best_model_idln['lr'],\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit([train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())])\n",
    "    pred_series, mape_idln, sle_idln = eval_model(\n",
    "        model,\n",
    "        len(val_scaled),\n",
    "        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_scaled,\n",
    "        target_series = train_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_idln = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "    u2_idln = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_idln)\n",
    "    print('U2: ', u2_idln)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    bias = trial.suggest_categorical(\"bias\", [True, False])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(input_chunk_length - 1))\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = IDLN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        batch_size=2**batch_size,\n",
    "        bias=bias,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IDLN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    bias=study.best_trial.params['bias'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    bias = trial.suggest_categorical(\"bias\", [True, False])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(input_chunk_length - 1))\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = IDLN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        batch_size=2**batch_size,\n",
    "        bias=bias,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IDLN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    bias=study.best_trial.params['bias'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando MAPE e U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    bias = trial.suggest_categorical(\"bias\", [True, False])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(input_chunk_length - 1))\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = IDLN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        batch_size=2**batch_size,\n",
    "        bias=bias,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_scaled, preds)\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IDLN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    bias=study.best_trial.params['bias'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Brasil (detrend) + Sudeste (detrend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Janela deslizante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_idln = []\n",
    "\n",
    "for input_chunk_length in range(20, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "       for batch_size in [2**i for i in range(3, 7)]:\n",
    "           for lr in [10**(-i) for i in range(2, 5)]:\n",
    "               for bias in [True, False]:\n",
    "                    try:\n",
    "                        model = IDLN(\n",
    "                            input_chunk_length=input_chunk_length,\n",
    "                            output_chunk_length=output_chunk_length,\n",
    "                            batch_size=batch_size,\n",
    "                            bias=bias,\n",
    "                            n_epochs=400,\n",
    "                            lr=lr,\n",
    "                            device=\"cuda\",\n",
    "                            random_state = 0\n",
    "                        )\n",
    "                        model.fit([train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())])\n",
    "                        pred_series, mape_idln, sle_idln = eval_model(\n",
    "                            model,\n",
    "                            len(val_detrend_scaled),\n",
    "                            series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "                            val_detrend_scaled,\n",
    "                            target_series = train_detrend_scaled,\n",
    "                            returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                            plot = False,\n",
    "                        )\n",
    "                        uTheil = UTheil()\n",
    "                        u1_idln = uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)])\n",
    "                        u2_idln = uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)])\n",
    "                        print({\n",
    "                            'MAPE': mape_idln,\n",
    "                            'SLE': sle_idln,\n",
    "                            'U1': u1_idln,\n",
    "                            'U2': u1_idln,\n",
    "                            'lr': lr,\n",
    "                            'input_chunk_length': input_chunk_length,\n",
    "                            'output_chunk_length': output_chunk_length,\n",
    "                            'bias': bias,\n",
    "                            'batch_size': batch_size,\n",
    "                        })\n",
    "                        models_idln.append({\n",
    "                            'MAPE': mape_idln,\n",
    "                            'SLE': sle_idln,\n",
    "                            'U1': u1_idln,\n",
    "                            'U2': u1_idln,\n",
    "                            'lr': lr,\n",
    "                            'input_chunk_length': input_chunk_length,\n",
    "                            'output_chunk_length': output_chunk_length,\n",
    "                            'bias': bias,\n",
    "                            'batch_size': batch_size,\n",
    "                        })\n",
    "                    except:\n",
    "                        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_idln in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_idln, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_idln, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'bias': min(models_idln, key=lambda d: d[i])['bias'],\n",
    "                                'batch_size': min(models_idln, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_idln, key=lambda d: d[i])['lr'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_idln['name'])\n",
    "    model = IDLN(\n",
    "        input_chunk_length=best_model_idln['input_chunk_length'],\n",
    "        output_chunk_length=best_model_idln['output_chunk_length'],\n",
    "        batch_size=best_model_idln['batch_size'],\n",
    "        bias=best_model_idln['bias'],\n",
    "        n_epochs=400,\n",
    "        lr=best_model_idln['lr'],\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit([train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())])\n",
    "    pred_series, mape_idln, sle_idln = eval_model(\n",
    "        model,\n",
    "        len(val_detrend_scaled),\n",
    "        series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_detrend_scaled,\n",
    "        target_series = train_detrend_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_idln = uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)])\n",
    "    u2_idln = uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_idln)\n",
    "    print('U2: ', u2_idln)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    bias = trial.suggest_categorical(\"bias\", [True, False])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = IDLN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        batch_size=2**batch_size,\n",
    "        bias=bias,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    mapes = mape(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IDLN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    bias=study.best_trial.params['bias'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    bias = trial.suggest_categorical(\"bias\", [True, False])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = IDLN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        batch_size=2**batch_size,\n",
    "        bias=bias,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IDLN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    bias=study.best_trial.params['bias'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando MAPE e U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    bias = trial.suggest_categorical(\"bias\", [True, False])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = IDLN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        batch_size=2**batch_size,\n",
    "        bias=bias,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_detrend_scaled, preds)\n",
    "    mapes = mape(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IDLN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    bias=study.best_trial.params['bias'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Takens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_idln = []\n",
    "\n",
    "for input_chunk_length in range(20, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "       for batch_size in [2**i for i in range(3, 7)]:\n",
    "           for lr in [10**(-i) for i in range(2, 5)]:\n",
    "               for bias in [True, False]:\n",
    "                   for takens_tau in range(1, len(train)//(input_chunk_length - 1)):\n",
    "                        try:\n",
    "                            model = IDLN(\n",
    "                                input_chunk_length=input_chunk_length,\n",
    "                                output_chunk_length=output_chunk_length,\n",
    "                                batch_size=batch_size,\n",
    "                                bias=bias,\n",
    "                                window_model = Takens(tau=takens_tau),\n",
    "                                n_epochs=400,\n",
    "                                lr=lr,\n",
    "                                device=\"cuda\",\n",
    "                                random_state = 0\n",
    "                            )\n",
    "                            model.fit([train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())])\n",
    "                            pred_series, mape_idln, sle_idln = eval_model(\n",
    "                                model,\n",
    "                                len(val_detrend_scaled),\n",
    "                                series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                val_detrend_scaled,\n",
    "                                target_series = train_detrend_scaled,\n",
    "                                returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                plot = False,\n",
    "                            )\n",
    "                            uTheil = UTheil()\n",
    "                            u1_idln = uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)])\n",
    "                            u2_idln = uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)])\n",
    "                            print({\n",
    "                                'MAPE': mape_idln,\n",
    "                                'SLE': sle_idln,\n",
    "                                'U1': u1_idln,\n",
    "                                'U2': u1_idln,\n",
    "                                'lr': lr,\n",
    "                                'input_chunk_length': input_chunk_length,\n",
    "                                'output_chunk_length': output_chunk_length,\n",
    "                                'bias': bias,\n",
    "                                'batch_size': batch_size,\n",
    "                                'takens_tau': takens_tau,\n",
    "                            })\n",
    "                            models_idln.append({\n",
    "                                'MAPE': mape_idln,\n",
    "                                'SLE': sle_idln,\n",
    "                                'U1': u1_idln,\n",
    "                                'U2': u1_idln,\n",
    "                                'lr': lr,\n",
    "                                'input_chunk_length': input_chunk_length,\n",
    "                                'output_chunk_length': output_chunk_length,\n",
    "                                'bias': bias,\n",
    "                                'batch_size': batch_size,\n",
    "                                'takens_tau': takens_tau,\n",
    "                            })\n",
    "                        except:\n",
    "                            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_idln in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_idln, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_idln, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'bias': min(models_idln, key=lambda d: d[i])['bias'],\n",
    "                                'batch_size': min(models_idln, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_idln, key=lambda d: d[i])['lr'],\n",
    "                                'takens_tau': min(models_idln, key=lambda d: d[i])['takens_tau'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_idln['name'])\n",
    "    model = IDLN(\n",
    "        input_chunk_length=best_model_idln['input_chunk_length'],\n",
    "        output_chunk_length=best_model_idln['output_chunk_length'],\n",
    "        batch_size=best_model_idln['batch_size'],\n",
    "        bias=best_model_idln['bias'],\n",
    "        window_model = Takens(tau=best_model_idln['takens_tau']),\n",
    "        n_epochs=400,\n",
    "        lr=best_model_idln['lr'],\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit([train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())])\n",
    "    pred_series, mape_idln, sle_idln = eval_model(\n",
    "        model,\n",
    "        len(val_detrend_scaled),\n",
    "        series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_detrend_scaled,\n",
    "        target_series = train_detrend_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_idln = uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)])\n",
    "    u2_idln = uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_idln)\n",
    "    print('U2: ', u2_idln)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    bias = trial.suggest_categorical(\"bias\", [True, False])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(in_len - 1))\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = IDLN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        batch_size=2**batch_size,\n",
    "        bias=bias,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    mapes = mape(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IDLN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    bias=study.best_trial.params['bias'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    bias = trial.suggest_categorical(\"bias\", [True, False])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(in_len - 1))\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = IDLN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        batch_size=2**batch_size,\n",
    "        bias=bias,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IDLN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    bias=study.best_trial.params['bias'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando MAPE e U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    bias = trial.suggest_categorical(\"bias\", [True, False])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(in_len - 1))\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = IDLN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        batch_size=2**batch_size,\n",
    "        bias=bias,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_detrend_scaled, preds)\n",
    "    mapes = mape(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IDLN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    bias=study.best_trial.params['bias'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Brasil + Óleo de Soja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Janela deslizante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_idln = []\n",
    "\n",
    "for input_chunk_length in range(20, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "       for batch_size in [2**i for i in range(3, 7)]:\n",
    "           for lr in [10**(-i) for i in range(2, 5)]:\n",
    "               for bias in [True, False]:\n",
    "                    try:\n",
    "                        model = IDLN(\n",
    "                            input_chunk_length=input_chunk_length,\n",
    "                            output_chunk_length=output_chunk_length,\n",
    "                            batch_size=batch_size,\n",
    "                            bias=bias,\n",
    "                            n_epochs=400,\n",
    "                            lr=lr,\n",
    "                            device=\"cuda\",\n",
    "                            random_state = 0\n",
    "                        )\n",
    "                        model.fit([train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())])\n",
    "                        pred_series, mape_idln, sle_idln = eval_model(\n",
    "                            model,\n",
    "                            len(val_scaled),\n",
    "                            series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "                            val_scaled,\n",
    "                            target_series = train_scaled,\n",
    "                            returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                            plot = False,\n",
    "                        )\n",
    "                        uTheil = UTheil()\n",
    "                        u1_idln = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "                        u2_idln = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "                        print({\n",
    "                            'MAPE': mape_idln,\n",
    "                            'SLE': sle_idln,\n",
    "                            'U1': u1_idln,\n",
    "                            'U2': u1_idln,\n",
    "                            'lr': lr,\n",
    "                            'input_chunk_length': input_chunk_length,\n",
    "                            'output_chunk_length': output_chunk_length,\n",
    "                            'bias': bias,\n",
    "                            'batch_size': batch_size,\n",
    "                        })\n",
    "                        models_idln.append({\n",
    "                            'MAPE': mape_idln,\n",
    "                            'SLE': sle_idln,\n",
    "                            'U1': u1_idln,\n",
    "                            'U2': u1_idln,\n",
    "                            'lr': lr,\n",
    "                            'input_chunk_length': input_chunk_length,\n",
    "                            'output_chunk_length': output_chunk_length,\n",
    "                            'bias': bias,\n",
    "                            'batch_size': batch_size,\n",
    "                        })\n",
    "                    except:\n",
    "                        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_idln in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_idln, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_idln, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'bias': min(models_idln, key=lambda d: d[i])['bias'],\n",
    "                                'batch_size': min(models_idln, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_idln, key=lambda d: d[i])['lr'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_idln['name'])\n",
    "    model = IDLN(\n",
    "        input_chunk_length=best_model_idln['input_chunk_length'],\n",
    "        output_chunk_length=best_model_idln['output_chunk_length'],\n",
    "        batch_size=best_model_idln['batch_size'],\n",
    "        bias=best_model_idln['bias'],\n",
    "        n_epochs=400,\n",
    "        lr=best_model_idln['lr'],\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit([train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())])\n",
    "    pred_series, mape_idln, sle_idln = eval_model(\n",
    "        model,\n",
    "        len(val_scaled),\n",
    "        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_scaled,\n",
    "        target_series = train_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_idln = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "    u2_idln = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_idln)\n",
    "    print('U2: ', u2_idln)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    bias = trial.suggest_categorical(\"bias\", [True, False])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = IDLN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        batch_size=2**batch_size,\n",
    "        bias=bias,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IDLN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    bias=study.best_trial.params['bias'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    bias = trial.suggest_categorical(\"bias\", [True, False])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = IDLN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        batch_size=2**batch_size,\n",
    "        bias=bias,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IDLN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    bias=study.best_trial.params['bias'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando MAPE e U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    bias = trial.suggest_categorical(\"bias\", [True, False])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = IDLN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        batch_size=2**batch_size,\n",
    "        bias=bias,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_scaled, preds)\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IDLN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    bias=study.best_trial.params['bias'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Takens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_idln = []\n",
    "\n",
    "for input_chunk_length in range(20, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "       for batch_size in [2**i for i in range(3, 7)]:\n",
    "           for lr in [10**(-i) for i in range(2, 5)]:\n",
    "               for bias in [True, False]:\n",
    "                   for takens_tau in range(1, len(train)//(input_chunk_length - 1)):\n",
    "                        try:\n",
    "                            model = IDLN(\n",
    "                                input_chunk_length=input_chunk_length,\n",
    "                                output_chunk_length=output_chunk_length,\n",
    "                                batch_size=batch_size,\n",
    "                                bias=bias,\n",
    "                                window_model = Takens(tau=takens_tau),\n",
    "                                n_epochs=400,\n",
    "                                lr=lr,\n",
    "                                device=\"cuda\",\n",
    "                                random_state = 0\n",
    "                            )\n",
    "                            model.fit([train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())])\n",
    "                            pred_series, mape_idln, sle_idln = eval_model(\n",
    "                                model,\n",
    "                                len(val_scaled),\n",
    "                                series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                val_scaled,\n",
    "                                target_series = train_scaled,\n",
    "                                returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                plot = False,\n",
    "                            )\n",
    "                            uTheil = UTheil()\n",
    "                            u1_idln = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "                            u2_idln = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "                            print({\n",
    "                                'MAPE': mape_idln,\n",
    "                                'SLE': sle_idln,\n",
    "                                'U1': u1_idln,\n",
    "                                'U2': u1_idln,\n",
    "                                'lr': lr,\n",
    "                                'input_chunk_length': input_chunk_length,\n",
    "                                'output_chunk_length': output_chunk_length,\n",
    "                                'bias': bias,\n",
    "                                'batch_size': batch_size,\n",
    "                                'takens_tau': takens_tau,\n",
    "                            })\n",
    "                            models_idln.append({\n",
    "                                'MAPE': mape_idln,\n",
    "                                'SLE': sle_idln,\n",
    "                                'U1': u1_idln,\n",
    "                                'U2': u1_idln,\n",
    "                                'lr': lr,\n",
    "                                'input_chunk_length': input_chunk_length,\n",
    "                                'output_chunk_length': output_chunk_length,\n",
    "                                'bias': bias,\n",
    "                                'batch_size': batch_size,\n",
    "                                'takens_tau': takens_tau,\n",
    "                            })\n",
    "                        except:\n",
    "                            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_idln in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_idln, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_idln, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'bias': min(models_idln, key=lambda d: d[i])['bias'],\n",
    "                                'batch_size': min(models_idln, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_idln, key=lambda d: d[i])['lr'],\n",
    "                                'takens_tau': min(models_idln, key=lambda d: d[i])['takens_tau'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_idln['name'])\n",
    "    model = IDLN(\n",
    "        input_chunk_length=best_model_idln['input_chunk_length'],\n",
    "        output_chunk_length=best_model_idln['output_chunk_length'],\n",
    "        batch_size=best_model_idln['batch_size'],\n",
    "        bias=best_model_idln['bias'],\n",
    "        window_model = Takens(tau=best_model_idln['takens_tau']),\n",
    "        n_epochs=400,\n",
    "        lr=best_model_idln['lr'],\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit([train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())])\n",
    "    pred_series, mape_idln, sle_idln = eval_model(\n",
    "        model,\n",
    "        len(val_scaled),\n",
    "        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_scaled,\n",
    "        target_series = train_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_idln = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "    u2_idln = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_idln)\n",
    "    print('U2: ', u2_idln)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    bias = trial.suggest_categorical(\"bias\", [True, False])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(input_chunk_length - 1))\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = IDLN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        batch_size=2**batch_size,\n",
    "        bias=bias,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IDLN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    bias=study.best_trial.params['bias'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    bias = trial.suggest_categorical(\"bias\", [True, False])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(input_chunk_length - 1))\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = IDLN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        batch_size=2**batch_size,\n",
    "        bias=bias,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IDLN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    bias=study.best_trial.params['bias'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando MAPE e U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    bias = trial.suggest_categorical(\"bias\", [True, False])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    takens_tau = trial.suggest_int(\"takens_tau\", 1, len(train)//(input_chunk_length - 1))\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = IDLN(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        batch_size=2**batch_size,\n",
    "        bias=bias,\n",
    "        window_model = Takens(tau=takens_tau),\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr,\n",
    "        device=\"cuda\",\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_scaled, preds)\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IDLN(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    bias=study.best_trial.params['bias'],\n",
    "    window_model = Takens(tau=study.best_trial.params['takens_tau']),\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    lr=study.best_trial.params['lr'],\n",
    "    device=\"cuda\",\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## N-Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Brasil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Janela deslizante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_nlinear = []\n",
    "\n",
    "for input_chunk_length in range(20, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "        for batch_size in [2**i for i in range(4,7)]:\n",
    "           for shared_weights in [True, False]:\n",
    "               for const_init in [True, False]:\n",
    "                   for normalize in [True, False]:\n",
    "                       for use_static_covariates in [True, False]:\n",
    "                           for lr in [10**(-i) for i in [2,3,4]]:\n",
    "                                try:\n",
    "                                    model = NLinearModel(\n",
    "                                        input_chunk_length=input_chunk_length,\n",
    "                                        output_chunk_length=output_chunk_length,\n",
    "                                        shared_weights=shared_weights,\n",
    "                                        const_init=const_init,\n",
    "                                        normalize=normalize,\n",
    "                                        use_static_covariates=use_static_covariates,\n",
    "                                        batch_size=batch_size,\n",
    "                                        n_epochs=400,\n",
    "                                        optimizer_kwargs={'lr': lr},\n",
    "                                        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "                                        random_state = 0\n",
    "                                    )\n",
    "                                    model.fit(train_scaled)\n",
    "                                    pred_series, mape_nlinear, sle_nlinear = eval_model(\n",
    "                                        model,\n",
    "                                        len(val_scaled),\n",
    "                                        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                        val_scaled,\n",
    "                                        target_series = train_scaled,\n",
    "                                        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                        plot = False,\n",
    "                                    )\n",
    "                                    uTheil = UTheil()\n",
    "                                    u1_nlinear = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "                                    u2_nlinear = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "                                    print({\n",
    "                                        'MAPE': mape_nlinear,\n",
    "                                        'SLE': sle_nlinear,\n",
    "                                        'U1': u1_nlinear,\n",
    "                                        'U2': u1_nlinear,\n",
    "                                        'lr': lr,\n",
    "                                        'input_chunk_length': input_chunk_length,\n",
    "                                        'output_chunk_length': output_chunk_length,\n",
    "                                        'shared_weights': shared_weights,\n",
    "                                        'const_init': const_init,\n",
    "                                        'normalize': normalize,\n",
    "                                        'use_static_covariates': use_static_covariates,\n",
    "                                        'batch_size': batch_size,\n",
    "                                    })\n",
    "                                    models_nlinear.append({\n",
    "                                        'MAPE': mape_nlinear,\n",
    "                                        'SLE': sle_nlinear,\n",
    "                                        'U1': u1_nlinear,\n",
    "                                        'U2': u1_nlinear,\n",
    "                                        'lr': lr,\n",
    "                                        'input_chunk_length': input_chunk_length,\n",
    "                                        'output_chunk_length': output_chunk_length,\n",
    "                                        'shared_weights': shared_weights,\n",
    "                                        'const_init': const_init,\n",
    "                                        'normalize': normalize,\n",
    "                                        'use_static_covariates': use_static_covariates,\n",
    "                                        'batch_size': batch_size,\n",
    "                                    })\n",
    "                                except:\n",
    "                                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_nlinear in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_nlinear, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_nlinear, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'shared_weights': min(models_nlinear, key=lambda d: d[i])['shared_weights'],\n",
    "                                'const_init': min(models_nlinear, key=lambda d: d[i])['const_init'],\n",
    "                                'normalize': min(models_nlinear, key=lambda d: d[i])['normalize'],\n",
    "                                'use_static_covariates': min(models_nlinear, key=lambda d: d[i])['use_static_covariates'],\n",
    "                                'batch_size': min(models_nlinear, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_nlinear, key=lambda d: d[i])['lr'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_nlinear['name'])\n",
    "    model = NLinearModel(\n",
    "        input_chunk_length=best_model_nlinear['input_chunk_length'],\n",
    "        output_chunk_length=best_model_nlinear['output_chunk_length'],\n",
    "        shared_weights=best_model_nlinear['shared_weights'],\n",
    "        const_init=best_model_nlinear['const_init'],\n",
    "        normalize=best_model_nlinear['normalize'],\n",
    "        use_static_covariates=best_model_nlinear['use_static_covariates'],\n",
    "        batch_size=best_model_nlinear['batch_size'],\n",
    "        n_epochs=400,\n",
    "        optimizer_kwargs={'lr': best_model_nlinear['lr']},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit(train_scaled)\n",
    "    pred_series, mape_nlinear, sle_nlinear = eval_model(\n",
    "        model,\n",
    "        len(val_scaled),\n",
    "        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_scaled,\n",
    "        target_series = train_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_nlinear = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "    u2_nlinear = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_nlinear)\n",
    "    print('U2: ', u2_nlinear)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    shared_weights = trial.suggest_categorical(\"shared_weights\", [True, False])\n",
    "    const_init = trial.suggest_categorical(\"const_init\", [True, False])\n",
    "    normalize = trial.suggest_categorical(\"normalize\", [True, False])\n",
    "    use_static_covariates = trial.suggest_categorical(\"use_static_covariates\", [True, False])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NLinearModel(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        shared_weights=shared_weights,\n",
    "        const_init=const_init,\n",
    "        normalize=normalize,\n",
    "        use_static_covariates=use_static_covariates,\n",
    "        batch_size=2**batch_size,\n",
    "        n_epochs=n_epochs,\n",
    "        optimizer_kwargs={'lr': lr},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NLinearModel(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    shared_weights=study.best_trial.params['shared_weights'],\n",
    "    const_init=study.best_trial.params['const_init'],\n",
    "    normalize=study.best_trial.params['normalize'],\n",
    "    use_static_covariates=study.best_trial.params['use_static_covariates'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    optimizer_kwargs={'lr': study.best_trial.params['lr']},\n",
    "    pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    shared_weights = trial.suggest_categorical(\"shared_weights\", [True, False])\n",
    "    const_init = trial.suggest_categorical(\"const_init\", [True, False])\n",
    "    normalize = trial.suggest_categorical(\"normalize\", [True, False])\n",
    "    use_static_covariates = trial.suggest_categorical(\"use_static_covariates\", [True, False])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NLinearModel(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        shared_weights=shared_weights,\n",
    "        const_init=const_init,\n",
    "        normalize=normalize,\n",
    "        use_static_covariates=use_static_covariates,\n",
    "        batch_size=2**batch_size,\n",
    "        n_epochs=n_epochs,\n",
    "        optimizer_kwargs={'lr': lr},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NLinearModel(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    shared_weights=study.best_trial.params['shared_weights'],\n",
    "    const_init=study.best_trial.params['const_init'],\n",
    "    normalize=study.best_trial.params['normalize'],\n",
    "    use_static_covariates=study.best_trial.params['use_static_covariates'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    optimizer_kwargs={'lr': study.best_trial.params['lr']},\n",
    "    pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando MAPE e U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    shared_weights = trial.suggest_categorical(\"shared_weights\", [True, False])\n",
    "    const_init = trial.suggest_categorical(\"const_init\", [True, False])\n",
    "    normalize = trial.suggest_categorical(\"normalize\", [True, False])\n",
    "    use_static_covariates = trial.suggest_categorical(\"use_static_covariates\", [True, False])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NLinearModel(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        shared_weights=shared_weights,\n",
    "        const_init=const_init,\n",
    "        normalize=normalize,\n",
    "        use_static_covariates=use_static_covariates,\n",
    "        batch_size=2**batch_size,\n",
    "        n_epochs=n_epochs,\n",
    "        optimizer_kwargs={'lr': lr},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_scaled, preds)\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NLinearModel(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    shared_weights=study.best_trial.params['shared_weights'],\n",
    "    const_init=study.best_trial.params['const_init'],\n",
    "    normalize=study.best_trial.params['normalize'],\n",
    "    use_static_covariates=study.best_trial.params['use_static_covariates'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    optimizer_kwargs={'lr': study.best_trial.params['lr']},\n",
    "    pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Brasil (detrend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Janela deslizante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_nlinear = []\n",
    "\n",
    "for input_chunk_length in range(20, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "        for batch_size in [2**i for i in range(4,7)]:\n",
    "           for shared_weights in [True, False]:\n",
    "               for const_init in [True, False]:\n",
    "                   for normalize in [True, False]:\n",
    "                       for use_static_covariates in [True, False]:\n",
    "                           for lr in [10**(-i) for i in range(2, 5):\n",
    "                                try:\n",
    "                                    model = NLinearModel(\n",
    "                                        input_chunk_length=input_chunk_length,\n",
    "                                        output_chunk_length=output_chunk_length,\n",
    "                                        shared_weights=shared_weights,\n",
    "                                        const_init=const_init,\n",
    "                                        normalize=normalize,\n",
    "                                        use_static_covariates=use_static_covariates,\n",
    "                                        batch_size=batch_size,\n",
    "                                        n_epochs=400,\n",
    "                                        optimizer_kwargs={'lr': lr},\n",
    "                                        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "                                        random_state = 0\n",
    "                                    )\n",
    "                                    model.fit(train_detrend_scaled)\n",
    "                                    pred_series, mape_nlinear, sle_nlinear = eval_model(\n",
    "                                        model,\n",
    "                                        len(val_detrend_scaled),\n",
    "                                        series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                        val_detrend_scaled,\n",
    "                                        target_series = train_detrend_scaled,\n",
    "                                        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                        plot = False,\n",
    "                                    )\n",
    "                                    uTheil = UTheil()\n",
    "                                    u1_nlinear = uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)])\n",
    "                                    u2_nlinear = uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)])\n",
    "                                    print({\n",
    "                                        'MAPE': mape_nlinear,\n",
    "                                        'SLE': sle_nlinear,\n",
    "                                        'U1': u1_nlinear,\n",
    "                                        'U2': u1_nlinear,\n",
    "                                        'lr': lr,\n",
    "                                        'input_chunk_length': input_chunk_length,\n",
    "                                        'output_chunk_length': output_chunk_length,\n",
    "                                        'shared_weights': shared_weights,\n",
    "                                        'const_init': const_init,\n",
    "                                        'normalize': normalize,\n",
    "                                        'use_static_covariates': use_static_covariates,\n",
    "                                        'batch_size': batch_size,\n",
    "                                    })\n",
    "                                    models_nlinear.append({\n",
    "                                        'MAPE': mape_nlinear,\n",
    "                                        'SLE': sle_nlinear,\n",
    "                                        'U1': u1_nlinear,\n",
    "                                        'U2': u1_nlinear,\n",
    "                                        'lr': lr,\n",
    "                                        'input_chunk_length': input_chunk_length,\n",
    "                                        'output_chunk_length': output_chunk_length,\n",
    "                                        'shared_weights': shared_weights,\n",
    "                                        'const_init': const_init,\n",
    "                                        'normalize': normalize,\n",
    "                                        'use_static_covariates': use_static_covariates,\n",
    "                                        'batch_size': batch_size,\n",
    "                                    })\n",
    "                                except:\n",
    "                                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_nlinear in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_nlinear, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_nlinear, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'shared_weights': min(models_nlinear, key=lambda d: d[i])['shared_weights'],\n",
    "                                'const_init': min(models_nlinear, key=lambda d: d[i])['const_init'],\n",
    "                                'normalize': min(models_nlinear, key=lambda d: d[i])['normalize'],\n",
    "                                'use_static_covariates': min(models_nlinear, key=lambda d: d[i])['use_static_covariates'],\n",
    "                                'batch_size': min(models_nlinear, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_nlinear, key=lambda d: d[i])['lr'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_nlinear['name'])\n",
    "    model = NLinearModel(\n",
    "        input_chunk_length=best_model_nlinear['input_chunk_length'],\n",
    "        output_chunk_length=best_model_nlinear['output_chunk_length'],\n",
    "        shared_weights=best_model_nlinear['shared_weights'],\n",
    "        const_init=best_model_nlinear['const_init'],\n",
    "        normalize=best_model_nlinear['normalize'],\n",
    "        use_static_covariates=best_model_nlinear['use_static_covariates'],\n",
    "        batch_size=best_model_nlinear['batch_size'],\n",
    "        n_epochs=400,\n",
    "        optimizer_kwargs={'lr': best_model_nlinear['lr']},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit(train_detrend_scaled)\n",
    "    pred_series, mape_nlinear, sle_nlinear = eval_model(\n",
    "        model,\n",
    "        len(val_detrend_scaled),\n",
    "        series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_detrend_scaled,\n",
    "        target_series = train_detrend_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_nlinear = uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)])\n",
    "    u2_nlinear = uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_nlinear)\n",
    "    print('U2: ', u2_nlinear)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    shared_weights = trial.suggest_categorical(\"shared_weights\", [True, False])\n",
    "    const_init = trial.suggest_categorical(\"const_init\", [True, False])\n",
    "    normalize = trial.suggest_categorical(\"normalize\", [True, False])\n",
    "    use_static_covariates = trial.suggest_categorical(\"use_static_covariates\", [True, False])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NLinearModel(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        shared_weights=shared_weights,\n",
    "        const_init=const_init,\n",
    "        normalize=normalize,\n",
    "        use_static_covariates=use_static_covariates,\n",
    "        batch_size=2**batch_size,\n",
    "        n_epochs=n_epochs,\n",
    "        optimizer_kwargs={'lr': lr},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_detrend_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    mapes = mape(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NLinearModel(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    shared_weights=study.best_trial.params['shared_weights'],\n",
    "    const_init=study.best_trial.params['const_init'],\n",
    "    normalize=study.best_trial.params['normalize'],\n",
    "    use_static_covariates=study.best_trial.params['use_static_covariates'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    optimizer_kwargs={'lr': study.best_trial.params['lr']},\n",
    "    pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_detrend_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    shared_weights = trial.suggest_categorical(\"shared_weights\", [True, False])\n",
    "    const_init = trial.suggest_categorical(\"const_init\", [True, False])\n",
    "    normalize = trial.suggest_categorical(\"normalize\", [True, False])\n",
    "    use_static_covariates = trial.suggest_categorical(\"use_static_covariates\", [True, False])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NLinearModel(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        shared_weights=shared_weights,\n",
    "        const_init=const_init,\n",
    "        normalize=normalize,\n",
    "        use_static_covariates=use_static_covariates,\n",
    "        batch_size=2**batch_size,\n",
    "        n_epochs=n_epochs,\n",
    "        optimizer_kwargs={'lr': lr},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_detrend_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NLinearModel(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    shared_weights=study.best_trial.params['shared_weights'],\n",
    "    const_init=study.best_trial.params['const_init'],\n",
    "    normalize=study.best_trial.params['normalize'],\n",
    "    use_static_covariates=study.best_trial.params['use_static_covariates'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    optimizer_kwargs={'lr': study.best_trial.params['lr']},\n",
    "    pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_detrend_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando MAPE e U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    shared_weights = trial.suggest_categorical(\"shared_weights\", [True, False])\n",
    "    const_init = trial.suggest_categorical(\"const_init\", [True, False])\n",
    "    normalize = trial.suggest_categorical(\"normalize\", [True, False])\n",
    "    use_static_covariates = trial.suggest_categorical(\"use_static_covariates\", [True, False])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NLinearModel(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        shared_weights=shared_weights,\n",
    "        const_init=const_init,\n",
    "        normalize=normalize,\n",
    "        use_static_covariates=use_static_covariates,\n",
    "        batch_size=2**batch_size,\n",
    "        n_epochs=n_epochs,\n",
    "        optimizer_kwargs={'lr': lr},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_detrend_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_detrend_scaled, preds)\n",
    "    mapes = mape(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NLinearModel(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    shared_weights=study.best_trial.params['shared_weights'],\n",
    "    const_init=study.best_trial.params['const_init'],\n",
    "    normalize=study.best_trial.params['normalize'],\n",
    "    use_static_covariates=study.best_trial.params['use_static_covariates'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    optimizer_kwargs={'lr': study.best_trial.params['lr']},\n",
    "    pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_detrend_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Brasil + Sudeste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Janela deslizante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_nlinear = []\n",
    "\n",
    "for input_chunk_length in range(20, 24, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "        for batch_size in [2**i for i in range(4,7)]:\n",
    "           for shared_weights in [True, False]:\n",
    "               for const_init in [True, False]:\n",
    "                   for normalize in [True, False]:\n",
    "                       for use_static_covariates in [True, False]:\n",
    "                           for lr in [10**(-i) for i in [2]]:\n",
    "                                try:\n",
    "                                    model = NLinearModel(\n",
    "                                        input_chunk_length=input_chunk_length,\n",
    "                                        output_chunk_length=output_chunk_length,\n",
    "                                        shared_weights=shared_weights,\n",
    "                                        const_init=const_init,\n",
    "                                        normalize=normalize,\n",
    "                                        use_static_covariates=use_static_covariates,\n",
    "                                        batch_size=batch_size,\n",
    "                                        n_epochs=400,\n",
    "                                        optimizer_kwargs={'lr': lr},\n",
    "                                        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "                                        random_state = 0\n",
    "                                    )\n",
    "                                    model.fit([train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())])\n",
    "                                    pred_series, mape_nlinear, sle_nlinear = eval_model(\n",
    "                                        model,\n",
    "                                        len(val_scaled),\n",
    "                                        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                        val_scaled,\n",
    "                                        target_series = train_scaled,\n",
    "                                        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                        plot = False,\n",
    "                                    )\n",
    "                                    uTheil = UTheil()\n",
    "                                    u1_nlinear = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "                                    u2_nlinear = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "                                    print({\n",
    "                                        'MAPE': mape_nlinear,\n",
    "                                        'SLE': sle_nlinear,\n",
    "                                        'U1': u1_nlinear,\n",
    "                                        'U2': u1_nlinear,\n",
    "                                        'lr': lr,\n",
    "                                        'input_chunk_length': input_chunk_length,\n",
    "                                        'output_chunk_length': output_chunk_length,\n",
    "                                        'shared_weights': shared_weights,\n",
    "                                        'const_init': const_init,\n",
    "                                        'normalize': normalize,\n",
    "                                        'use_static_covariates': use_static_covariates,\n",
    "                                        'batch_size': batch_size,\n",
    "                                    })\n",
    "                                    models_nlinear.append({\n",
    "                                        'MAPE': mape_nlinear,\n",
    "                                        'SLE': sle_nlinear,\n",
    "                                        'U1': u1_nlinear,\n",
    "                                        'U2': u1_nlinear,\n",
    "                                        'lr': lr,\n",
    "                                        'input_chunk_length': input_chunk_length,\n",
    "                                        'output_chunk_length': output_chunk_length,\n",
    "                                        'shared_weights': shared_weights,\n",
    "                                        'const_init': const_init,\n",
    "                                        'normalize': normalize,\n",
    "                                        'use_static_covariates': use_static_covariates,\n",
    "                                        'batch_size': batch_size,\n",
    "                                    })\n",
    "                                except:\n",
    "                                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_nlinear in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_nlinear, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_nlinear, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'shared_weights': min(models_nlinear, key=lambda d: d[i])['shared_weights'],\n",
    "                                'const_init': min(models_nlinear, key=lambda d: d[i])['const_init'],\n",
    "                                'normalize': min(models_nlinear, key=lambda d: d[i])['normalize'],\n",
    "                                'use_static_covariates': min(models_nlinear, key=lambda d: d[i])['use_static_covariates'],\n",
    "                                'batch_size': min(models_nlinear, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_nlinear, key=lambda d: d[i])['lr'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_nlinear['name'])\n",
    "    model = NLinearModel(\n",
    "        input_chunk_length=best_model_nlinear['input_chunk_length'],\n",
    "        output_chunk_length=best_model_nlinear['output_chunk_length'],\n",
    "        shared_weights=best_model_nlinear['shared_weights'],\n",
    "        const_init=best_model_nlinear['const_init'],\n",
    "        normalize=best_model_nlinear['normalize'],\n",
    "        use_static_covariates=best_model_nlinear['use_static_covariates'],\n",
    "        batch_size=best_model_nlinear['batch_size'],\n",
    "        n_epochs=400,\n",
    "        optimizer_kwargs={'lr': best_model_nlinear['lr']},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit([train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())])\n",
    "    pred_series, mape_nlinear, sle_nlinear = eval_model(\n",
    "        model,\n",
    "        len(val_scaled),\n",
    "        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_scaled,\n",
    "        target_series = train_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_nlinear = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "    u2_nlinear = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_nlinear)\n",
    "    print('U2: ', u2_nlinear)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_nlinear = []\n",
    "\n",
    "for input_chunk_length in range(24, 26, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "        for batch_size in [2**i for i in range(4,7)]:\n",
    "           for shared_weights in [True, False]:\n",
    "               for const_init in [True, False]:\n",
    "                   for normalize in [True, False]:\n",
    "                       for use_static_covariates in [True, False]:\n",
    "                           for lr in [10**(-i) for i in [2]]:\n",
    "                                try:\n",
    "                                    model = NLinearModel(\n",
    "                                        input_chunk_length=input_chunk_length,\n",
    "                                        output_chunk_length=output_chunk_length,\n",
    "                                        shared_weights=shared_weights,\n",
    "                                        const_init=const_init,\n",
    "                                        normalize=normalize,\n",
    "                                        use_static_covariates=use_static_covariates,\n",
    "                                        batch_size=batch_size,\n",
    "                                        n_epochs=400,\n",
    "                                        optimizer_kwargs={'lr': lr},\n",
    "                                        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "                                        random_state = 0\n",
    "                                    )\n",
    "                                    model.fit([train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())])\n",
    "                                    pred_series, mape_nlinear, sle_nlinear = eval_model(\n",
    "                                        model,\n",
    "                                        len(val_scaled),\n",
    "                                        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                        val_scaled,\n",
    "                                        target_series = train_scaled,\n",
    "                                        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                        plot = False,\n",
    "                                    )\n",
    "                                    uTheil = UTheil()\n",
    "                                    u1_nlinear = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "                                    u2_nlinear = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "                                    print({\n",
    "                                        'MAPE': mape_nlinear,\n",
    "                                        'SLE': sle_nlinear,\n",
    "                                        'U1': u1_nlinear,\n",
    "                                        'U2': u1_nlinear,\n",
    "                                        'lr': lr,\n",
    "                                        'input_chunk_length': input_chunk_length,\n",
    "                                        'output_chunk_length': output_chunk_length,\n",
    "                                        'shared_weights': shared_weights,\n",
    "                                        'const_init': const_init,\n",
    "                                        'normalize': normalize,\n",
    "                                        'use_static_covariates': use_static_covariates,\n",
    "                                        'batch_size': batch_size,\n",
    "                                    })\n",
    "                                    models_nlinear.append({\n",
    "                                        'MAPE': mape_nlinear,\n",
    "                                        'SLE': sle_nlinear,\n",
    "                                        'U1': u1_nlinear,\n",
    "                                        'U2': u1_nlinear,\n",
    "                                        'lr': lr,\n",
    "                                        'input_chunk_length': input_chunk_length,\n",
    "                                        'output_chunk_length': output_chunk_length,\n",
    "                                        'shared_weights': shared_weights,\n",
    "                                        'const_init': const_init,\n",
    "                                        'normalize': normalize,\n",
    "                                        'use_static_covariates': use_static_covariates,\n",
    "                                        'batch_size': batch_size,\n",
    "                                    })\n",
    "                                except:\n",
    "                                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_nlinear in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_nlinear, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_nlinear, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'shared_weights': min(models_nlinear, key=lambda d: d[i])['shared_weights'],\n",
    "                                'const_init': min(models_nlinear, key=lambda d: d[i])['const_init'],\n",
    "                                'normalize': min(models_nlinear, key=lambda d: d[i])['normalize'],\n",
    "                                'use_static_covariates': min(models_nlinear, key=lambda d: d[i])['use_static_covariates'],\n",
    "                                'batch_size': min(models_nlinear, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_nlinear, key=lambda d: d[i])['lr'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_nlinear['name'])\n",
    "    model = NLinearModel(\n",
    "        input_chunk_length=best_model_nlinear['input_chunk_length'],\n",
    "        output_chunk_length=best_model_nlinear['output_chunk_length'],\n",
    "        shared_weights=best_model_nlinear['shared_weights'],\n",
    "        const_init=best_model_nlinear['const_init'],\n",
    "        normalize=best_model_nlinear['normalize'],\n",
    "        use_static_covariates=best_model_nlinear['use_static_covariates'],\n",
    "        batch_size=best_model_nlinear['batch_size'],\n",
    "        n_epochs=400,\n",
    "        optimizer_kwargs={'lr': best_model_nlinear['lr']},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit([train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())])\n",
    "    pred_series, mape_nlinear, sle_nlinear = eval_model(\n",
    "        model,\n",
    "        len(val_scaled),\n",
    "        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_scaled,\n",
    "        target_series = train_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_nlinear = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "    u2_nlinear = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_nlinear)\n",
    "    print('U2: ', u2_nlinear)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_nlinear = []\n",
    "\n",
    "for input_chunk_length in range(26, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "        for batch_size in [2**i for i in range(4,7)]:\n",
    "           for shared_weights in [True, False]:\n",
    "               for const_init in [True, False]:\n",
    "                   for normalize in [True, False]:\n",
    "                       for use_static_covariates in [True, False]:\n",
    "                           for lr in [10**(-i) for i in [2]]:\n",
    "                                try:\n",
    "                                    model = NLinearModel(\n",
    "                                        input_chunk_length=input_chunk_length,\n",
    "                                        output_chunk_length=output_chunk_length,\n",
    "                                        shared_weights=shared_weights,\n",
    "                                        const_init=const_init,\n",
    "                                        normalize=normalize,\n",
    "                                        use_static_covariates=use_static_covariates,\n",
    "                                        batch_size=batch_size,\n",
    "                                        n_epochs=400,\n",
    "                                        optimizer_kwargs={'lr': lr},\n",
    "                                        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "                                        random_state = 0\n",
    "                                    )\n",
    "                                    model.fit([train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())])\n",
    "                                    pred_series, mape_nlinear, sle_nlinear = eval_model(\n",
    "                                        model,\n",
    "                                        len(val_scaled),\n",
    "                                        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                        val_scaled,\n",
    "                                        target_series = train_scaled,\n",
    "                                        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                        plot = False,\n",
    "                                    )\n",
    "                                    uTheil = UTheil()\n",
    "                                    u1_nlinear = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "                                    u2_nlinear = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "                                    print({\n",
    "                                        'MAPE': mape_nlinear,\n",
    "                                        'SLE': sle_nlinear,\n",
    "                                        'U1': u1_nlinear,\n",
    "                                        'U2': u1_nlinear,\n",
    "                                        'lr': lr,\n",
    "                                        'input_chunk_length': input_chunk_length,\n",
    "                                        'output_chunk_length': output_chunk_length,\n",
    "                                        'shared_weights': shared_weights,\n",
    "                                        'const_init': const_init,\n",
    "                                        'normalize': normalize,\n",
    "                                        'use_static_covariates': use_static_covariates,\n",
    "                                        'batch_size': batch_size,\n",
    "                                    })\n",
    "                                    models_nlinear.append({\n",
    "                                        'MAPE': mape_nlinear,\n",
    "                                        'SLE': sle_nlinear,\n",
    "                                        'U1': u1_nlinear,\n",
    "                                        'U2': u1_nlinear,\n",
    "                                        'lr': lr,\n",
    "                                        'input_chunk_length': input_chunk_length,\n",
    "                                        'output_chunk_length': output_chunk_length,\n",
    "                                        'shared_weights': shared_weights,\n",
    "                                        'const_init': const_init,\n",
    "                                        'normalize': normalize,\n",
    "                                        'use_static_covariates': use_static_covariates,\n",
    "                                        'batch_size': batch_size,\n",
    "                                    })\n",
    "                                except:\n",
    "                                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_nlinear in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_nlinear, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_nlinear, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'shared_weights': min(models_nlinear, key=lambda d: d[i])['shared_weights'],\n",
    "                                'const_init': min(models_nlinear, key=lambda d: d[i])['const_init'],\n",
    "                                'normalize': min(models_nlinear, key=lambda d: d[i])['normalize'],\n",
    "                                'use_static_covariates': min(models_nlinear, key=lambda d: d[i])['use_static_covariates'],\n",
    "                                'batch_size': min(models_nlinear, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_nlinear, key=lambda d: d[i])['lr'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_nlinear['name'])\n",
    "    model = NLinearModel(\n",
    "        input_chunk_length=best_model_nlinear['input_chunk_length'],\n",
    "        output_chunk_length=best_model_nlinear['output_chunk_length'],\n",
    "        shared_weights=best_model_nlinear['shared_weights'],\n",
    "        const_init=best_model_nlinear['const_init'],\n",
    "        normalize=best_model_nlinear['normalize'],\n",
    "        use_static_covariates=best_model_nlinear['use_static_covariates'],\n",
    "        batch_size=best_model_nlinear['batch_size'],\n",
    "        n_epochs=400,\n",
    "        optimizer_kwargs={'lr': best_model_nlinear['lr']},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit([train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())])\n",
    "    pred_series, mape_nlinear, sle_nlinear = eval_model(\n",
    "        model,\n",
    "        len(val_scaled),\n",
    "        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_scaled,\n",
    "        target_series = train_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_nlinear = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "    u2_nlinear = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_nlinear)\n",
    "    print('U2: ', u2_nlinear)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_nlinear = []\n",
    "\n",
    "for input_chunk_length in range(20, 24, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "        for batch_size in [2**i for i in range(4,7)]:\n",
    "           for shared_weights in [True, False]:\n",
    "               for const_init in [True, False]:\n",
    "                   for normalize in [True, False]:\n",
    "                       for use_static_covariates in [True, False]:\n",
    "                           for lr in [10**(-i) for i in [3]]:\n",
    "                                try:\n",
    "                                    model = NLinearModel(\n",
    "                                        input_chunk_length=input_chunk_length,\n",
    "                                        output_chunk_length=output_chunk_length,\n",
    "                                        shared_weights=shared_weights,\n",
    "                                        const_init=const_init,\n",
    "                                        normalize=normalize,\n",
    "                                        use_static_covariates=use_static_covariates,\n",
    "                                        batch_size=batch_size,\n",
    "                                        n_epochs=400,\n",
    "                                        optimizer_kwargs={'lr': lr},\n",
    "                                        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "                                        random_state = 0\n",
    "                                    )\n",
    "                                    model.fit([train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())])\n",
    "                                    pred_series, mape_nlinear, sle_nlinear = eval_model(\n",
    "                                        model,\n",
    "                                        len(val_scaled),\n",
    "                                        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                        val_scaled,\n",
    "                                        target_series = train_scaled,\n",
    "                                        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                        plot = False,\n",
    "                                    )\n",
    "                                    uTheil = UTheil()\n",
    "                                    u1_nlinear = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "                                    u2_nlinear = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "                                    print({\n",
    "                                        'MAPE': mape_nlinear,\n",
    "                                        'SLE': sle_nlinear,\n",
    "                                        'U1': u1_nlinear,\n",
    "                                        'U2': u1_nlinear,\n",
    "                                        'lr': lr,\n",
    "                                        'input_chunk_length': input_chunk_length,\n",
    "                                        'output_chunk_length': output_chunk_length,\n",
    "                                        'shared_weights': shared_weights,\n",
    "                                        'const_init': const_init,\n",
    "                                        'normalize': normalize,\n",
    "                                        'use_static_covariates': use_static_covariates,\n",
    "                                        'batch_size': batch_size,\n",
    "                                    })\n",
    "                                    models_nlinear.append({\n",
    "                                        'MAPE': mape_nlinear,\n",
    "                                        'SLE': sle_nlinear,\n",
    "                                        'U1': u1_nlinear,\n",
    "                                        'U2': u1_nlinear,\n",
    "                                        'lr': lr,\n",
    "                                        'input_chunk_length': input_chunk_length,\n",
    "                                        'output_chunk_length': output_chunk_length,\n",
    "                                        'shared_weights': shared_weights,\n",
    "                                        'const_init': const_init,\n",
    "                                        'normalize': normalize,\n",
    "                                        'use_static_covariates': use_static_covariates,\n",
    "                                        'batch_size': batch_size,\n",
    "                                    })\n",
    "                                except:\n",
    "                                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_nlinear in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_nlinear, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_nlinear, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'shared_weights': min(models_nlinear, key=lambda d: d[i])['shared_weights'],\n",
    "                                'const_init': min(models_nlinear, key=lambda d: d[i])['const_init'],\n",
    "                                'normalize': min(models_nlinear, key=lambda d: d[i])['normalize'],\n",
    "                                'use_static_covariates': min(models_nlinear, key=lambda d: d[i])['use_static_covariates'],\n",
    "                                'batch_size': min(models_nlinear, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_nlinear, key=lambda d: d[i])['lr'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_nlinear['name'])\n",
    "    model = NLinearModel(\n",
    "        input_chunk_length=best_model_nlinear['input_chunk_length'],\n",
    "        output_chunk_length=best_model_nlinear['output_chunk_length'],\n",
    "        shared_weights=best_model_nlinear['shared_weights'],\n",
    "        const_init=best_model_nlinear['const_init'],\n",
    "        normalize=best_model_nlinear['normalize'],\n",
    "        use_static_covariates=best_model_nlinear['use_static_covariates'],\n",
    "        batch_size=best_model_nlinear['batch_size'],\n",
    "        n_epochs=400,\n",
    "        optimizer_kwargs={'lr': best_model_nlinear['lr']},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit([train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())])\n",
    "    pred_series, mape_nlinear, sle_nlinear = eval_model(\n",
    "        model,\n",
    "        len(val_scaled),\n",
    "        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_scaled,\n",
    "        target_series = train_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_nlinear = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "    u2_nlinear = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_nlinear)\n",
    "    print('U2: ', u2_nlinear)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_nlinear = []\n",
    "\n",
    "for input_chunk_length in range(24, 26, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "        for batch_size in [2**i for i in range(4,7)]:\n",
    "           for shared_weights in [True, False]:\n",
    "               for const_init in [True, False]:\n",
    "                   for normalize in [True, False]:\n",
    "                       for use_static_covariates in [True, False]:\n",
    "                           for lr in [10**(-i) for i in [3]]:\n",
    "                                try:\n",
    "                                    model = NLinearModel(\n",
    "                                        input_chunk_length=input_chunk_length,\n",
    "                                        output_chunk_length=output_chunk_length,\n",
    "                                        shared_weights=shared_weights,\n",
    "                                        const_init=const_init,\n",
    "                                        normalize=normalize,\n",
    "                                        use_static_covariates=use_static_covariates,\n",
    "                                        batch_size=batch_size,\n",
    "                                        n_epochs=400,\n",
    "                                        optimizer_kwargs={'lr': lr},\n",
    "                                        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "                                        random_state = 0\n",
    "                                    )\n",
    "                                    model.fit([train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())])\n",
    "                                    pred_series, mape_nlinear, sle_nlinear = eval_model(\n",
    "                                        model,\n",
    "                                        len(val_scaled),\n",
    "                                        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                        val_scaled,\n",
    "                                        target_series = train_scaled,\n",
    "                                        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                        plot = False,\n",
    "                                    )\n",
    "                                    uTheil = UTheil()\n",
    "                                    u1_nlinear = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "                                    u2_nlinear = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "                                    print({\n",
    "                                        'MAPE': mape_nlinear,\n",
    "                                        'SLE': sle_nlinear,\n",
    "                                        'U1': u1_nlinear,\n",
    "                                        'U2': u1_nlinear,\n",
    "                                        'lr': lr,\n",
    "                                        'input_chunk_length': input_chunk_length,\n",
    "                                        'output_chunk_length': output_chunk_length,\n",
    "                                        'shared_weights': shared_weights,\n",
    "                                        'const_init': const_init,\n",
    "                                        'normalize': normalize,\n",
    "                                        'use_static_covariates': use_static_covariates,\n",
    "                                        'batch_size': batch_size,\n",
    "                                    })\n",
    "                                    models_nlinear.append({\n",
    "                                        'MAPE': mape_nlinear,\n",
    "                                        'SLE': sle_nlinear,\n",
    "                                        'U1': u1_nlinear,\n",
    "                                        'U2': u1_nlinear,\n",
    "                                        'lr': lr,\n",
    "                                        'input_chunk_length': input_chunk_length,\n",
    "                                        'output_chunk_length': output_chunk_length,\n",
    "                                        'shared_weights': shared_weights,\n",
    "                                        'const_init': const_init,\n",
    "                                        'normalize': normalize,\n",
    "                                        'use_static_covariates': use_static_covariates,\n",
    "                                        'batch_size': batch_size,\n",
    "                                    })\n",
    "                                except:\n",
    "                                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_nlinear in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_nlinear, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_nlinear, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'shared_weights': min(models_nlinear, key=lambda d: d[i])['shared_weights'],\n",
    "                                'const_init': min(models_nlinear, key=lambda d: d[i])['const_init'],\n",
    "                                'normalize': min(models_nlinear, key=lambda d: d[i])['normalize'],\n",
    "                                'use_static_covariates': min(models_nlinear, key=lambda d: d[i])['use_static_covariates'],\n",
    "                                'batch_size': min(models_nlinear, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_nlinear, key=lambda d: d[i])['lr'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_nlinear['name'])\n",
    "    model = NLinearModel(\n",
    "        input_chunk_length=best_model_nlinear['input_chunk_length'],\n",
    "        output_chunk_length=best_model_nlinear['output_chunk_length'],\n",
    "        shared_weights=best_model_nlinear['shared_weights'],\n",
    "        const_init=best_model_nlinear['const_init'],\n",
    "        normalize=best_model_nlinear['normalize'],\n",
    "        use_static_covariates=best_model_nlinear['use_static_covariates'],\n",
    "        batch_size=best_model_nlinear['batch_size'],\n",
    "        n_epochs=400,\n",
    "        optimizer_kwargs={'lr': best_model_nlinear['lr']},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit([train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())])\n",
    "    pred_series, mape_nlinear, sle_nlinear = eval_model(\n",
    "        model,\n",
    "        len(val_scaled),\n",
    "        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_scaled,\n",
    "        target_series = train_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_nlinear = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "    u2_nlinear = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_nlinear)\n",
    "    print('U2: ', u2_nlinear)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_nlinear = []\n",
    "\n",
    "for input_chunk_length in range(26, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "        for batch_size in [2**i for i in range(4,7)]:\n",
    "           for shared_weights in [True, False]:\n",
    "               for const_init in [True, False]:\n",
    "                   for normalize in [True, False]:\n",
    "                       for use_static_covariates in [True, False]:\n",
    "                           for lr in [10**(-i) for i in [3]]:\n",
    "                                try:\n",
    "                                    model = NLinearModel(\n",
    "                                        input_chunk_length=input_chunk_length,\n",
    "                                        output_chunk_length=output_chunk_length,\n",
    "                                        shared_weights=shared_weights,\n",
    "                                        const_init=const_init,\n",
    "                                        normalize=normalize,\n",
    "                                        use_static_covariates=use_static_covariates,\n",
    "                                        batch_size=batch_size,\n",
    "                                        n_epochs=400,\n",
    "                                        optimizer_kwargs={'lr': lr},\n",
    "                                        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "                                        random_state = 0\n",
    "                                    )\n",
    "                                    model.fit([train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())])\n",
    "                                    pred_series, mape_nlinear, sle_nlinear = eval_model(\n",
    "                                        model,\n",
    "                                        len(val_scaled),\n",
    "                                        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                        val_scaled,\n",
    "                                        target_series = train_scaled,\n",
    "                                        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                        plot = False,\n",
    "                                    )\n",
    "                                    uTheil = UTheil()\n",
    "                                    u1_nlinear = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "                                    u2_nlinear = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "                                    print({\n",
    "                                        'MAPE': mape_nlinear,\n",
    "                                        'SLE': sle_nlinear,\n",
    "                                        'U1': u1_nlinear,\n",
    "                                        'U2': u1_nlinear,\n",
    "                                        'lr': lr,\n",
    "                                        'input_chunk_length': input_chunk_length,\n",
    "                                        'output_chunk_length': output_chunk_length,\n",
    "                                        'shared_weights': shared_weights,\n",
    "                                        'const_init': const_init,\n",
    "                                        'normalize': normalize,\n",
    "                                        'use_static_covariates': use_static_covariates,\n",
    "                                        'batch_size': batch_size,\n",
    "                                    })\n",
    "                                    models_nlinear.append({\n",
    "                                        'MAPE': mape_nlinear,\n",
    "                                        'SLE': sle_nlinear,\n",
    "                                        'U1': u1_nlinear,\n",
    "                                        'U2': u1_nlinear,\n",
    "                                        'lr': lr,\n",
    "                                        'input_chunk_length': input_chunk_length,\n",
    "                                        'output_chunk_length': output_chunk_length,\n",
    "                                        'shared_weights': shared_weights,\n",
    "                                        'const_init': const_init,\n",
    "                                        'normalize': normalize,\n",
    "                                        'use_static_covariates': use_static_covariates,\n",
    "                                        'batch_size': batch_size,\n",
    "                                    })\n",
    "                                except:\n",
    "                                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_nlinear in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_nlinear, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_nlinear, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'shared_weights': min(models_nlinear, key=lambda d: d[i])['shared_weights'],\n",
    "                                'const_init': min(models_nlinear, key=lambda d: d[i])['const_init'],\n",
    "                                'normalize': min(models_nlinear, key=lambda d: d[i])['normalize'],\n",
    "                                'use_static_covariates': min(models_nlinear, key=lambda d: d[i])['use_static_covariates'],\n",
    "                                'batch_size': min(models_nlinear, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_nlinear, key=lambda d: d[i])['lr'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_nlinear['name'])\n",
    "    model = NLinearModel(\n",
    "        input_chunk_length=best_model_nlinear['input_chunk_length'],\n",
    "        output_chunk_length=best_model_nlinear['output_chunk_length'],\n",
    "        shared_weights=best_model_nlinear['shared_weights'],\n",
    "        const_init=best_model_nlinear['const_init'],\n",
    "        normalize=best_model_nlinear['normalize'],\n",
    "        use_static_covariates=best_model_nlinear['use_static_covariates'],\n",
    "        batch_size=best_model_nlinear['batch_size'],\n",
    "        n_epochs=400,\n",
    "        optimizer_kwargs={'lr': best_model_nlinear['lr']},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit([train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())])\n",
    "    pred_series, mape_nlinear, sle_nlinear = eval_model(\n",
    "        model,\n",
    "        len(val_scaled),\n",
    "        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_scaled,\n",
    "        target_series = train_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_nlinear = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "    u2_nlinear = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_nlinear)\n",
    "    print('U2: ', u2_nlinear)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_nlinear = []\n",
    "\n",
    "for input_chunk_length in range(20, 24, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "        for batch_size in [2**i for i in range(4,7)]:\n",
    "           for shared_weights in [True, False]:\n",
    "               for const_init in [True, False]:\n",
    "                   for normalize in [True, False]:\n",
    "                       for use_static_covariates in [True, False]:\n",
    "                           for lr in [10**(-i) for i in [4]]:\n",
    "                                try:\n",
    "                                    model = NLinearModel(\n",
    "                                        input_chunk_length=input_chunk_length,\n",
    "                                        output_chunk_length=output_chunk_length,\n",
    "                                        shared_weights=shared_weights,\n",
    "                                        const_init=const_init,\n",
    "                                        normalize=normalize,\n",
    "                                        use_static_covariates=use_static_covariates,\n",
    "                                        batch_size=batch_size,\n",
    "                                        n_epochs=400,\n",
    "                                        optimizer_kwargs={'lr': lr},\n",
    "                                        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "                                        random_state = 0\n",
    "                                    )\n",
    "                                    model.fit([train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())])\n",
    "                                    pred_series, mape_nlinear, sle_nlinear = eval_model(\n",
    "                                        model,\n",
    "                                        len(val_scaled),\n",
    "                                        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                        val_scaled,\n",
    "                                        target_series = train_scaled,\n",
    "                                        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                        plot = False,\n",
    "                                    )\n",
    "                                    uTheil = UTheil()\n",
    "                                    u1_nlinear = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "                                    u2_nlinear = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "                                    print({\n",
    "                                        'MAPE': mape_nlinear,\n",
    "                                        'SLE': sle_nlinear,\n",
    "                                        'U1': u1_nlinear,\n",
    "                                        'U2': u1_nlinear,\n",
    "                                        'lr': lr,\n",
    "                                        'input_chunk_length': input_chunk_length,\n",
    "                                        'output_chunk_length': output_chunk_length,\n",
    "                                        'shared_weights': shared_weights,\n",
    "                                        'const_init': const_init,\n",
    "                                        'normalize': normalize,\n",
    "                                        'use_static_covariates': use_static_covariates,\n",
    "                                        'batch_size': batch_size,\n",
    "                                    })\n",
    "                                    models_nlinear.append({\n",
    "                                        'MAPE': mape_nlinear,\n",
    "                                        'SLE': sle_nlinear,\n",
    "                                        'U1': u1_nlinear,\n",
    "                                        'U2': u1_nlinear,\n",
    "                                        'lr': lr,\n",
    "                                        'input_chunk_length': input_chunk_length,\n",
    "                                        'output_chunk_length': output_chunk_length,\n",
    "                                        'shared_weights': shared_weights,\n",
    "                                        'const_init': const_init,\n",
    "                                        'normalize': normalize,\n",
    "                                        'use_static_covariates': use_static_covariates,\n",
    "                                        'batch_size': batch_size,\n",
    "                                    })\n",
    "                                except:\n",
    "                                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_nlinear in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_nlinear, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_nlinear, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'shared_weights': min(models_nlinear, key=lambda d: d[i])['shared_weights'],\n",
    "                                'const_init': min(models_nlinear, key=lambda d: d[i])['const_init'],\n",
    "                                'normalize': min(models_nlinear, key=lambda d: d[i])['normalize'],\n",
    "                                'use_static_covariates': min(models_nlinear, key=lambda d: d[i])['use_static_covariates'],\n",
    "                                'batch_size': min(models_nlinear, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_nlinear, key=lambda d: d[i])['lr'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_nlinear['name'])\n",
    "    model = NLinearModel(\n",
    "        input_chunk_length=best_model_nlinear['input_chunk_length'],\n",
    "        output_chunk_length=best_model_nlinear['output_chunk_length'],\n",
    "        shared_weights=best_model_nlinear['shared_weights'],\n",
    "        const_init=best_model_nlinear['const_init'],\n",
    "        normalize=best_model_nlinear['normalize'],\n",
    "        use_static_covariates=best_model_nlinear['use_static_covariates'],\n",
    "        batch_size=best_model_nlinear['batch_size'],\n",
    "        n_epochs=400,\n",
    "        optimizer_kwargs={'lr': best_model_nlinear['lr']},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit([train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())])\n",
    "    pred_series, mape_nlinear, sle_nlinear = eval_model(\n",
    "        model,\n",
    "        len(val_scaled),\n",
    "        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_scaled,\n",
    "        target_series = train_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_nlinear = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "    u2_nlinear = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_nlinear)\n",
    "    print('U2: ', u2_nlinear)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_nlinear = []\n",
    "\n",
    "for input_chunk_length in range(24, 26, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "        for batch_size in [2**i for i in range(4,7)]:\n",
    "           for shared_weights in [True, False]:\n",
    "               for const_init in [True, False]:\n",
    "                   for normalize in [True, False]:\n",
    "                       for use_static_covariates in [True, False]:\n",
    "                           for lr in [10**(-i) for i in [4]]:\n",
    "                                try:\n",
    "                                    model = NLinearModel(\n",
    "                                        input_chunk_length=input_chunk_length,\n",
    "                                        output_chunk_length=output_chunk_length,\n",
    "                                        shared_weights=shared_weights,\n",
    "                                        const_init=const_init,\n",
    "                                        normalize=normalize,\n",
    "                                        use_static_covariates=use_static_covariates,\n",
    "                                        batch_size=batch_size,\n",
    "                                        n_epochs=400,\n",
    "                                        optimizer_kwargs={'lr': lr},\n",
    "                                        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "                                        random_state = 0\n",
    "                                    )\n",
    "                                    model.fit([train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())])\n",
    "                                    pred_series, mape_nlinear, sle_nlinear = eval_model(\n",
    "                                        model,\n",
    "                                        len(val_scaled),\n",
    "                                        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                        val_scaled,\n",
    "                                        target_series = train_scaled,\n",
    "                                        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                        plot = False,\n",
    "                                    )\n",
    "                                    uTheil = UTheil()\n",
    "                                    u1_nlinear = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "                                    u2_nlinear = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "                                    print({\n",
    "                                        'MAPE': mape_nlinear,\n",
    "                                        'SLE': sle_nlinear,\n",
    "                                        'U1': u1_nlinear,\n",
    "                                        'U2': u1_nlinear,\n",
    "                                        'lr': lr,\n",
    "                                        'input_chunk_length': input_chunk_length,\n",
    "                                        'output_chunk_length': output_chunk_length,\n",
    "                                        'shared_weights': shared_weights,\n",
    "                                        'const_init': const_init,\n",
    "                                        'normalize': normalize,\n",
    "                                        'use_static_covariates': use_static_covariates,\n",
    "                                        'batch_size': batch_size,\n",
    "                                    })\n",
    "                                    models_nlinear.append({\n",
    "                                        'MAPE': mape_nlinear,\n",
    "                                        'SLE': sle_nlinear,\n",
    "                                        'U1': u1_nlinear,\n",
    "                                        'U2': u1_nlinear,\n",
    "                                        'lr': lr,\n",
    "                                        'input_chunk_length': input_chunk_length,\n",
    "                                        'output_chunk_length': output_chunk_length,\n",
    "                                        'shared_weights': shared_weights,\n",
    "                                        'const_init': const_init,\n",
    "                                        'normalize': normalize,\n",
    "                                        'use_static_covariates': use_static_covariates,\n",
    "                                        'batch_size': batch_size,\n",
    "                                    })\n",
    "                                except:\n",
    "                                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_nlinear in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_nlinear, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_nlinear, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'shared_weights': min(models_nlinear, key=lambda d: d[i])['shared_weights'],\n",
    "                                'const_init': min(models_nlinear, key=lambda d: d[i])['const_init'],\n",
    "                                'normalize': min(models_nlinear, key=lambda d: d[i])['normalize'],\n",
    "                                'use_static_covariates': min(models_nlinear, key=lambda d: d[i])['use_static_covariates'],\n",
    "                                'batch_size': min(models_nlinear, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_nlinear, key=lambda d: d[i])['lr'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_nlinear['name'])\n",
    "    model = NLinearModel(\n",
    "        input_chunk_length=best_model_nlinear['input_chunk_length'],\n",
    "        output_chunk_length=best_model_nlinear['output_chunk_length'],\n",
    "        shared_weights=best_model_nlinear['shared_weights'],\n",
    "        const_init=best_model_nlinear['const_init'],\n",
    "        normalize=best_model_nlinear['normalize'],\n",
    "        use_static_covariates=best_model_nlinear['use_static_covariates'],\n",
    "        batch_size=best_model_nlinear['batch_size'],\n",
    "        n_epochs=400,\n",
    "        optimizer_kwargs={'lr': best_model_nlinear['lr']},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit([train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())])\n",
    "    pred_series, mape_nlinear, sle_nlinear = eval_model(\n",
    "        model,\n",
    "        len(val_scaled),\n",
    "        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_scaled,\n",
    "        target_series = train_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_nlinear = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "    u2_nlinear = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_nlinear)\n",
    "    print('U2: ', u2_nlinear)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_nlinear = []\n",
    "\n",
    "for input_chunk_length in range(26, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "        for batch_size in [2**i for i in range(4,7)]:\n",
    "           for shared_weights in [True, False]:\n",
    "               for const_init in [True, False]:\n",
    "                   for normalize in [True, False]:\n",
    "                       for use_static_covariates in [True, False]:\n",
    "                           for lr in [10**(-i) for i in [4]]:\n",
    "                                try:\n",
    "                                    model = NLinearModel(\n",
    "                                        input_chunk_length=input_chunk_length,\n",
    "                                        output_chunk_length=output_chunk_length,\n",
    "                                        shared_weights=shared_weights,\n",
    "                                        const_init=const_init,\n",
    "                                        normalize=normalize,\n",
    "                                        use_static_covariates=use_static_covariates,\n",
    "                                        batch_size=batch_size,\n",
    "                                        n_epochs=400,\n",
    "                                        optimizer_kwargs={'lr': lr},\n",
    "                                        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "                                        random_state = 0\n",
    "                                    )\n",
    "                                    model.fit([train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())])\n",
    "                                    pred_series, mape_nlinear, sle_nlinear = eval_model(\n",
    "                                        model,\n",
    "                                        len(val_scaled),\n",
    "                                        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                        val_scaled,\n",
    "                                        target_series = train_scaled,\n",
    "                                        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                        plot = False,\n",
    "                                    )\n",
    "                                    uTheil = UTheil()\n",
    "                                    u1_nlinear = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "                                    u2_nlinear = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "                                    print({\n",
    "                                        'MAPE': mape_nlinear,\n",
    "                                        'SLE': sle_nlinear,\n",
    "                                        'U1': u1_nlinear,\n",
    "                                        'U2': u1_nlinear,\n",
    "                                        'lr': lr,\n",
    "                                        'input_chunk_length': input_chunk_length,\n",
    "                                        'output_chunk_length': output_chunk_length,\n",
    "                                        'shared_weights': shared_weights,\n",
    "                                        'const_init': const_init,\n",
    "                                        'normalize': normalize,\n",
    "                                        'use_static_covariates': use_static_covariates,\n",
    "                                        'batch_size': batch_size,\n",
    "                                    })\n",
    "                                    models_nlinear.append({\n",
    "                                        'MAPE': mape_nlinear,\n",
    "                                        'SLE': sle_nlinear,\n",
    "                                        'U1': u1_nlinear,\n",
    "                                        'U2': u1_nlinear,\n",
    "                                        'lr': lr,\n",
    "                                        'input_chunk_length': input_chunk_length,\n",
    "                                        'output_chunk_length': output_chunk_length,\n",
    "                                        'shared_weights': shared_weights,\n",
    "                                        'const_init': const_init,\n",
    "                                        'normalize': normalize,\n",
    "                                        'use_static_covariates': use_static_covariates,\n",
    "                                        'batch_size': batch_size,\n",
    "                                    })\n",
    "                                except:\n",
    "                                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_nlinear in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_nlinear, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_nlinear, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'shared_weights': min(models_nlinear, key=lambda d: d[i])['shared_weights'],\n",
    "                                'const_init': min(models_nlinear, key=lambda d: d[i])['const_init'],\n",
    "                                'normalize': min(models_nlinear, key=lambda d: d[i])['normalize'],\n",
    "                                'use_static_covariates': min(models_nlinear, key=lambda d: d[i])['use_static_covariates'],\n",
    "                                'batch_size': min(models_nlinear, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_nlinear, key=lambda d: d[i])['lr'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_nlinear['name'])\n",
    "    model = NLinearModel(\n",
    "        input_chunk_length=best_model_nlinear['input_chunk_length'],\n",
    "        output_chunk_length=best_model_nlinear['output_chunk_length'],\n",
    "        shared_weights=best_model_nlinear['shared_weights'],\n",
    "        const_init=best_model_nlinear['const_init'],\n",
    "        normalize=best_model_nlinear['normalize'],\n",
    "        use_static_covariates=best_model_nlinear['use_static_covariates'],\n",
    "        batch_size=best_model_nlinear['batch_size'],\n",
    "        n_epochs=400,\n",
    "        optimizer_kwargs={'lr': best_model_nlinear['lr']},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit([train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())])\n",
    "    pred_series, mape_nlinear, sle_nlinear = eval_model(\n",
    "        model,\n",
    "        len(val_scaled),\n",
    "        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_scaled,\n",
    "        target_series = train_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_nlinear = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "    u2_nlinear = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_nlinear)\n",
    "    print('U2: ', u2_nlinear)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    shared_weights = trial.suggest_categorical(\"shared_weights\", [True, False])\n",
    "    const_init = trial.suggest_categorical(\"const_init\", [True, False])\n",
    "    normalize = trial.suggest_categorical(\"normalize\", [True, False])\n",
    "    use_static_covariates = trial.suggest_categorical(\"use_static_covariates\", [True, False])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NLinearModel(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        shared_weights=shared_weights,\n",
    "        const_init=const_init,\n",
    "        normalize=normalize,\n",
    "        use_static_covariates=use_static_covariates,\n",
    "        batch_size=2**batch_size,\n",
    "        n_epochs=n_epochs,\n",
    "        optimizer_kwargs={'lr': lr},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NLinearModel(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    shared_weights=study.best_trial.params['shared_weights'],\n",
    "    const_init=study.best_trial.params['const_init'],\n",
    "    normalize=study.best_trial.params['normalize'],\n",
    "    use_static_covariates=study.best_trial.params['use_static_covariates'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    optimizer_kwargs={'lr': study.best_trial.params['lr']},\n",
    "    pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    shared_weights = trial.suggest_categorical(\"shared_weights\", [True, False])\n",
    "    const_init = trial.suggest_categorical(\"const_init\", [True, False])\n",
    "    normalize = trial.suggest_categorical(\"normalize\", [True, False])\n",
    "    use_static_covariates = trial.suggest_categorical(\"use_static_covariates\", [True, False])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NLinearModel(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        shared_weights=shared_weights,\n",
    "        const_init=const_init,\n",
    "        normalize=normalize,\n",
    "        use_static_covariates=use_static_covariates,\n",
    "        batch_size=2**batch_size,\n",
    "        n_epochs=n_epochs,\n",
    "        optimizer_kwargs={'lr': lr},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NLinearModel(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    shared_weights=study.best_trial.params['shared_weights'],\n",
    "    const_init=study.best_trial.params['const_init'],\n",
    "    normalize=study.best_trial.params['normalize'],\n",
    "    use_static_covariates=study.best_trial.params['use_static_covariates'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    optimizer_kwargs={'lr': study.best_trial.params['lr']},\n",
    "    pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando MAPE e U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    shared_weights = trial.suggest_categorical(\"shared_weights\", [True, False])\n",
    "    const_init = trial.suggest_categorical(\"const_init\", [True, False])\n",
    "    normalize = trial.suggest_categorical(\"normalize\", [True, False])\n",
    "    use_static_covariates = trial.suggest_categorical(\"use_static_covariates\", [True, False])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NLinearModel(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        shared_weights=shared_weights,\n",
    "        const_init=const_init,\n",
    "        normalize=normalize,\n",
    "        use_static_covariates=use_static_covariates,\n",
    "        batch_size=2**batch_size,\n",
    "        n_epochs=n_epochs,\n",
    "        optimizer_kwargs={'lr': lr},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_scaled, preds)\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NLinearModel(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    shared_weights=study.best_trial.params['shared_weights'],\n",
    "    const_init=study.best_trial.params['const_init'],\n",
    "    normalize=study.best_trial.params['normalize'],\n",
    "    use_static_covariates=study.best_trial.params['use_static_covariates'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    optimizer_kwargs={'lr': study.best_trial.params['lr']},\n",
    "    pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Brasil (detrend) + Sudeste (detrend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Janela deslizante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_nlinear = []\n",
    "\n",
    "for input_chunk_length in range(20, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "        for batch_size in [2**i for i in range(4,7)]:\n",
    "           for shared_weights in [True, False]:\n",
    "               for const_init in [True, False]:\n",
    "                   for normalize in [True, False]:\n",
    "                       for use_static_covariates in [True, False]:\n",
    "                           for lr in [10**(-i) for i in range(2, 5):\n",
    "                                try:\n",
    "                                    model = NLinearModel(\n",
    "                                        input_chunk_length=input_chunk_length,\n",
    "                                        output_chunk_length=output_chunk_length,\n",
    "                                        shared_weights=shared_weights,\n",
    "                                        const_init=const_init,\n",
    "                                        normalize=normalize,\n",
    "                                        use_static_covariates=use_static_covariates,\n",
    "                                        batch_size=batch_size,\n",
    "                                        n_epochs=400,\n",
    "                                        optimizer_kwargs={'lr': lr},\n",
    "                                        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "                                        random_state = 0\n",
    "                                    )\n",
    "                                    model.fit([train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())])\n",
    "                                    pred_series, mape_nlinear, sle_nlinear = eval_model(\n",
    "                                        model,\n",
    "                                        len(val_detrend_scaled),\n",
    "                                        series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                        val_detrend_scaled,\n",
    "                                        target_series = train_detrend_scaled,\n",
    "                                        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                        plot = False,\n",
    "                                    )\n",
    "                                    uTheil = UTheil()\n",
    "                                    u1_nlinear = uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)])\n",
    "                                    u2_nlinear = uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)])\n",
    "                                    print({\n",
    "                                        'MAPE': mape_nlinear,\n",
    "                                        'SLE': sle_nlinear,\n",
    "                                        'U1': u1_nlinear,\n",
    "                                        'U2': u1_nlinear,\n",
    "                                        'lr': lr,\n",
    "                                        'input_chunk_length': input_chunk_length,\n",
    "                                        'output_chunk_length': output_chunk_length,\n",
    "                                        'shared_weights': shared_weights,\n",
    "                                        'const_init': const_init,\n",
    "                                        'normalize': normalize,\n",
    "                                        'use_static_covariates': use_static_covariates,\n",
    "                                        'batch_size': batch_size,\n",
    "                                    })\n",
    "                                    models_nlinear.append({\n",
    "                                        'MAPE': mape_nlinear,\n",
    "                                        'SLE': sle_nlinear,\n",
    "                                        'U1': u1_nlinear,\n",
    "                                        'U2': u1_nlinear,\n",
    "                                        'lr': lr,\n",
    "                                        'input_chunk_length': input_chunk_length,\n",
    "                                        'output_chunk_length': output_chunk_length,\n",
    "                                        'shared_weights': shared_weights,\n",
    "                                        'const_init': const_init,\n",
    "                                        'normalize': normalize,\n",
    "                                        'use_static_covariates': use_static_covariates,\n",
    "                                        'batch_size': batch_size,\n",
    "                                    })\n",
    "                                except:\n",
    "                                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_nlinear in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_nlinear, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_nlinear, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'shared_weights': min(models_nlinear, key=lambda d: d[i])['shared_weights'],\n",
    "                                'const_init': min(models_nlinear, key=lambda d: d[i])['const_init'],\n",
    "                                'normalize': min(models_nlinear, key=lambda d: d[i])['normalize'],\n",
    "                                'use_static_covariates': min(models_nlinear, key=lambda d: d[i])['use_static_covariates'],\n",
    "                                'batch_size': min(models_nlinear, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_nlinear, key=lambda d: d[i])['lr'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_nlinear['name'])\n",
    "    model = NLinearModel(\n",
    "        input_chunk_length=best_model_nlinear['input_chunk_length'],\n",
    "        output_chunk_length=best_model_nlinear['output_chunk_length'],\n",
    "        shared_weights=best_model_nlinear['shared_weights'],\n",
    "        const_init=best_model_nlinear['const_init'],\n",
    "        normalize=best_model_nlinear['normalize'],\n",
    "        use_static_covariates=best_model_nlinear['use_static_covariates'],\n",
    "        batch_size=best_model_nlinear['batch_size'],\n",
    "        n_epochs=400,\n",
    "        optimizer_kwargs={'lr': best_model_nlinear['lr']},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit([train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())])\n",
    "    pred_series, mape_nlinear, sle_nlinear = eval_model(\n",
    "        model,\n",
    "        len(val_detrend_scaled),\n",
    "        series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_detrend_scaled,\n",
    "        target_series = train_detrend_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_nlinear = uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)])\n",
    "    u2_nlinear = uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_nlinear)\n",
    "    print('U2: ', u2_nlinear)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    shared_weights = trial.suggest_categorical(\"shared_weights\", [True, False])\n",
    "    const_init = trial.suggest_categorical(\"const_init\", [True, False])\n",
    "    normalize = trial.suggest_categorical(\"normalize\", [True, False])\n",
    "    use_static_covariates = trial.suggest_categorical(\"use_static_covariates\", [True, False])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NLinearModel(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        shared_weights=shared_weights,\n",
    "        const_init=const_init,\n",
    "        normalize=normalize,\n",
    "        use_static_covariates=use_static_covariates,\n",
    "        batch_size=2**batch_size,\n",
    "        n_epochs=n_epochs,\n",
    "        optimizer_kwargs={'lr': lr},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    mapes = mape(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NLinearModel(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    shared_weights=study.best_trial.params['shared_weights'],\n",
    "    const_init=study.best_trial.params['const_init'],\n",
    "    normalize=study.best_trial.params['normalize'],\n",
    "    use_static_covariates=study.best_trial.params['use_static_covariates'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    optimizer_kwargs={'lr': study.best_trial.params['lr']},\n",
    "    pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    shared_weights = trial.suggest_categorical(\"shared_weights\", [True, False])\n",
    "    const_init = trial.suggest_categorical(\"const_init\", [True, False])\n",
    "    normalize = trial.suggest_categorical(\"normalize\", [True, False])\n",
    "    use_static_covariates = trial.suggest_categorical(\"use_static_covariates\", [True, False])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NLinearModel(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        shared_weights=shared_weights,\n",
    "        const_init=const_init,\n",
    "        normalize=normalize,\n",
    "        use_static_covariates=use_static_covariates,\n",
    "        batch_size=2**batch_size,\n",
    "        n_epochs=n_epochs,\n",
    "        optimizer_kwargs={'lr': lr},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NLinearModel(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    shared_weights=study.best_trial.params['shared_weights'],\n",
    "    const_init=study.best_trial.params['const_init'],\n",
    "    normalize=study.best_trial.params['normalize'],\n",
    "    use_static_covariates=study.best_trial.params['use_static_covariates'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    optimizer_kwargs={'lr': study.best_trial.params['lr']},\n",
    "    pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando MAPE e U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    shared_weights = trial.suggest_categorical(\"shared_weights\", [True, False])\n",
    "    const_init = trial.suggest_categorical(\"const_init\", [True, False])\n",
    "    normalize = trial.suggest_categorical(\"normalize\", [True, False])\n",
    "    use_static_covariates = trial.suggest_categorical(\"use_static_covariates\", [True, False])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NLinearModel(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        shared_weights=shared_weights,\n",
    "        const_init=const_init,\n",
    "        normalize=normalize,\n",
    "        use_static_covariates=use_static_covariates,\n",
    "        batch_size=2**batch_size,\n",
    "        n_epochs=n_epochs,\n",
    "        optimizer_kwargs={'lr': lr},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_detrend_scaled, preds)\n",
    "    mapes = mape(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NLinearModel(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    shared_weights=study.best_trial.params['shared_weights'],\n",
    "    const_init=study.best_trial.params['const_init'],\n",
    "    normalize=study.best_trial.params['normalize'],\n",
    "    use_static_covariates=study.best_trial.params['use_static_covariates'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    optimizer_kwargs={'lr': study.best_trial.params['lr']},\n",
    "    pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Brasil + Óleo de Soja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Janela deslizante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_nlinear = []\n",
    "\n",
    "for input_chunk_length in range(20, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "        for batch_size in [2**i for i in range(4,7)]:\n",
    "           for shared_weights in [True, False]:\n",
    "               for const_init in [True, False]:\n",
    "                   for normalize in [True, False]:\n",
    "                       for use_static_covariates in [True, False]:\n",
    "                           for lr in [10**(-i) for i in [2,3,4]]:\n",
    "                                try:\n",
    "                                    model = NLinearModel(\n",
    "                                        input_chunk_length=input_chunk_length,\n",
    "                                        output_chunk_length=output_chunk_length,\n",
    "                                        shared_weights=shared_weights,\n",
    "                                        const_init=const_init,\n",
    "                                        normalize=normalize,\n",
    "                                        use_static_covariates=use_static_covariates,\n",
    "                                        batch_size=batch_size,\n",
    "                                        n_epochs=400,\n",
    "                                        optimizer_kwargs={'lr': lr},\n",
    "                                        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "                                        random_state = 0\n",
    "                                    )\n",
    "                                    model.fit([train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())])\n",
    "                                    pred_series, mape_nlinear, sle_nlinear = eval_model(\n",
    "                                        model,\n",
    "                                        len(val_scaled),\n",
    "                                        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                        val_scaled,\n",
    "                                        target_series = train_scaled,\n",
    "                                        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                        plot = False,\n",
    "                                    )\n",
    "                                    uTheil = UTheil()\n",
    "                                    u1_nlinear = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "                                    u2_nlinear = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "                                    print({\n",
    "                                        'MAPE': mape_nlinear,\n",
    "                                        'SLE': sle_nlinear,\n",
    "                                        'U1': u1_nlinear,\n",
    "                                        'U2': u1_nlinear,\n",
    "                                        'lr': lr,\n",
    "                                        'input_chunk_length': input_chunk_length,\n",
    "                                        'output_chunk_length': output_chunk_length,\n",
    "                                        'shared_weights': shared_weights,\n",
    "                                        'const_init': const_init,\n",
    "                                        'normalize': normalize,\n",
    "                                        'use_static_covariates': use_static_covariates,\n",
    "                                        'batch_size': batch_size,\n",
    "                                    })\n",
    "                                    models_nlinear.append({\n",
    "                                        'MAPE': mape_nlinear,\n",
    "                                        'SLE': sle_nlinear,\n",
    "                                        'U1': u1_nlinear,\n",
    "                                        'U2': u1_nlinear,\n",
    "                                        'lr': lr,\n",
    "                                        'input_chunk_length': input_chunk_length,\n",
    "                                        'output_chunk_length': output_chunk_length,\n",
    "                                        'shared_weights': shared_weights,\n",
    "                                        'const_init': const_init,\n",
    "                                        'normalize': normalize,\n",
    "                                        'use_static_covariates': use_static_covariates,\n",
    "                                        'batch_size': batch_size,\n",
    "                                    })\n",
    "                                except:\n",
    "                                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_nlinear in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_nlinear, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_nlinear, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'shared_weights': min(models_nlinear, key=lambda d: d[i])['shared_weights'],\n",
    "                                'const_init': min(models_nlinear, key=lambda d: d[i])['const_init'],\n",
    "                                'normalize': min(models_nlinear, key=lambda d: d[i])['normalize'],\n",
    "                                'use_static_covariates': min(models_nlinear, key=lambda d: d[i])['use_static_covariates'],\n",
    "                                'batch_size': min(models_nlinear, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_nlinear, key=lambda d: d[i])['lr'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_nlinear['name'])\n",
    "    model = NLinearModel(\n",
    "        input_chunk_length=best_model_nlinear['input_chunk_length'],\n",
    "        output_chunk_length=best_model_nlinear['output_chunk_length'],\n",
    "        shared_weights=best_model_nlinear['shared_weights'],\n",
    "        const_init=best_model_nlinear['const_init'],\n",
    "        normalize=best_model_nlinear['normalize'],\n",
    "        use_static_covariates=best_model_nlinear['use_static_covariates'],\n",
    "        batch_size=best_model_nlinear['batch_size'],\n",
    "        n_epochs=400,\n",
    "        optimizer_kwargs={'lr': best_model_nlinear['lr']},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit([train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())])\n",
    "    pred_series, mape_nlinear, sle_nlinear = eval_model(\n",
    "        model,\n",
    "        len(val_scaled),\n",
    "        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_scaled,\n",
    "        target_series = train_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_nlinear = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "    u2_nlinear = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_nlinear)\n",
    "    print('U2: ', u2_nlinear)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    shared_weights = trial.suggest_categorical(\"shared_weights\", [True, False])\n",
    "    const_init = trial.suggest_categorical(\"const_init\", [True, False])\n",
    "    normalize = trial.suggest_categorical(\"normalize\", [True, False])\n",
    "    use_static_covariates = trial.suggest_categorical(\"use_static_covariates\", [True, False])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NLinearModel(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        shared_weights=shared_weights,\n",
    "        const_init=const_init,\n",
    "        normalize=normalize,\n",
    "        use_static_covariates=use_static_covariates,\n",
    "        batch_size=2**batch_size,\n",
    "        n_epochs=n_epochs,\n",
    "        optimizer_kwargs={'lr': lr},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NLinearModel(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    shared_weights=study.best_trial.params['shared_weights'],\n",
    "    const_init=study.best_trial.params['const_init'],\n",
    "    normalize=study.best_trial.params['normalize'],\n",
    "    use_static_covariates=study.best_trial.params['use_static_covariates'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    optimizer_kwargs={'lr': study.best_trial.params['lr']},\n",
    "    pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    shared_weights = trial.suggest_categorical(\"shared_weights\", [True, False])\n",
    "    const_init = trial.suggest_categorical(\"const_init\", [True, False])\n",
    "    normalize = trial.suggest_categorical(\"normalize\", [True, False])\n",
    "    use_static_covariates = trial.suggest_categorical(\"use_static_covariates\", [True, False])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NLinearModel(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        shared_weights=shared_weights,\n",
    "        const_init=const_init,\n",
    "        normalize=normalize,\n",
    "        use_static_covariates=use_static_covariates,\n",
    "        batch_size=2**batch_size,\n",
    "        n_epochs=n_epochs,\n",
    "        optimizer_kwargs={'lr': lr},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NLinearModel(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    shared_weights=study.best_trial.params['shared_weights'],\n",
    "    const_init=study.best_trial.params['const_init'],\n",
    "    normalize=study.best_trial.params['normalize'],\n",
    "    use_static_covariates=study.best_trial.params['use_static_covariates'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    optimizer_kwargs={'lr': study.best_trial.params['lr']},\n",
    "    pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando MAPE e U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    shared_weights = trial.suggest_categorical(\"shared_weights\", [True, False])\n",
    "    const_init = trial.suggest_categorical(\"const_init\", [True, False])\n",
    "    normalize = trial.suggest_categorical(\"normalize\", [True, False])\n",
    "    use_static_covariates = trial.suggest_categorical(\"use_static_covariates\", [True, False])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NLinearModel(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        shared_weights=shared_weights,\n",
    "        const_init=const_init,\n",
    "        normalize=normalize,\n",
    "        use_static_covariates=use_static_covariates,\n",
    "        batch_size=2**batch_size,\n",
    "        n_epochs=n_epochs,\n",
    "        optimizer_kwargs={'lr': lr},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_scaled, preds)\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NLinearModel(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    shared_weights=study.best_trial.params['shared_weights'],\n",
    "    const_init=study.best_trial.params['const_init'],\n",
    "    normalize=study.best_trial.params['normalize'],\n",
    "    use_static_covariates=study.best_trial.params['use_static_covariates'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    optimizer_kwargs={'lr': study.best_trial.params['lr']},\n",
    "    pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## TFT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Brasil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Janela deslizante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Não terminou a GRID search, deveria demorar quase 15 dias\n",
    "\n",
    "models_tft = []\n",
    "\n",
    "for input_chunk_length in range(20, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "        for lstm_layers in range(1, 4):\n",
    "            for num_attention_heads in range(1, 5):\n",
    "                for full_attention in [True, False]:\n",
    "                   for hidden_size in [2**i for i in range(3, 7)]:\n",
    "                       for batch_size in [2**i for i in range(3, 7)]:\n",
    "                           for dropout in [i/100 for i in range(0, 20, 5)]:\n",
    "                               for lr in [10**(-i) for i in range(2, 5)]:\n",
    "                                    try:\n",
    "                                        model = TFTModel(\n",
    "                                            input_chunk_length=input_chunk_length,\n",
    "                                            output_chunk_length=output_chunk_length,\n",
    "                                            hidden_size=hidden_size,\n",
    "                                            batch_size=batch_size,\n",
    "                                            lstm_layers=lstm_layers,\n",
    "                                            num_attention_heads=num_attention_heads,\n",
    "                                            full_attention=full_attention,\n",
    "                                            dropout=dropout,\n",
    "                                            add_relative_index=True,\n",
    "                                            loss_fn=torch.nn.MSELoss(),\n",
    "                                            n_epochs=400,\n",
    "                                            optimizer_kwargs={'lr':lr},\n",
    "                                            pl_trainer_kwargs = {\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "                                            random_state = 0,\n",
    "                                        )\n",
    "                                        model.fit(train_scaled)\n",
    "                                        pred_series, mape_tft, sle_tft = eval_model(\n",
    "                                            model,\n",
    "                                            len(val_scaled),\n",
    "                                            series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                            val_scaled,\n",
    "                                            target_series = train_scaled,\n",
    "                                            returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                            plot = False,\n",
    "                                        )\n",
    "                                        uTheil = UTheil()\n",
    "                                        u1_tft = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "                                        u2_tft = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "                                        print({\n",
    "                                            'MAPE': mape_tft,\n",
    "                                            'SLE': sle_tft,\n",
    "                                            'U1': u1_tft,\n",
    "                                            'U2': u1_tft,\n",
    "                                            'lr': lr,\n",
    "                                            'input_chunk_length': input_chunk_length,\n",
    "                                            'output_chunk_length': output_chunk_length,\n",
    "                                            'hidden_size': hidden_size,\n",
    "                                            'batch_size': batch_size,\n",
    "                                            'lstm_layers': lstm_layers,\n",
    "                                            'num_attention_heads': num_attention_heads,\n",
    "                                            'full_attention': full_attention,\n",
    "                                            'dropout': dropout,\n",
    "                                        })\n",
    "                                        models_tft.append({\n",
    "                                            'MAPE': mape_tft,\n",
    "                                            'SLE': sle_tft,\n",
    "                                            'U1': u1_tft,\n",
    "                                            'U2': u1_tft,\n",
    "                                            'lr': lr,\n",
    "                                            'input_chunk_length': input_chunk_length,\n",
    "                                            'output_chunk_length': output_chunk_length,\n",
    "                                            'hidden_size': hidden_size,\n",
    "                                            'batch_size': batch_size,\n",
    "                                            'lstm_layers': lstm_layers,\n",
    "                                            'num_attention_heads': num_attention_heads,\n",
    "                                            'full_attention': full_attention,\n",
    "                                            'dropout': dropout,\n",
    "                                        })\n",
    "                                    except:\n",
    "                                        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_tft in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_tft, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_tft, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_tft, key=lambda d: d[i])['hidden_size'],\n",
    "                                'batch_size': min(models_tft, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_tft, key=lambda d: d[i])['lr'],\n",
    "                                'lstm_layers': min(models_tft, key=lambda d: d[i])['lstm_layers'],\n",
    "                                'num_attention_heads': min(models_tft, key=lambda d: d[i])['num_attention_heads'],\n",
    "                                'full_attention': min(models_tft, key=lambda d: d[i])['full_attention'],\n",
    "                                'dropout': min(models_tft, key=lambda d: d[i])['dropout'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_tft['name'])\n",
    "    model = TFTModel(\n",
    "        input_chunk_length=best_model_tft['input_chunk_length'],\n",
    "        output_chunk_length=best_model_tft['output_chunk_length'],\n",
    "        hidden_size=best_model_tft['hidden_size'],\n",
    "        batch_size=best_model_tft['batch_size'],\n",
    "        lstm_layers=best_model_tft['lstm_layers'],\n",
    "        num_attention_heads=best_model_tft['num_attention_heads'],\n",
    "        full_attention=best_model_tft['full_attention'],\n",
    "        dropout=best_model_tft['dropout'],\n",
    "        add_relative_index=True,\n",
    "        loss_fn=torch.nn.MSELoss(),\n",
    "        n_epochs=400,\n",
    "        optimizer_kwargs={'lr':best_model_tft['lr']},\n",
    "        pl_trainer_kwargs = {\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0,\n",
    "    )\n",
    "\n",
    "    model.fit(train_scaled)\n",
    "    pred_series, mape_tft, sle_tft = eval_model(\n",
    "        model,\n",
    "        len(val_scaled),\n",
    "        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_scaled,\n",
    "        target_series = train_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_tft = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "    u2_tft = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_tft)\n",
    "    print('U2: ', u2_tft)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    num_attention_heads = trial.suggest_int(\"num_attention_heads\", 1, 4)\n",
    "    lstm_layers = trial.suggest_int(\"lstm_layers\", 1, 4)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "    dropout = trial.suggest_uniform(\"dropout\", 0, 0.2)\n",
    "    full_attention = trial.suggest_categorical(\"full_attention\", [True, False])\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = TFTModel(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        lstm_layers=lstm_layers,\n",
    "        num_attention_heads=num_attention_heads,\n",
    "        full_attention=full_attention,\n",
    "        dropout=dropout,\n",
    "        add_relative_index=True,\n",
    "        loss_fn=torch.nn.MSELoss(),\n",
    "        n_epochs=n_epochs,\n",
    "        optimizer_kwargs={'lr':lr},\n",
    "        pl_trainer_kwargs = {\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0,\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TFTModel(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    lstm_layers=study.best_trial.params['lstm_layers'],\n",
    "    num_attention_heads=study.best_trial.params['num_attention_heads'],\n",
    "    full_attention=study.best_trial.params['full_attention'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    add_relative_index=True,\n",
    "    loss_fn=torch.nn.MSELoss(),\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    optimizer_kwargs={'lr':study.best_trial.params['lr']},\n",
    "    pl_trainer_kwargs = {\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "    random_state = 0,\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    num_attention_heads = trial.suggest_int(\"num_attention_heads\", 1, 4)\n",
    "    lstm_layers = trial.suggest_int(\"lstm_layers\", 1, 4)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "    dropout = trial.suggest_uniform(\"dropout\", 0, 0.2)\n",
    "    full_attention = trial.suggest_categorical(\"full_attention\", [True, False])\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = TFTModel(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        lstm_layers=lstm_layers,\n",
    "        num_attention_heads=num_attention_heads,\n",
    "        full_attention=full_attention,\n",
    "        dropout=dropout,\n",
    "        add_relative_index=True,\n",
    "        loss_fn=torch.nn.MSELoss(),\n",
    "        n_epochs=n_epochs,\n",
    "        optimizer_kwargs={'lr':lr},\n",
    "        pl_trainer_kwargs = {\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0,\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TFTModel(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    lstm_layers=study.best_trial.params['lstm_layers'],\n",
    "    num_attention_heads=study.best_trial.params['num_attention_heads'],\n",
    "    full_attention=study.best_trial.params['full_attention'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    add_relative_index=True,\n",
    "    loss_fn=torch.nn.MSELoss(),\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    optimizer_kwargs={'lr':study.best_trial.params['lr']},\n",
    "    pl_trainer_kwargs = {\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "    random_state = 0,\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando MAPE e U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    num_attention_heads = trial.suggest_int(\"num_attention_heads\", 1, 4)\n",
    "    lstm_layers = trial.suggest_int(\"lstm_layers\", 1, 4)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "    dropout = trial.suggest_uniform(\"dropout\", 0, 0.2)\n",
    "    full_attention = trial.suggest_categorical(\"full_attention\", [True, False])\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = TFTModel(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        lstm_layers=lstm_layers,\n",
    "        num_attention_heads=num_attention_heads,\n",
    "        full_attention=full_attention,\n",
    "        dropout=dropout,\n",
    "        add_relative_index=True,\n",
    "        loss_fn=torch.nn.MSELoss(),\n",
    "        n_epochs=n_epochs,\n",
    "        optimizer_kwargs={'lr':lr},\n",
    "        pl_trainer_kwargs = {\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0,\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_scaled, preds)\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TFTModel(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    lstm_layers=study.best_trial.params['lstm_layers'],\n",
    "    num_attention_heads=study.best_trial.params['num_attention_heads'],\n",
    "    full_attention=study.best_trial.params['full_attention'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    add_relative_index=True,\n",
    "    loss_fn=torch.nn.MSELoss(),\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    optimizer_kwargs={'lr':study.best_trial.params['lr']},\n",
    "    pl_trainer_kwargs = {\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "    random_state = 0,\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Brasil (detrend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Janela deslizante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Não terminou a GRID search, deveria demorar quase 15 dias\n",
    "\n",
    "models_tft = []\n",
    "\n",
    "for input_chunk_length in range(20, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "        for lstm_layers in range(1, 4):\n",
    "            for num_attention_heads in range(1, 5):\n",
    "                for full_attention in [True, False]:\n",
    "                   for hidden_size in [2**i for i in range(3, 7)]:\n",
    "                       for batch_size in [2**i for i in range(3, 7)]:\n",
    "                           for dropout in [i/100 for i in range(0, 20, 5)]:\n",
    "                               for lr in [10**(-i) for i in range(2, 5)]:\n",
    "                                    try:\n",
    "                                        model = TFTModel(\n",
    "                                            input_chunk_length=input_chunk_length,\n",
    "                                            output_chunk_length=output_chunk_length,\n",
    "                                            hidden_size=hidden_size,\n",
    "                                            batch_size=batch_size,\n",
    "                                            lstm_layers=lstm_layers,\n",
    "                                            num_attention_heads=num_attention_heads,\n",
    "                                            full_attention=full_attention,\n",
    "                                            dropout=dropout,\n",
    "                                            add_relative_index=True,\n",
    "                                            loss_fn=torch.nn.MSELoss(),\n",
    "                                            n_epochs=400,\n",
    "                                            optimizer_kwargs={'lr':lr},\n",
    "                                            pl_trainer_kwargs = {\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "                                            random_state = 0,\n",
    "                                        )\n",
    "                                        model.fit(train_detrend_scaled)\n",
    "                                        pred_series, mape_tft, sle_tft = eval_model(\n",
    "                                            model,\n",
    "                                            len(val_detrend_scaled),\n",
    "                                            series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                            val_detrend_scaled,\n",
    "                                            target_series = train_detrend_scaled,\n",
    "                                            returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                            plot = False,\n",
    "                                        )\n",
    "                                        uTheil = UTheil()\n",
    "                                        u1_tft = uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)])\n",
    "                                        u2_tft = uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)])\n",
    "                                        print({\n",
    "                                            'MAPE': mape_tft,\n",
    "                                            'SLE': sle_tft,\n",
    "                                            'U1': u1_tft,\n",
    "                                            'U2': u1_tft,\n",
    "                                            'lr': lr,\n",
    "                                            'input_chunk_length': input_chunk_length,\n",
    "                                            'output_chunk_length': output_chunk_length,\n",
    "                                            'hidden_size': hidden_size,\n",
    "                                            'batch_size': batch_size,\n",
    "                                            'lstm_layers': lstm_layers,\n",
    "                                            'num_attention_heads': num_attention_heads,\n",
    "                                            'full_attention': full_attention,\n",
    "                                            'dropout': dropout,\n",
    "                                        })\n",
    "                                        models_tft.append({\n",
    "                                            'MAPE': mape_tft,\n",
    "                                            'SLE': sle_tft,\n",
    "                                            'U1': u1_tft,\n",
    "                                            'U2': u1_tft,\n",
    "                                            'lr': lr,\n",
    "                                            'input_chunk_length': input_chunk_length,\n",
    "                                            'output_chunk_length': output_chunk_length,\n",
    "                                            'hidden_size': hidden_size,\n",
    "                                            'batch_size': batch_size,\n",
    "                                            'lstm_layers': lstm_layers,\n",
    "                                            'num_attention_heads': num_attention_heads,\n",
    "                                            'full_attention': full_attention,\n",
    "                                            'dropout': dropout,\n",
    "                                        })\n",
    "                                    except:\n",
    "                                        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_tft in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_tft, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_tft, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_tft, key=lambda d: d[i])['hidden_size'],\n",
    "                                'batch_size': min(models_tft, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_tft, key=lambda d: d[i])['lr'],\n",
    "                                'lstm_layers': min(models_tft, key=lambda d: d[i])['lstm_layers'],\n",
    "                                'num_attention_heads': min(models_tft, key=lambda d: d[i])['num_attention_heads'],\n",
    "                                'full_attention': min(models_tft, key=lambda d: d[i])['full_attention'],\n",
    "                                'dropout': min(models_tft, key=lambda d: d[i])['dropout'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_tft['name'])\n",
    "    model = TFTModel(\n",
    "        input_chunk_length=best_model_tft['input_chunk_length'],\n",
    "        output_chunk_length=best_model_tft['output_chunk_length'],\n",
    "        hidden_size=best_model_tft['hidden_size'],\n",
    "        batch_size=best_model_tft['batch_size'],\n",
    "        lstm_layers=best_model_tft['lstm_layers'],\n",
    "        num_attention_heads=best_model_tft['num_attention_heads'],\n",
    "        full_attention=best_model_tft['full_attention'],\n",
    "        dropout=best_model_tft['dropout'],\n",
    "        add_relative_index=True,\n",
    "        loss_fn=torch.nn.MSELoss(),\n",
    "        n_epochs=400,\n",
    "        optimizer_kwargs={'lr':best_model_tft['lr']},\n",
    "        pl_trainer_kwargs = {\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0,\n",
    "    )\n",
    "\n",
    "    model.fit(train_detrend_scaled)\n",
    "    pred_series, mape_tft, sle_tft = eval_model(\n",
    "        model,\n",
    "        len(val_detrend_scaled),\n",
    "        series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_detrend_scaled,\n",
    "        target_series = train_detrend_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_tft = uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)])\n",
    "    u2_tft = uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_tft)\n",
    "    print('U2: ', u2_tft)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    num_attention_heads = trial.suggest_int(\"num_attention_heads\", 1, 4)\n",
    "    lstm_layers = trial.suggest_int(\"lstm_layers\", 1, 4)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "    dropout = trial.suggest_uniform(\"dropout\", 0, 0.2)\n",
    "    full_attention = trial.suggest_categorical(\"full_attention\", [True, False])\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = TFTModel(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        lstm_layers=lstm_layers,\n",
    "        num_attention_heads=num_attention_heads,\n",
    "        full_attention=full_attention,\n",
    "        dropout=dropout,\n",
    "        add_relative_index=True,\n",
    "        loss_fn=torch.nn.MSELoss(),\n",
    "        n_epochs=n_epochs,\n",
    "        optimizer_kwargs={'lr':lr},\n",
    "        pl_trainer_kwargs = {\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0,\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_detrend_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    mapes = mape(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TFTModel(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    lstm_layers=study.best_trial.params['lstm_layers'],\n",
    "    num_attention_heads=study.best_trial.params['num_attention_heads'],\n",
    "    full_attention=study.best_trial.params['full_attention'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    add_relative_index=True,\n",
    "    loss_fn=torch.nn.MSELoss(),\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    optimizer_kwargs={'lr':study.best_trial.params['lr']},\n",
    "    pl_trainer_kwargs = {\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "    random_state = 0,\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_detrend_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    num_attention_heads = trial.suggest_int(\"num_attention_heads\", 1, 4)\n",
    "    lstm_layers = trial.suggest_int(\"lstm_layers\", 1, 4)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "    dropout = trial.suggest_uniform(\"dropout\", 0, 0.2)\n",
    "    full_attention = trial.suggest_categorical(\"full_attention\", [True, False])\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = TFTModel(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        lstm_layers=lstm_layers,\n",
    "        num_attention_heads=num_attention_heads,\n",
    "        full_attention=full_attention,\n",
    "        dropout=dropout,\n",
    "        add_relative_index=True,\n",
    "        loss_fn=torch.nn.MSELoss(),\n",
    "        n_epochs=n_epochs,\n",
    "        optimizer_kwargs={'lr':lr},\n",
    "        pl_trainer_kwargs = {\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0,\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_detrend_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TFTModel(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    lstm_layers=study.best_trial.params['lstm_layers'],\n",
    "    num_attention_heads=study.best_trial.params['num_attention_heads'],\n",
    "    full_attention=study.best_trial.params['full_attention'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    add_relative_index=True,\n",
    "    loss_fn=torch.nn.MSELoss(),\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    optimizer_kwargs={'lr':study.best_trial.params['lr']},\n",
    "    pl_trainer_kwargs = {\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "    random_state = 0,\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_detrend_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando MAPE e U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    num_attention_heads = trial.suggest_int(\"num_attention_heads\", 1, 4)\n",
    "    lstm_layers = trial.suggest_int(\"lstm_layers\", 1, 4)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "    dropout = trial.suggest_uniform(\"dropout\", 0, 0.2)\n",
    "    full_attention = trial.suggest_categorical(\"full_attention\", [True, False])\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = TFTModel(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        lstm_layers=lstm_layers,\n",
    "        num_attention_heads=num_attention_heads,\n",
    "        full_attention=full_attention,\n",
    "        dropout=dropout,\n",
    "        add_relative_index=True,\n",
    "        loss_fn=torch.nn.MSELoss(),\n",
    "        n_epochs=n_epochs,\n",
    "        optimizer_kwargs={'lr':lr},\n",
    "        pl_trainer_kwargs = {\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0,\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_detrend_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_detrend_scaled, preds)\n",
    "    mapes = mape(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TFTModel(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    lstm_layers=study.best_trial.params['lstm_layers'],\n",
    "    num_attention_heads=study.best_trial.params['num_attention_heads'],\n",
    "    full_attention=study.best_trial.params['full_attention'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    add_relative_index=True,\n",
    "    loss_fn=torch.nn.MSELoss(),\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    optimizer_kwargs={'lr':study.best_trial.params['lr']},\n",
    "    pl_trainer_kwargs = {\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "    random_state = 0,\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_detrend_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Brasil + Sudeste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Janela deslizante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Não terminou a GRID search, deveria demorar quase 15 dias\n",
    "\n",
    "models_tft = []\n",
    "\n",
    "for input_chunk_length in range(20, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "        for lstm_layers in range(1, 4):\n",
    "            for num_attention_heads in range(1, 5):\n",
    "                for full_attention in [True, False]:\n",
    "                   for hidden_size in [2**i for i in range(3, 7)]:\n",
    "                       for batch_size in [2**i for i in range(3, 7)]:\n",
    "                           for dropout in [i/100 for i in range(0, 20, 5)]:\n",
    "                               for lr in [10**(-i) for i in range(2, 5)]:\n",
    "                                    try:\n",
    "                                        model = TFTModel(\n",
    "                                            input_chunk_length=input_chunk_length,\n",
    "                                            output_chunk_length=output_chunk_length,\n",
    "                                            hidden_size=hidden_size,\n",
    "                                            batch_size=batch_size,\n",
    "                                            lstm_layers=lstm_layers,\n",
    "                                            num_attention_heads=num_attention_heads,\n",
    "                                            full_attention=full_attention,\n",
    "                                            dropout=dropout,\n",
    "                                            add_relative_index=True,\n",
    "                                            loss_fn=torch.nn.MSELoss(),\n",
    "                                            n_epochs=400,\n",
    "                                            optimizer_kwargs={'lr':lr},\n",
    "                                            pl_trainer_kwargs = {\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "                                            random_state = 0,\n",
    "                                        )\n",
    "                                        model.fit([train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())])\n",
    "                                        pred_series, mape_tft, sle_tft = eval_model(\n",
    "                                            model,\n",
    "                                            len(val_scaled),\n",
    "                                            series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                            val_scaled,\n",
    "                                            target_series = train_scaled,\n",
    "                                            returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                            plot = False,\n",
    "                                        )\n",
    "                                        uTheil = UTheil()\n",
    "                                        u1_tft = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "                                        u2_tft = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "                                        print({\n",
    "                                            'MAPE': mape_tft,\n",
    "                                            'SLE': sle_tft,\n",
    "                                            'U1': u1_tft,\n",
    "                                            'U2': u1_tft,\n",
    "                                            'lr': lr,\n",
    "                                            'input_chunk_length': input_chunk_length,\n",
    "                                            'output_chunk_length': output_chunk_length,\n",
    "                                            'hidden_size': hidden_size,\n",
    "                                            'batch_size': batch_size,\n",
    "                                            'lstm_layers': lstm_layers,\n",
    "                                            'num_attention_heads': num_attention_heads,\n",
    "                                            'full_attention': full_attention,\n",
    "                                            'dropout': dropout,\n",
    "                                        })\n",
    "                                        models_tft.append({\n",
    "                                            'MAPE': mape_tft,\n",
    "                                            'SLE': sle_tft,\n",
    "                                            'U1': u1_tft,\n",
    "                                            'U2': u1_tft,\n",
    "                                            'lr': lr,\n",
    "                                            'input_chunk_length': input_chunk_length,\n",
    "                                            'output_chunk_length': output_chunk_length,\n",
    "                                            'hidden_size': hidden_size,\n",
    "                                            'batch_size': batch_size,\n",
    "                                            'lstm_layers': lstm_layers,\n",
    "                                            'num_attention_heads': num_attention_heads,\n",
    "                                            'full_attention': full_attention,\n",
    "                                            'dropout': dropout,\n",
    "                                        })\n",
    "                                    except:\n",
    "                                        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_tft in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_tft, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_tft, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_tft, key=lambda d: d[i])['hidden_size'],\n",
    "                                'batch_size': min(models_tft, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_tft, key=lambda d: d[i])['lr'],\n",
    "                                'lstm_layers': min(models_tft, key=lambda d: d[i])['lstm_layers'],\n",
    "                                'num_attention_heads': min(models_tft, key=lambda d: d[i])['num_attention_heads'],\n",
    "                                'full_attention': min(models_tft, key=lambda d: d[i])['full_attention'],\n",
    "                                'dropout': min(models_tft, key=lambda d: d[i])['dropout'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_tft['name'])\n",
    "    model = TFTModel(\n",
    "        input_chunk_length=best_model_tft['input_chunk_length'],\n",
    "        output_chunk_length=best_model_tft['output_chunk_length'],\n",
    "        hidden_size=best_model_tft['hidden_size'],\n",
    "        batch_size=best_model_tft['batch_size'],\n",
    "        lstm_layers=best_model_tft['lstm_layers'],\n",
    "        num_attention_heads=best_model_tft['num_attention_heads'],\n",
    "        full_attention=best_model_tft['full_attention'],\n",
    "        dropout=best_model_tft['dropout'],\n",
    "        add_relative_index=True,\n",
    "        loss_fn=torch.nn.MSELoss(),\n",
    "        n_epochs=400,\n",
    "        optimizer_kwargs={'lr':best_model_tft['lr']},\n",
    "        pl_trainer_kwargs = {\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0,\n",
    "    )\n",
    "\n",
    "    model.fit([train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())])\n",
    "    pred_series, mape_tft, sle_tft = eval_model(\n",
    "        model,\n",
    "        len(val_scaled),\n",
    "        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_scaled,\n",
    "        target_series = train_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_tft = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "    u2_tft = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_tft)\n",
    "    print('U2: ', u2_tft)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    num_attention_heads = trial.suggest_int(\"num_attention_heads\", 1, 4)\n",
    "    lstm_layers = trial.suggest_int(\"lstm_layers\", 1, 4)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "    dropout = trial.suggest_uniform(\"dropout\", 0, 0.2)\n",
    "    full_attention = trial.suggest_categorical(\"full_attention\", [True, False])\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = TFTModel(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        lstm_layers=lstm_layers,\n",
    "        num_attention_heads=num_attention_heads,\n",
    "        full_attention=full_attention,\n",
    "        dropout=dropout,\n",
    "        add_relative_index=True,\n",
    "        loss_fn=torch.nn.MSELoss(),\n",
    "        n_epochs=n_epochs,\n",
    "        optimizer_kwargs={'lr':lr},\n",
    "        pl_trainer_kwargs = {\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0,\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TFTModel(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    lstm_layers=study.best_trial.params['lstm_layers'],\n",
    "    num_attention_heads=study.best_trial.params['num_attention_heads'],\n",
    "    full_attention=study.best_trial.params['full_attention'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    add_relative_index=True,\n",
    "    loss_fn=torch.nn.MSELoss(),\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    optimizer_kwargs={'lr':study.best_trial.params['lr']},\n",
    "    pl_trainer_kwargs = {\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "    random_state = 0,\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    num_attention_heads = trial.suggest_int(\"num_attention_heads\", 1, 4)\n",
    "    lstm_layers = trial.suggest_int(\"lstm_layers\", 1, 4)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "    dropout = trial.suggest_uniform(\"dropout\", 0, 0.2)\n",
    "    full_attention = trial.suggest_categorical(\"full_attention\", [True, False])\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = TFTModel(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        lstm_layers=lstm_layers,\n",
    "        num_attention_heads=num_attention_heads,\n",
    "        full_attention=full_attention,\n",
    "        dropout=dropout,\n",
    "        add_relative_index=True,\n",
    "        loss_fn=torch.nn.MSELoss(),\n",
    "        n_epochs=n_epochs,\n",
    "        optimizer_kwargs={'lr':lr},\n",
    "        pl_trainer_kwargs = {\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0,\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TFTModel(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    lstm_layers=study.best_trial.params['lstm_layers'],\n",
    "    num_attention_heads=study.best_trial.params['num_attention_heads'],\n",
    "    full_attention=study.best_trial.params['full_attention'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    add_relative_index=True,\n",
    "    loss_fn=torch.nn.MSELoss(),\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    optimizer_kwargs={'lr':study.best_trial.params['lr']},\n",
    "    pl_trainer_kwargs = {\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "    random_state = 0,\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando MAPE e U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    num_attention_heads = trial.suggest_int(\"num_attention_heads\", 1, 4)\n",
    "    lstm_layers = trial.suggest_int(\"lstm_layers\", 1, 4)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "    dropout = trial.suggest_uniform(\"dropout\", 0, 0.2)\n",
    "    full_attention = trial.suggest_categorical(\"full_attention\", [True, False])\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = TFTModel(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        lstm_layers=lstm_layers,\n",
    "        num_attention_heads=num_attention_heads,\n",
    "        full_attention=full_attention,\n",
    "        dropout=dropout,\n",
    "        add_relative_index=True,\n",
    "        loss_fn=torch.nn.MSELoss(),\n",
    "        n_epochs=n_epochs,\n",
    "        optimizer_kwargs={'lr':lr},\n",
    "        pl_trainer_kwargs = {\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0,\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_scaled, preds)\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TFTModel(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    lstm_layers=study.best_trial.params['lstm_layers'],\n",
    "    num_attention_heads=study.best_trial.params['num_attention_heads'],\n",
    "    full_attention=study.best_trial.params['full_attention'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    add_relative_index=True,\n",
    "    loss_fn=torch.nn.MSELoss(),\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    optimizer_kwargs={'lr':study.best_trial.params['lr']},\n",
    "    pl_trainer_kwargs = {\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "    random_state = 0,\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Brasil (detrend) + Sudeste (detrend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Janela deslizante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Não terminou a GRID search, deveria demorar quase 15 dias\n",
    "\n",
    "models_tft = []\n",
    "\n",
    "for input_chunk_length in range(20, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "        for lstm_layers in range(1, 4):\n",
    "            for num_attention_heads in range(1, 5):\n",
    "                for full_attention in [True, False]:\n",
    "                   for hidden_size in [2**i for i in range(3, 7)]:\n",
    "                       for batch_size in [2**i for i in range(3, 7)]:\n",
    "                           for dropout in [i/100 for i in range(0, 20, 5)]:\n",
    "                               for lr in [10**(-i) for i in range(2, 5)]:\n",
    "                                    try:\n",
    "                                        model = TFTModel(\n",
    "                                            input_chunk_length=input_chunk_length,\n",
    "                                            output_chunk_length=output_chunk_length,\n",
    "                                            hidden_size=hidden_size,\n",
    "                                            batch_size=batch_size,\n",
    "                                            lstm_layers=lstm_layers,\n",
    "                                            num_attention_heads=num_attention_heads,\n",
    "                                            full_attention=full_attention,\n",
    "                                            dropout=dropout,\n",
    "                                            add_relative_index=True,\n",
    "                                            loss_fn=torch.nn.MSELoss(),\n",
    "                                            n_epochs=400,\n",
    "                                            optimizer_kwargs={'lr':lr},\n",
    "                                            pl_trainer_kwargs = {\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "                                            random_state = 0,\n",
    "                                        )\n",
    "                                        model.fit([train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())])\n",
    "                                        pred_series, mape_tft, sle_tft = eval_model(\n",
    "                                            model,\n",
    "                                            len(val_detrend_scaled),\n",
    "                                            series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                            val_detrend_scaled,\n",
    "                                            target_series = train_detrend_scaled,\n",
    "                                            returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                            plot = False,\n",
    "                                        )\n",
    "                                        uTheil = UTheil()\n",
    "                                        u1_tft = uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)])\n",
    "                                        u2_tft = uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)])\n",
    "                                        print({\n",
    "                                            'MAPE': mape_tft,\n",
    "                                            'SLE': sle_tft,\n",
    "                                            'U1': u1_tft,\n",
    "                                            'U2': u1_tft,\n",
    "                                            'lr': lr,\n",
    "                                            'input_chunk_length': input_chunk_length,\n",
    "                                            'output_chunk_length': output_chunk_length,\n",
    "                                            'hidden_size': hidden_size,\n",
    "                                            'batch_size': batch_size,\n",
    "                                            'lstm_layers': lstm_layers,\n",
    "                                            'num_attention_heads': num_attention_heads,\n",
    "                                            'full_attention': full_attention,\n",
    "                                            'dropout': dropout,\n",
    "                                        })\n",
    "                                        models_tft.append({\n",
    "                                            'MAPE': mape_tft,\n",
    "                                            'SLE': sle_tft,\n",
    "                                            'U1': u1_tft,\n",
    "                                            'U2': u1_tft,\n",
    "                                            'lr': lr,\n",
    "                                            'input_chunk_length': input_chunk_length,\n",
    "                                            'output_chunk_length': output_chunk_length,\n",
    "                                            'hidden_size': hidden_size,\n",
    "                                            'batch_size': batch_size,\n",
    "                                            'lstm_layers': lstm_layers,\n",
    "                                            'num_attention_heads': num_attention_heads,\n",
    "                                            'full_attention': full_attention,\n",
    "                                            'dropout': dropout,\n",
    "                                        })\n",
    "                                    except:\n",
    "                                        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_tft in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_tft, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_tft, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_tft, key=lambda d: d[i])['hidden_size'],\n",
    "                                'batch_size': min(models_tft, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_tft, key=lambda d: d[i])['lr'],\n",
    "                                'lstm_layers': min(models_tft, key=lambda d: d[i])['lstm_layers'],\n",
    "                                'num_attention_heads': min(models_tft, key=lambda d: d[i])['num_attention_heads'],\n",
    "                                'full_attention': min(models_tft, key=lambda d: d[i])['full_attention'],\n",
    "                                'dropout': min(models_tft, key=lambda d: d[i])['dropout'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_tft['name'])\n",
    "    model = TFTModel(\n",
    "        input_chunk_length=best_model_tft['input_chunk_length'],\n",
    "        output_chunk_length=best_model_tft['output_chunk_length'],\n",
    "        hidden_size=best_model_tft['hidden_size'],\n",
    "        batch_size=best_model_tft['batch_size'],\n",
    "        lstm_layers=best_model_tft['lstm_layers'],\n",
    "        num_attention_heads=best_model_tft['num_attention_heads'],\n",
    "        full_attention=best_model_tft['full_attention'],\n",
    "        dropout=best_model_tft['dropout'],\n",
    "        add_relative_index=True,\n",
    "        loss_fn=torch.nn.MSELoss(),\n",
    "        n_epochs=400,\n",
    "        optimizer_kwargs={'lr':best_model_tft['lr']},\n",
    "        pl_trainer_kwargs = {\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0,\n",
    "    )\n",
    "\n",
    "    model.fit([train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())])\n",
    "    pred_series, mape_tft, sle_tft = eval_model(\n",
    "        model,\n",
    "        len(val_detrend_scaled),\n",
    "        series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_detrend_scaled,\n",
    "        target_series = train_detrend_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_tft = uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)])\n",
    "    u2_tft = uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_tft)\n",
    "    print('U2: ', u2_tft)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    num_attention_heads = trial.suggest_int(\"num_attention_heads\", 1, 4)\n",
    "    lstm_layers = trial.suggest_int(\"lstm_layers\", 1, 4)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "    dropout = trial.suggest_uniform(\"dropout\", 0, 0.2)\n",
    "    full_attention = trial.suggest_categorical(\"full_attention\", [True, False])\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = TFTModel(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        lstm_layers=lstm_layers,\n",
    "        num_attention_heads=num_attention_heads,\n",
    "        full_attention=full_attention,\n",
    "        dropout=dropout,\n",
    "        add_relative_index=True,\n",
    "        loss_fn=torch.nn.MSELoss(),\n",
    "        n_epochs=n_epochs,\n",
    "        optimizer_kwargs={'lr':lr},\n",
    "        pl_trainer_kwargs = {\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0,\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    mapes = mape(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TFTModel(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    lstm_layers=study.best_trial.params['lstm_layers'],\n",
    "    num_attention_heads=study.best_trial.params['num_attention_heads'],\n",
    "    full_attention=study.best_trial.params['full_attention'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    add_relative_index=True,\n",
    "    loss_fn=torch.nn.MSELoss(),\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    optimizer_kwargs={'lr':study.best_trial.params['lr']},\n",
    "    pl_trainer_kwargs = {\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "    random_state = 0,\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    num_attention_heads = trial.suggest_int(\"num_attention_heads\", 1, 4)\n",
    "    lstm_layers = trial.suggest_int(\"lstm_layers\", 1, 4)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "    dropout = trial.suggest_uniform(\"dropout\", 0, 0.2)\n",
    "    full_attention = trial.suggest_categorical(\"full_attention\", [True, False])\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = TFTModel(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        lstm_layers=lstm_layers,\n",
    "        num_attention_heads=num_attention_heads,\n",
    "        full_attention=full_attention,\n",
    "        dropout=dropout,\n",
    "        add_relative_index=True,\n",
    "        loss_fn=torch.nn.MSELoss(),\n",
    "        n_epochs=n_epochs,\n",
    "        optimizer_kwargs={'lr':lr},\n",
    "        pl_trainer_kwargs = {\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0,\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TFTModel(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    lstm_layers=study.best_trial.params['lstm_layers'],\n",
    "    num_attention_heads=study.best_trial.params['num_attention_heads'],\n",
    "    full_attention=study.best_trial.params['full_attention'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    add_relative_index=True,\n",
    "    loss_fn=torch.nn.MSELoss(),\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    optimizer_kwargs={'lr':study.best_trial.params['lr']},\n",
    "    pl_trainer_kwargs = {\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "    random_state = 0,\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando MAPE e U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    num_attention_heads = trial.suggest_int(\"num_attention_heads\", 1, 4)\n",
    "    lstm_layers = trial.suggest_int(\"lstm_layers\", 1, 4)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "    dropout = trial.suggest_uniform(\"dropout\", 0, 0.2)\n",
    "    full_attention = trial.suggest_categorical(\"full_attention\", [True, False])\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = TFTModel(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        lstm_layers=lstm_layers,\n",
    "        num_attention_heads=num_attention_heads,\n",
    "        full_attention=full_attention,\n",
    "        dropout=dropout,\n",
    "        add_relative_index=True,\n",
    "        loss_fn=torch.nn.MSELoss(),\n",
    "        n_epochs=n_epochs,\n",
    "        optimizer_kwargs={'lr':lr},\n",
    "        pl_trainer_kwargs = {\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0,\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_detrend_scaled, preds)\n",
    "    mapes = mape(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TFTModel(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    lstm_layers=study.best_trial.params['lstm_layers'],\n",
    "    num_attention_heads=study.best_trial.params['num_attention_heads'],\n",
    "    full_attention=study.best_trial.params['full_attention'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    add_relative_index=True,\n",
    "    loss_fn=torch.nn.MSELoss(),\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    optimizer_kwargs={'lr':study.best_trial.params['lr']},\n",
    "    pl_trainer_kwargs = {\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "    random_state = 0,\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Brasil + Óleo de Soja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Janela deslizante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Não terminou a GRID search, deveria demorar quase 15 dias\n",
    "\n",
    "models_tft = []\n",
    "\n",
    "for input_chunk_length in range(20, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "        for lstm_layers in range(1, 4):\n",
    "            for num_attention_heads in range(1, 5):\n",
    "                for full_attention in [True, False]:\n",
    "                   for hidden_size in [2**i for i in range(3, 7)]:\n",
    "                       for batch_size in [2**i for i in range(3, 7)]:\n",
    "                           for dropout in [i/100 for i in range(0, 20, 5)]:\n",
    "                               for lr in [10**(-i) for i in range(2, 5)]:\n",
    "                                    try:\n",
    "                                        model = TFTModel(\n",
    "                                            input_chunk_length=input_chunk_length,\n",
    "                                            output_chunk_length=output_chunk_length,\n",
    "                                            hidden_size=hidden_size,\n",
    "                                            batch_size=batch_size,\n",
    "                                            lstm_layers=lstm_layers,\n",
    "                                            num_attention_heads=num_attention_heads,\n",
    "                                            full_attention=full_attention,\n",
    "                                            dropout=dropout,\n",
    "                                            add_relative_index=True,\n",
    "                                            loss_fn=torch.nn.MSELoss(),\n",
    "                                            n_epochs=400,\n",
    "                                            optimizer_kwargs={'lr':lr},\n",
    "                                            pl_trainer_kwargs = {\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "                                            random_state = 0,\n",
    "                                        )\n",
    "                                        model.fit([train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())])\n",
    "                                        pred_series, mape_tft, sle_tft = eval_model(\n",
    "                                            model,\n",
    "                                            len(val_scaled),\n",
    "                                            series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "                                            val_scaled,\n",
    "                                            target_series = train_scaled,\n",
    "                                            returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                                            plot = False,\n",
    "                                        )\n",
    "                                        uTheil = UTheil()\n",
    "                                        u1_tft = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "                                        u2_tft = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "                                        print({\n",
    "                                            'MAPE': mape_tft,\n",
    "                                            'SLE': sle_tft,\n",
    "                                            'U1': u1_tft,\n",
    "                                            'U2': u1_tft,\n",
    "                                            'lr': lr,\n",
    "                                            'input_chunk_length': input_chunk_length,\n",
    "                                            'output_chunk_length': output_chunk_length,\n",
    "                                            'hidden_size': hidden_size,\n",
    "                                            'batch_size': batch_size,\n",
    "                                            'lstm_layers': lstm_layers,\n",
    "                                            'num_attention_heads': num_attention_heads,\n",
    "                                            'full_attention': full_attention,\n",
    "                                            'dropout': dropout,\n",
    "                                        })\n",
    "                                        models_tft.append({\n",
    "                                            'MAPE': mape_tft,\n",
    "                                            'SLE': sle_tft,\n",
    "                                            'U1': u1_tft,\n",
    "                                            'U2': u1_tft,\n",
    "                                            'lr': lr,\n",
    "                                            'input_chunk_length': input_chunk_length,\n",
    "                                            'output_chunk_length': output_chunk_length,\n",
    "                                            'hidden_size': hidden_size,\n",
    "                                            'batch_size': batch_size,\n",
    "                                            'lstm_layers': lstm_layers,\n",
    "                                            'num_attention_heads': num_attention_heads,\n",
    "                                            'full_attention': full_attention,\n",
    "                                            'dropout': dropout,\n",
    "                                        })\n",
    "                                    except:\n",
    "                                        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_tft in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_tft, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_tft, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'hidden_size': min(models_tft, key=lambda d: d[i])['hidden_size'],\n",
    "                                'batch_size': min(models_tft, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_tft, key=lambda d: d[i])['lr'],\n",
    "                                'lstm_layers': min(models_tft, key=lambda d: d[i])['lstm_layers'],\n",
    "                                'num_attention_heads': min(models_tft, key=lambda d: d[i])['num_attention_heads'],\n",
    "                                'full_attention': min(models_tft, key=lambda d: d[i])['full_attention'],\n",
    "                                'dropout': min(models_tft, key=lambda d: d[i])['dropout'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_tft['name'])\n",
    "    model = TFTModel(\n",
    "        input_chunk_length=best_model_tft['input_chunk_length'],\n",
    "        output_chunk_length=best_model_tft['output_chunk_length'],\n",
    "        hidden_size=best_model_tft['hidden_size'],\n",
    "        batch_size=best_model_tft['batch_size'],\n",
    "        lstm_layers=best_model_tft['lstm_layers'],\n",
    "        num_attention_heads=best_model_tft['num_attention_heads'],\n",
    "        full_attention=best_model_tft['full_attention'],\n",
    "        dropout=best_model_tft['dropout'],\n",
    "        add_relative_index=True,\n",
    "        loss_fn=torch.nn.MSELoss(),\n",
    "        n_epochs=400,\n",
    "        optimizer_kwargs={'lr':best_model_tft['lr']},\n",
    "        pl_trainer_kwargs = {\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0,\n",
    "    )\n",
    "\n",
    "    model.fit([train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())])\n",
    "    pred_series, mape_tft, sle_tft = eval_model(\n",
    "        model,\n",
    "        len(val_scaled),\n",
    "        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_scaled,\n",
    "        target_series = train_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_tft = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "    u2_tft = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_tft)\n",
    "    print('U2: ', u2_tft)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    num_attention_heads = trial.suggest_int(\"num_attention_heads\", 1, 4)\n",
    "    lstm_layers = trial.suggest_int(\"lstm_layers\", 1, 4)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "    dropout = trial.suggest_uniform(\"dropout\", 0, 0.2)\n",
    "    full_attention = trial.suggest_categorical(\"full_attention\", [True, False])\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = TFTModel(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        lstm_layers=lstm_layers,\n",
    "        num_attention_heads=num_attention_heads,\n",
    "        full_attention=full_attention,\n",
    "        dropout=dropout,\n",
    "        add_relative_index=True,\n",
    "        loss_fn=torch.nn.MSELoss(),\n",
    "        n_epochs=n_epochs,\n",
    "        optimizer_kwargs={'lr':lr},\n",
    "        pl_trainer_kwargs = {\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0,\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TFTModel(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    lstm_layers=study.best_trial.params['lstm_layers'],\n",
    "    num_attention_heads=study.best_trial.params['num_attention_heads'],\n",
    "    full_attention=study.best_trial.params['full_attention'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    add_relative_index=True,\n",
    "    loss_fn=torch.nn.MSELoss(),\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    optimizer_kwargs={'lr':study.best_trial.params['lr']},\n",
    "    pl_trainer_kwargs = {\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "    random_state = 0,\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    num_attention_heads = trial.suggest_int(\"num_attention_heads\", 1, 4)\n",
    "    lstm_layers = trial.suggest_int(\"lstm_layers\", 1, 4)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "    dropout = trial.suggest_uniform(\"dropout\", 0, 0.2)\n",
    "    full_attention = trial.suggest_categorical(\"full_attention\", [True, False])\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = TFTModel(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        lstm_layers=lstm_layers,\n",
    "        num_attention_heads=num_attention_heads,\n",
    "        full_attention=full_attention,\n",
    "        dropout=dropout,\n",
    "        add_relative_index=True,\n",
    "        loss_fn=torch.nn.MSELoss(),\n",
    "        n_epochs=n_epochs,\n",
    "        optimizer_kwargs={'lr':lr},\n",
    "        pl_trainer_kwargs = {\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0,\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TFTModel(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    lstm_layers=study.best_trial.params['lstm_layers'],\n",
    "    num_attention_heads=study.best_trial.params['num_attention_heads'],\n",
    "    full_attention=study.best_trial.params['full_attention'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    add_relative_index=True,\n",
    "    loss_fn=torch.nn.MSELoss(),\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    optimizer_kwargs={'lr':study.best_trial.params['lr']},\n",
    "    pl_trainer_kwargs = {\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "    random_state = 0,\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando MAPE e U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 3, 7)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    num_attention_heads = trial.suggest_int(\"num_attention_heads\", 1, 4)\n",
    "    lstm_layers = trial.suggest_int(\"lstm_layers\", 1, 4)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "    dropout = trial.suggest_uniform(\"dropout\", 0, 0.2)\n",
    "    full_attention = trial.suggest_categorical(\"full_attention\", [True, False])\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = TFTModel(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        hidden_size=2**hidden_size,\n",
    "        batch_size=2**batch_size,\n",
    "        lstm_layers=lstm_layers,\n",
    "        num_attention_heads=num_attention_heads,\n",
    "        full_attention=full_attention,\n",
    "        dropout=dropout,\n",
    "        add_relative_index=True,\n",
    "        loss_fn=torch.nn.MSELoss(),\n",
    "        n_epochs=n_epochs,\n",
    "        optimizer_kwargs={'lr':lr},\n",
    "        pl_trainer_kwargs = {\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0,\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_scaled, preds)\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TFTModel(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    hidden_size=2**study.best_trial.params['hidden_size'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    lstm_layers=study.best_trial.params['lstm_layers'],\n",
    "    num_attention_heads=study.best_trial.params['num_attention_heads'],\n",
    "    full_attention=study.best_trial.params['full_attention'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    add_relative_index=True,\n",
    "    loss_fn=torch.nn.MSELoss(),\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    optimizer_kwargs={'lr':study.best_trial.params['lr']},\n",
    "    pl_trainer_kwargs = {\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "    random_state = 0,\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## NHiTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Brasil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Janela deslizante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_nhits = []\n",
    "\n",
    "for input_chunk_length in range(20, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "       for num_stacks in range(1,4):\n",
    "       for num_blocks in range(1,4):\n",
    "       for num_layers in range(1,4):\n",
    "           for batch_size in [2**i for i in range(3, 7)]:\n",
    "           for layer_widths in [2**i for i in range(6, 9)]:\n",
    "               for dropout in [i/100 for i in range(0, 20, 5)]:\n",
    "               for lr in [10**(-i) for i in range(2, 5)]:\n",
    "                    try:\n",
    "                        model = NHiTSModel(\n",
    "                            input_chunk_length=input_chunk_length,\n",
    "                            output_chunk_length=output_chunk_length,\n",
    "                            batch_size=batch_size,\n",
    "                            num_stacks=num_stacks,\n",
    "                            num_blocks=num_blocks,\n",
    "                            num_layers=num_layers,\n",
    "                            layer_widths=layer_widths,\n",
    "                            dropout=dropout,\n",
    "                            n_epochs=400,\n",
    "                            optimizer_kwargs={'lr': lr},\n",
    "                            pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "                            random_state = 0\n",
    "                        )\n",
    "                        model.fit(train_scaled)\n",
    "                        pred_series, mape_nhits, sle_nhits = eval_model(\n",
    "                            model,\n",
    "                            len(val_scaled),\n",
    "                            series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "                            val_scaled,\n",
    "                            target_series = train_scaled,\n",
    "                            returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                            plot = False,\n",
    "                        )\n",
    "                        uTheil = UTheil()\n",
    "                        u1_nhits = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "                        u2_nhits = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "                        print({\n",
    "                            'MAPE': mape_nhits,\n",
    "                            'SLE': sle_nhits,\n",
    "                            'U1': u1_nhits,\n",
    "                            'U2': u1_nhits,\n",
    "                            'lr': lr,\n",
    "                            'input_chunk_length': input_chunk_length,\n",
    "                            'output_chunk_length': output_chunk_length,\n",
    "                            'num_stacks': num_stacks,\n",
    "                            'num_blocks': num_blocks,\n",
    "                            'num_layers': num_layers,\n",
    "                            'batch_size': batch_size,\n",
    "                            'layer_widths': layer_widths,\n",
    "                            'dropout': dropout,\n",
    "                        })\n",
    "                        models_nhits.append({\n",
    "                            'MAPE': mape_nhits,\n",
    "                            'SLE': sle_nhits,\n",
    "                            'U1': u1_nhits,\n",
    "                            'U2': u1_nhits,\n",
    "                            'lr': lr,\n",
    "                            'input_chunk_length': input_chunk_length,\n",
    "                            'output_chunk_length': output_chunk_length,\n",
    "                            'num_stacks': num_stacks,\n",
    "                            'num_blocks': num_blocks,\n",
    "                            'num_layers': num_layers,\n",
    "                            'batch_size': batch_size,\n",
    "                            'layer_widths': layer_widths,\n",
    "                            'dropout': dropout,\n",
    "                        })\n",
    "                    except:\n",
    "                        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_nhits in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_nhits, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_nhits, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'dropout': min(models_nhits, key=lambda d: d[i])['dropout'],\n",
    "                                'batch_size': min(models_nhits, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_nhits, key=lambda d: d[i])['lr'],\n",
    "                                'num_stacks': min(models_nhits, key=lambda d: d[i])['num_stacks'],\n",
    "                                'num_blocks': min(models_nhits, key=lambda d: d[i])['num_blocks'],\n",
    "                                'num_layers': min(models_nhits, key=lambda d: d[i])['num_layers'],\n",
    "                                'layer_widths': min(models_nhits, key=lambda d: d[i])['layer_widths'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_nhits['name'])\n",
    "    model = NHiTSModel(\n",
    "        input_chunk_length=best_model_nhits['input_chunk_length'],\n",
    "        output_chunk_length=best_model_nhits['output_chunk_length'],\n",
    "        batch_size=best_model_nhits['batch_size'],\n",
    "        num_stacks=best_model_nhits['num_stacks'],\n",
    "        num_blocks=best_model_nhits['num_blocks'],\n",
    "        num_layers=best_model_nhits['num_layers'],\n",
    "        layer_widths=best_model_nhits['layer_widths'],\n",
    "        dropout=best_model_nhits['dropout'],\n",
    "        n_epochs=400,\n",
    "        optimizer_kwargs={'lr': best_model_nhits['lr']},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit(train_scaled)\n",
    "    pred_series, mape_nhits, sle_nhits = eval_model(\n",
    "        model,\n",
    "        len(val_scaled),\n",
    "        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_scaled,\n",
    "        target_series = train_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_nhits = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "    u2_nhits = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_nhits)\n",
    "    print('U2: ', u2_nhits)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    num_stacks = trial.suggest_int(\"num_stacks\", 1, 4)\n",
    "    num_blocks = trial.suggest_int(\"num_blocks\", 1, 4)\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 4)\n",
    "    layer_widths = trial.suggest_int(\"layer_widths\", 7, 11)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    dropout = trial.suggest_uniform(\"dropout\", 0, 0.2)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NHiTSModel(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        batch_size=2**batch_size,\n",
    "        num_stacks=num_stacks,\n",
    "        num_blocks=num_blocks,\n",
    "        num_layers=num_layers,\n",
    "        layer_widths=2**layer_widths,\n",
    "        dropout=dropout,\n",
    "        n_epochs=n_epochs,\n",
    "        optimizer_kwargs={'lr': lr},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NHiTSModel(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    num_stacks=study.best_trial.params['num_stacks'],\n",
    "    num_blocks=study.best_trial.params['num_blocks'],\n",
    "    num_layers=study.best_trial.params['num_layers'],\n",
    "    layer_widths=2**study.best_trial.params['layer_widths'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    optimizer_kwargs={'lr': study.best_trial.params['lr']},\n",
    "    pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    num_stacks = trial.suggest_int(\"num_stacks\", 1, 4)\n",
    "    num_blocks = trial.suggest_int(\"num_blocks\", 1, 4)\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 4)\n",
    "    layer_widths = trial.suggest_int(\"layer_widths\", 7, 11)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    dropout = trial.suggest_uniform(\"dropout\", 0, 0.2)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NHiTSModel(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        batch_size=2**batch_size,\n",
    "        num_stacks=num_stacks,\n",
    "        num_blocks=num_blocks,\n",
    "        num_layers=num_layers,\n",
    "        layer_widths=2**layer_widths,\n",
    "        dropout=dropout,\n",
    "        n_epochs=n_epochs,\n",
    "        optimizer_kwargs={'lr': lr},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NHiTSModel(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    num_stacks=study.best_trial.params['num_stacks'],\n",
    "    num_blocks=study.best_trial.params['num_blocks'],\n",
    "    num_layers=study.best_trial.params['num_layers'],\n",
    "    layer_widths=2**study.best_trial.params['layer_widths'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    optimizer_kwargs={'lr': study.best_trial.params['lr']},\n",
    "    pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando MAPE e U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    num_stacks = trial.suggest_int(\"num_stacks\", 1, 4)\n",
    "    num_blocks = trial.suggest_int(\"num_blocks\", 1, 4)\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 4)\n",
    "    layer_widths = trial.suggest_int(\"layer_widths\", 7, 11)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    dropout = trial.suggest_uniform(\"dropout\", 0, 0.2)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NHiTSModel(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        batch_size=2**batch_size,\n",
    "        num_stacks=num_stacks,\n",
    "        num_blocks=num_blocks,\n",
    "        num_layers=num_layers,\n",
    "        layer_widths=2**layer_widths,\n",
    "        dropout=dropout,\n",
    "        n_epochs=n_epochs,\n",
    "        optimizer_kwargs={'lr': lr},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_scaled, preds)\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NHiTSModel(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    num_stacks=study.best_trial.params['num_stacks'],\n",
    "    num_blocks=study.best_trial.params['num_blocks'],\n",
    "    num_layers=study.best_trial.params['num_layers'],\n",
    "    layer_widths=2**study.best_trial.params['layer_widths'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    optimizer_kwargs={'lr': study.best_trial.params['lr']},\n",
    "    pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Brasil (detrend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Janela deslizante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_nhits = []\n",
    "\n",
    "for input_chunk_length in range(20, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "       for num_stacks in range(1,4):\n",
    "       for num_blocks in range(1,4):\n",
    "       for num_layers in range(1,4):\n",
    "           for batch_size in [2**i for i in range(3, 7)]:\n",
    "           for layer_widths in [2**i for i in range(6, 9)]:\n",
    "               for dropout in [i/100 for i in range(0, 20, 5)]:\n",
    "               for lr in [10**(-i) for i in range(2, 5)]:\n",
    "                    try:\n",
    "                        model = NHiTSModel(\n",
    "                            input_chunk_length=input_chunk_length,\n",
    "                            output_chunk_length=output_chunk_length,\n",
    "                            batch_size=batch_size,\n",
    "                            num_stacks=num_stacks,\n",
    "                            num_blocks=num_blocks,\n",
    "                            num_layers=num_layers,\n",
    "                            layer_widths=layer_widths,\n",
    "                            dropout=dropout,\n",
    "                            n_epochs=400,\n",
    "                            optimizer_kwargs={'lr': lr},\n",
    "                            pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "                            random_state = 0\n",
    "                        )\n",
    "                        model.fit(train_detrend_scaled)\n",
    "                        pred_series, mape_nhits, sle_nhits = eval_model(\n",
    "                            model,\n",
    "                            len(val_detrend_scaled),\n",
    "                            series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "                            val_detrend_scaled,\n",
    "                            target_series = train_detrend_scaled,\n",
    "                            returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                            plot = False,\n",
    "                        )\n",
    "                        uTheil = UTheil()\n",
    "                        u1_nhits = uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)])\n",
    "                        u2_nhits = uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)])\n",
    "                        print({\n",
    "                            'MAPE': mape_nhits,\n",
    "                            'SLE': sle_nhits,\n",
    "                            'U1': u1_nhits,\n",
    "                            'U2': u1_nhits,\n",
    "                            'lr': lr,\n",
    "                            'input_chunk_length': input_chunk_length,\n",
    "                            'output_chunk_length': output_chunk_length,\n",
    "                            'num_stacks': num_stacks,\n",
    "                            'num_blocks': num_blocks,\n",
    "                            'num_layers': num_layers,\n",
    "                            'batch_size': batch_size,\n",
    "                            'layer_widths': layer_widths,\n",
    "                            'dropout': dropout,\n",
    "                        })\n",
    "                        models_nhits.append({\n",
    "                            'MAPE': mape_nhits,\n",
    "                            'SLE': sle_nhits,\n",
    "                            'U1': u1_nhits,\n",
    "                            'U2': u1_nhits,\n",
    "                            'lr': lr,\n",
    "                            'input_chunk_length': input_chunk_length,\n",
    "                            'output_chunk_length': output_chunk_length,\n",
    "                            'num_stacks': num_stacks,\n",
    "                            'num_blocks': num_blocks,\n",
    "                            'num_layers': num_layers,\n",
    "                            'batch_size': batch_size,\n",
    "                            'layer_widths': layer_widths,\n",
    "                            'dropout': dropout,\n",
    "                        })\n",
    "                    except:\n",
    "                        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_nhits in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_nhits, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_nhits, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'dropout': min(models_nhits, key=lambda d: d[i])['dropout'],\n",
    "                                'batch_size': min(models_nhits, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_nhits, key=lambda d: d[i])['lr'],\n",
    "                                'num_stacks': min(models_nhits, key=lambda d: d[i])['num_stacks'],\n",
    "                                'num_blocks': min(models_nhits, key=lambda d: d[i])['num_blocks'],\n",
    "                                'num_layers': min(models_nhits, key=lambda d: d[i])['num_layers'],\n",
    "                                'layer_widths': min(models_nhits, key=lambda d: d[i])['layer_widths'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_nhits['name'])\n",
    "    model = NHiTSModel(\n",
    "        input_chunk_length=best_model_nhits['input_chunk_length'],\n",
    "        output_chunk_length=best_model_nhits['output_chunk_length'],\n",
    "        batch_size=best_model_nhits['batch_size'],\n",
    "        num_stacks=best_model_nhits['num_stacks'],\n",
    "        num_blocks=best_model_nhits['num_blocks'],\n",
    "        num_layers=best_model_nhits['num_layers'],\n",
    "        layer_widths=best_model_nhits['layer_widths'],\n",
    "        dropout=best_model_nhits['dropout'],\n",
    "        n_epochs=400,\n",
    "        optimizer_kwargs={'lr': best_model_nhits['lr']},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit(train_detrend_scaled)\n",
    "    pred_series, mape_nhits, sle_nhits = eval_model(\n",
    "        model,\n",
    "        len(val_detrend_scaled),\n",
    "        series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_detrend_scaled,\n",
    "        target_series = train_detrend_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_nhits = uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)])\n",
    "    u2_nhits = uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_nhits)\n",
    "    print('U2: ', u2_nhits)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    num_stacks = trial.suggest_int(\"num_stacks\", 1, 4)\n",
    "    num_blocks = trial.suggest_int(\"num_blocks\", 1, 4)\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 4)\n",
    "    layer_widths = trial.suggest_int(\"layer_widths\", 7, 11)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    dropout = trial.suggest_uniform(\"dropout\", 0, 0.2)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NHiTSModel(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        batch_size=2**batch_size,\n",
    "        num_stacks=num_stacks,\n",
    "        num_blocks=num_blocks,\n",
    "        num_layers=num_layers,\n",
    "        layer_widths=2**layer_widths,\n",
    "        dropout=dropout,\n",
    "        n_epochs=n_epochs,\n",
    "        optimizer_kwargs={'lr': lr},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_detrend_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    mapes = mape(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NHiTSModel(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    num_stacks=study.best_trial.params['num_stacks'],\n",
    "    num_blocks=study.best_trial.params['num_blocks'],\n",
    "    num_layers=study.best_trial.params['num_layers'],\n",
    "    layer_widths=2**study.best_trial.params['layer_widths'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    optimizer_kwargs={'lr': study.best_trial.params['lr']},\n",
    "    pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_detrend_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    num_stacks = trial.suggest_int(\"num_stacks\", 1, 4)\n",
    "    num_blocks = trial.suggest_int(\"num_blocks\", 1, 4)\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 4)\n",
    "    layer_widths = trial.suggest_int(\"layer_widths\", 7, 11)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    dropout = trial.suggest_uniform(\"dropout\", 0, 0.2)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NHiTSModel(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        batch_size=2**batch_size,\n",
    "        num_stacks=num_stacks,\n",
    "        num_blocks=num_blocks,\n",
    "        num_layers=num_layers,\n",
    "        layer_widths=2**layer_widths,\n",
    "        dropout=dropout,\n",
    "        n_epochs=n_epochs,\n",
    "        optimizer_kwargs={'lr': lr},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_detrend_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NHiTSModel(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    num_stacks=study.best_trial.params['num_stacks'],\n",
    "    num_blocks=study.best_trial.params['num_blocks'],\n",
    "    num_layers=study.best_trial.params['num_layers'],\n",
    "    layer_widths=2**study.best_trial.params['layer_widths'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    optimizer_kwargs={'lr': study.best_trial.params['lr']},\n",
    "    pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_detrend_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando MAPE e U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    num_stacks = trial.suggest_int(\"num_stacks\", 1, 4)\n",
    "    num_blocks = trial.suggest_int(\"num_blocks\", 1, 4)\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 4)\n",
    "    layer_widths = trial.suggest_int(\"layer_widths\", 7, 11)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    dropout = trial.suggest_uniform(\"dropout\", 0, 0.2)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NHiTSModel(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        batch_size=2**batch_size,\n",
    "        num_stacks=num_stacks,\n",
    "        num_blocks=num_blocks,\n",
    "        num_layers=num_layers,\n",
    "        layer_widths=2**layer_widths,\n",
    "        dropout=dropout,\n",
    "        n_epochs=n_epochs,\n",
    "        optimizer_kwargs={'lr': lr},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=train_detrend_scaled\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_detrend_scaled, preds)\n",
    "    mapes = mape(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NHiTSModel(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    num_stacks=study.best_trial.params['num_stacks'],\n",
    "    num_blocks=study.best_trial.params['num_blocks'],\n",
    "    num_layers=study.best_trial.params['num_layers'],\n",
    "    layer_widths=2**study.best_trial.params['layer_widths'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    optimizer_kwargs={'lr': study.best_trial.params['lr']},\n",
    "    pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=train_detrend_scaled\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Brasil + Sudeste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Janela deslizante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_nhits = []\n",
    "\n",
    "for input_chunk_length in range(20, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "       for num_stacks in range(1,4):\n",
    "       for num_blocks in range(1,4):\n",
    "       for num_layers in range(1,4):\n",
    "           for batch_size in [2**i for i in range(3, 7)]:\n",
    "           for layer_widths in [2**i for i in range(6, 9)]:\n",
    "               for dropout in [i/100 for i in range(0, 20, 5)]:\n",
    "               for lr in [10**(-i) for i in range(2, 5)]:\n",
    "                    try:\n",
    "                        model = NHiTSModel(\n",
    "                            input_chunk_length=input_chunk_length,\n",
    "                            output_chunk_length=output_chunk_length,\n",
    "                            batch_size=batch_size,\n",
    "                            num_stacks=num_stacks,\n",
    "                            num_blocks=num_blocks,\n",
    "                            num_layers=num_layers,\n",
    "                            layer_widths=layer_widths,\n",
    "                            dropout=dropout,\n",
    "                            n_epochs=400,\n",
    "                            optimizer_kwargs={'lr': lr},\n",
    "                            pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "                            random_state = 0\n",
    "                        )\n",
    "                        model.fit([train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())])\n",
    "                        pred_series, mape_nhits, sle_nhits = eval_model(\n",
    "                            model,\n",
    "                            len(val_scaled),\n",
    "                            series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "                            val_scaled,\n",
    "                            target_series = train_scaled,\n",
    "                            returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                            plot = False,\n",
    "                        )\n",
    "                        uTheil = UTheil()\n",
    "                        u1_nhits = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "                        u2_nhits = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "                        print({\n",
    "                            'MAPE': mape_nhits,\n",
    "                            'SLE': sle_nhits,\n",
    "                            'U1': u1_nhits,\n",
    "                            'U2': u1_nhits,\n",
    "                            'lr': lr,\n",
    "                            'input_chunk_length': input_chunk_length,\n",
    "                            'output_chunk_length': output_chunk_length,\n",
    "                            'num_stacks': num_stacks,\n",
    "                            'num_blocks': num_blocks,\n",
    "                            'num_layers': num_layers,\n",
    "                            'batch_size': batch_size,\n",
    "                            'layer_widths': layer_widths,\n",
    "                            'dropout': dropout,\n",
    "                        })\n",
    "                        models_nhits.append({\n",
    "                            'MAPE': mape_nhits,\n",
    "                            'SLE': sle_nhits,\n",
    "                            'U1': u1_nhits,\n",
    "                            'U2': u1_nhits,\n",
    "                            'lr': lr,\n",
    "                            'input_chunk_length': input_chunk_length,\n",
    "                            'output_chunk_length': output_chunk_length,\n",
    "                            'num_stacks': num_stacks,\n",
    "                            'num_blocks': num_blocks,\n",
    "                            'num_layers': num_layers,\n",
    "                            'batch_size': batch_size,\n",
    "                            'layer_widths': layer_widths,\n",
    "                            'dropout': dropout,\n",
    "                        })\n",
    "                    except:\n",
    "                        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_nhits in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_nhits, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_nhits, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'dropout': min(models_nhits, key=lambda d: d[i])['dropout'],\n",
    "                                'batch_size': min(models_nhits, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_nhits, key=lambda d: d[i])['lr'],\n",
    "                                'num_stacks': min(models_nhits, key=lambda d: d[i])['num_stacks'],\n",
    "                                'num_blocks': min(models_nhits, key=lambda d: d[i])['num_blocks'],\n",
    "                                'num_layers': min(models_nhits, key=lambda d: d[i])['num_layers'],\n",
    "                                'layer_widths': min(models_nhits, key=lambda d: d[i])['layer_widths'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_nhits['name'])\n",
    "    model = NHiTSModel(\n",
    "        input_chunk_length=best_model_nhits['input_chunk_length'],\n",
    "        output_chunk_length=best_model_nhits['output_chunk_length'],\n",
    "        batch_size=best_model_nhits['batch_size'],\n",
    "        num_stacks=best_model_nhits['num_stacks'],\n",
    "        num_blocks=best_model_nhits['num_blocks'],\n",
    "        num_layers=best_model_nhits['num_layers'],\n",
    "        layer_widths=best_model_nhits['layer_widths'],\n",
    "        dropout=best_model_nhits['dropout'],\n",
    "        n_epochs=400,\n",
    "        optimizer_kwargs={'lr': best_model_nhits['lr']},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit([train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())])\n",
    "    pred_series, mape_nhits, sle_nhits = eval_model(\n",
    "        model,\n",
    "        len(val_scaled),\n",
    "        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_scaled,\n",
    "        target_series = train_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_nhits = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "    u2_nhits = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_nhits)\n",
    "    print('U2: ', u2_nhits)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    num_stacks = trial.suggest_int(\"num_stacks\", 1, 4)\n",
    "    num_blocks = trial.suggest_int(\"num_blocks\", 1, 4)\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 4)\n",
    "    layer_widths = trial.suggest_int(\"layer_widths\", 7, 11)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    dropout = trial.suggest_uniform(\"dropout\", 0, 0.2)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NHiTSModel(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        batch_size=2**batch_size,\n",
    "        num_stacks=num_stacks,\n",
    "        num_blocks=num_blocks,\n",
    "        num_layers=num_layers,\n",
    "        layer_widths=2**layer_widths,\n",
    "        dropout=dropout,\n",
    "        n_epochs=n_epochs,\n",
    "        optimizer_kwargs={'lr': lr},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NHiTSModel(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    num_stacks=study.best_trial.params['num_stacks'],\n",
    "    num_blocks=study.best_trial.params['num_blocks'],\n",
    "    num_layers=study.best_trial.params['num_layers'],\n",
    "    layer_widths=2**study.best_trial.params['layer_widths'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    optimizer_kwargs={'lr': study.best_trial.params['lr']},\n",
    "    pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    num_stacks = trial.suggest_int(\"num_stacks\", 1, 4)\n",
    "    num_blocks = trial.suggest_int(\"num_blocks\", 1, 4)\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 4)\n",
    "    layer_widths = trial.suggest_int(\"layer_widths\", 7, 11)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    dropout = trial.suggest_uniform(\"dropout\", 0, 0.2)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NHiTSModel(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        batch_size=2**batch_size,\n",
    "        num_stacks=num_stacks,\n",
    "        num_blocks=num_blocks,\n",
    "        num_layers=num_layers,\n",
    "        layer_widths=2**layer_widths,\n",
    "        dropout=dropout,\n",
    "        n_epochs=n_epochs,\n",
    "        optimizer_kwargs={'lr': lr},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NHiTSModel(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    num_stacks=study.best_trial.params['num_stacks'],\n",
    "    num_blocks=study.best_trial.params['num_blocks'],\n",
    "    num_layers=study.best_trial.params['num_layers'],\n",
    "    layer_widths=2**study.best_trial.params['layer_widths'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    optimizer_kwargs={'lr': study.best_trial.params['lr']},\n",
    "    pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando MAPE e U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    num_stacks = trial.suggest_int(\"num_stacks\", 1, 4)\n",
    "    num_blocks = trial.suggest_int(\"num_blocks\", 1, 4)\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 4)\n",
    "    layer_widths = trial.suggest_int(\"layer_widths\", 7, 11)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    dropout = trial.suggest_uniform(\"dropout\", 0, 0.2)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NHiTSModel(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        batch_size=2**batch_size,\n",
    "        num_stacks=num_stacks,\n",
    "        num_blocks=num_blocks,\n",
    "        num_layers=num_layers,\n",
    "        layer_widths=2**layer_widths,\n",
    "        dropout=dropout,\n",
    "        n_epochs=n_epochs,\n",
    "        optimizer_kwargs={'lr': lr},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_scaled, preds)\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NHiTSModel(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    num_stacks=study.best_trial.params['num_stacks'],\n",
    "    num_blocks=study.best_trial.params['num_blocks'],\n",
    "    num_layers=study.best_trial.params['num_layers'],\n",
    "    layer_widths=2**study.best_trial.params['layer_widths'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    optimizer_kwargs={'lr': study.best_trial.params['lr']},\n",
    "    pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, series_southeast_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Brasil (detrend) + Sudeste (detrend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Janela deslizante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_nhits = []\n",
    "\n",
    "for input_chunk_length in range(20, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "       for num_stacks in range(1,4):\n",
    "       for num_blocks in range(1,4):\n",
    "       for num_layers in range(1,4):\n",
    "           for batch_size in [2**i for i in range(3, 7)]:\n",
    "           for layer_widths in [2**i for i in range(6, 9)]:\n",
    "               for dropout in [i/100 for i in range(0, 20, 5)]:\n",
    "               for lr in [10**(-i) for i in range(2, 5)]:\n",
    "                    try:\n",
    "                        model = NHiTSModel(\n",
    "                            input_chunk_length=input_chunk_length,\n",
    "                            output_chunk_length=output_chunk_length,\n",
    "                            batch_size=batch_size,\n",
    "                            num_stacks=num_stacks,\n",
    "                            num_blocks=num_blocks,\n",
    "                            num_layers=num_layers,\n",
    "                            layer_widths=layer_widths,\n",
    "                            dropout=dropout,\n",
    "                            n_epochs=400,\n",
    "                            optimizer_kwargs={'lr': lr},\n",
    "                            pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "                            random_state = 0\n",
    "                        )\n",
    "                        model.fit([train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())])\n",
    "                        pred_series, mape_nhits, sle_nhits = eval_model(\n",
    "                            model,\n",
    "                            len(val_detrend_scaled),\n",
    "                            series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "                            val_detrend_scaled,\n",
    "                            target_series = train_detrend_scaled,\n",
    "                            returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                            plot = False,\n",
    "                        )\n",
    "                        uTheil = UTheil()\n",
    "                        u1_nhits = uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)])\n",
    "                        u2_nhits = uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)])\n",
    "                        print({\n",
    "                            'MAPE': mape_nhits,\n",
    "                            'SLE': sle_nhits,\n",
    "                            'U1': u1_nhits,\n",
    "                            'U2': u1_nhits,\n",
    "                            'lr': lr,\n",
    "                            'input_chunk_length': input_chunk_length,\n",
    "                            'output_chunk_length': output_chunk_length,\n",
    "                            'num_stacks': num_stacks,\n",
    "                            'num_blocks': num_blocks,\n",
    "                            'num_layers': num_layers,\n",
    "                            'batch_size': batch_size,\n",
    "                            'layer_widths': layer_widths,\n",
    "                            'dropout': dropout,\n",
    "                        })\n",
    "                        models_nhits.append({\n",
    "                            'MAPE': mape_nhits,\n",
    "                            'SLE': sle_nhits,\n",
    "                            'U1': u1_nhits,\n",
    "                            'U2': u1_nhits,\n",
    "                            'lr': lr,\n",
    "                            'input_chunk_length': input_chunk_length,\n",
    "                            'output_chunk_length': output_chunk_length,\n",
    "                            'num_stacks': num_stacks,\n",
    "                            'num_blocks': num_blocks,\n",
    "                            'num_layers': num_layers,\n",
    "                            'batch_size': batch_size,\n",
    "                            'layer_widths': layer_widths,\n",
    "                            'dropout': dropout,\n",
    "                        })\n",
    "                    except:\n",
    "                        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_nhits in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_nhits, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_nhits, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'dropout': min(models_nhits, key=lambda d: d[i])['dropout'],\n",
    "                                'batch_size': min(models_nhits, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_nhits, key=lambda d: d[i])['lr'],\n",
    "                                'num_stacks': min(models_nhits, key=lambda d: d[i])['num_stacks'],\n",
    "                                'num_blocks': min(models_nhits, key=lambda d: d[i])['num_blocks'],\n",
    "                                'num_layers': min(models_nhits, key=lambda d: d[i])['num_layers'],\n",
    "                                'layer_widths': min(models_nhits, key=lambda d: d[i])['layer_widths'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_nhits['name'])\n",
    "    model = NHiTSModel(\n",
    "        input_chunk_length=best_model_nhits['input_chunk_length'],\n",
    "        output_chunk_length=best_model_nhits['output_chunk_length'],\n",
    "        batch_size=best_model_nhits['batch_size'],\n",
    "        num_stacks=best_model_nhits['num_stacks'],\n",
    "        num_blocks=best_model_nhits['num_blocks'],\n",
    "        num_layers=best_model_nhits['num_layers'],\n",
    "        layer_widths=best_model_nhits['layer_widths'],\n",
    "        dropout=best_model_nhits['dropout'],\n",
    "        n_epochs=400,\n",
    "        optimizer_kwargs={'lr': best_model_nhits['lr']},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit([train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())])\n",
    "    pred_series, mape_nhits, sle_nhits = eval_model(\n",
    "        model,\n",
    "        len(val_detrend_scaled),\n",
    "        series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_detrend_scaled,\n",
    "        target_series = train_detrend_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_nhits = uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)])\n",
    "    u2_nhits = uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_nhits)\n",
    "    print('U2: ', u2_nhits)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    num_stacks = trial.suggest_int(\"num_stacks\", 1, 4)\n",
    "    num_blocks = trial.suggest_int(\"num_blocks\", 1, 4)\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 4)\n",
    "    layer_widths = trial.suggest_int(\"layer_widths\", 7, 11)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    dropout = trial.suggest_uniform(\"dropout\", 0, 0.2)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NHiTSModel(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        batch_size=2**batch_size,\n",
    "        num_stacks=num_stacks,\n",
    "        num_blocks=num_blocks,\n",
    "        num_layers=num_layers,\n",
    "        layer_widths=2**layer_widths,\n",
    "        dropout=dropout,\n",
    "        n_epochs=n_epochs,\n",
    "        optimizer_kwargs={'lr': lr},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    mapes = mape(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NHiTSModel(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    num_stacks=study.best_trial.params['num_stacks'],\n",
    "    num_blocks=study.best_trial.params['num_blocks'],\n",
    "    num_layers=study.best_trial.params['num_layers'],\n",
    "    layer_widths=2**study.best_trial.params['layer_widths'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    optimizer_kwargs={'lr': study.best_trial.params['lr']},\n",
    "    pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    num_stacks = trial.suggest_int(\"num_stacks\", 1, 4)\n",
    "    num_blocks = trial.suggest_int(\"num_blocks\", 1, 4)\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 4)\n",
    "    layer_widths = trial.suggest_int(\"layer_widths\", 7, 11)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    dropout = trial.suggest_uniform(\"dropout\", 0, 0.2)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NHiTSModel(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        batch_size=2**batch_size,\n",
    "        num_stacks=num_stacks,\n",
    "        num_blocks=num_blocks,\n",
    "        num_layers=num_layers,\n",
    "        layer_widths=2**layer_widths,\n",
    "        dropout=dropout,\n",
    "        n_epochs=n_epochs,\n",
    "        optimizer_kwargs={'lr': lr},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NHiTSModel(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    num_stacks=study.best_trial.params['num_stacks'],\n",
    "    num_blocks=study.best_trial.params['num_blocks'],\n",
    "    num_layers=study.best_trial.params['num_layers'],\n",
    "    layer_widths=2**study.best_trial.params['layer_widths'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    optimizer_kwargs={'lr': study.best_trial.params['lr']},\n",
    "    pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando MAPE e U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    num_stacks = trial.suggest_int(\"num_stacks\", 1, 4)\n",
    "    num_blocks = trial.suggest_int(\"num_blocks\", 1, 4)\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 4)\n",
    "    layer_widths = trial.suggest_int(\"layer_widths\", 7, 11)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 200, 600)\n",
    "    dropout = trial.suggest_uniform(\"dropout\", 0, 0.2)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NHiTSModel(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        batch_size=2**batch_size,\n",
    "        num_stacks=num_stacks,\n",
    "        num_blocks=num_blocks,\n",
    "        num_layers=num_layers,\n",
    "        layer_widths=2**layer_widths,\n",
    "        dropout=dropout,\n",
    "        n_epochs=n_epochs,\n",
    "        optimizer_kwargs={'lr': lr},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_detrend_scaled, n=len(val_detrend_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_detrend_scaled, preds)\n",
    "    mapes = mape(val_detrend_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NHiTSModel(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    num_stacks=study.best_trial.params['num_stacks'],\n",
    "    num_blocks=study.best_trial.params['num_blocks'],\n",
    "    num_layers=study.best_trial.params['num_layers'],\n",
    "    layer_widths=2**study.best_trial.params['layer_widths'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    optimizer_kwargs={'lr': study.best_trial.params['lr']},\n",
    "    pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_detrend_scaled, series_southeast_detrend_scaled.slice(train.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_detrend_scaled),\n",
    "    series_national_detrend_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_detrend_scaled,\n",
    "    target_series = train_detrend_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_detrend_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_detrend_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Brasil + Óleo de Soja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Janela deslizante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_nhits = []\n",
    "\n",
    "for input_chunk_length in range(20, 30, 2):\n",
    "    for output_chunk_length in range(1, 20, 4):\n",
    "       for num_stacks in range(1,4):\n",
    "       for num_blocks in range(1,4):\n",
    "       for num_layers in range(1,4):\n",
    "           for batch_size in [2**i for i in range(3, 7)]:\n",
    "           for layer_widths in [2**i for i in range(6, 9)]:\n",
    "               for dropout in [i/100 for i in range(0, 20, 5)]:\n",
    "               for lr in [10**(-i) for i in range(2, 5)]:\n",
    "                    try:\n",
    "                        model = NHiTSModel(\n",
    "                            input_chunk_length=input_chunk_length,\n",
    "                            output_chunk_length=output_chunk_length,\n",
    "                            batch_size=batch_size,\n",
    "                            num_stacks=num_stacks,\n",
    "                            num_blocks=num_blocks,\n",
    "                            num_layers=num_layers,\n",
    "                            layer_widths=layer_widths,\n",
    "                            dropout=dropout,\n",
    "                            n_epochs=400,\n",
    "                            optimizer_kwargs={'lr': lr},\n",
    "                            pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "                            random_state = 0\n",
    "                        )\n",
    "                        model.fit([train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())])\n",
    "                        pred_series, mape_nhits, sle_nhits = eval_model(\n",
    "                            model,\n",
    "                            len(val_scaled),\n",
    "                            series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "                            val_scaled,\n",
    "                            target_series = train_scaled,\n",
    "                            returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "                            plot = False,\n",
    "                        )\n",
    "                        uTheil = UTheil()\n",
    "                        u1_nhits = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "                        u2_nhits = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "                        print({\n",
    "                            'MAPE': mape_nhits,\n",
    "                            'SLE': sle_nhits,\n",
    "                            'U1': u1_nhits,\n",
    "                            'U2': u1_nhits,\n",
    "                            'lr': lr,\n",
    "                            'input_chunk_length': input_chunk_length,\n",
    "                            'output_chunk_length': output_chunk_length,\n",
    "                            'num_stacks': num_stacks,\n",
    "                            'num_blocks': num_blocks,\n",
    "                            'num_layers': num_layers,\n",
    "                            'batch_size': batch_size,\n",
    "                            'layer_widths': layer_widths,\n",
    "                            'dropout': dropout,\n",
    "                        })\n",
    "                        models_nhits.append({\n",
    "                            'MAPE': mape_nhits,\n",
    "                            'SLE': sle_nhits,\n",
    "                            'U1': u1_nhits,\n",
    "                            'U2': u1_nhits,\n",
    "                            'lr': lr,\n",
    "                            'input_chunk_length': input_chunk_length,\n",
    "                            'output_chunk_length': output_chunk_length,\n",
    "                            'num_stacks': num_stacks,\n",
    "                            'num_blocks': num_blocks,\n",
    "                            'num_layers': num_layers,\n",
    "                            'batch_size': batch_size,\n",
    "                            'layer_widths': layer_widths,\n",
    "                            'dropout': dropout,\n",
    "                        })\n",
    "                    except:\n",
    "                        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "uTheil = UTheil()\n",
    "\n",
    "for best_model_nhits in [\n",
    "                            {\n",
    "                                'name': i,\n",
    "                                'input_chunk_length': min(models_nhits, key=lambda d: d[i])['input_chunk_length'],\n",
    "                                'output_chunk_length': min(models_nhits, key=lambda d: d[i])['output_chunk_length'],\n",
    "                                'dropout': min(models_nhits, key=lambda d: d[i])['dropout'],\n",
    "                                'batch_size': min(models_nhits, key=lambda d: d[i])['batch_size'],\n",
    "                                'lr': min(models_nhits, key=lambda d: d[i])['lr'],\n",
    "                                'num_stacks': min(models_nhits, key=lambda d: d[i])['num_stacks'],\n",
    "                                'num_blocks': min(models_nhits, key=lambda d: d[i])['num_blocks'],\n",
    "                                'num_layers': min(models_nhits, key=lambda d: d[i])['num_layers'],\n",
    "                                'layer_widths': min(models_nhits, key=lambda d: d[i])['layer_widths'],\n",
    "                            } for i in ['MAPE', 'SLE', 'U1', 'U2']\n",
    "                        ]:\n",
    "    print('Best', best_model_nhits['name'])\n",
    "    model = NHiTSModel(\n",
    "        input_chunk_length=best_model_nhits['input_chunk_length'],\n",
    "        output_chunk_length=best_model_nhits['output_chunk_length'],\n",
    "        batch_size=best_model_nhits['batch_size'],\n",
    "        num_stacks=best_model_nhits['num_stacks'],\n",
    "        num_blocks=best_model_nhits['num_blocks'],\n",
    "        num_layers=best_model_nhits['num_layers'],\n",
    "        layer_widths=best_model_nhits['layer_widths'],\n",
    "        dropout=best_model_nhits['dropout'],\n",
    "        n_epochs=400,\n",
    "        optimizer_kwargs={'lr': best_model_nhits['lr']},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    model.fit([train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())])\n",
    "    pred_series, mape_nhits, sle_nhits = eval_model(\n",
    "        model,\n",
    "        len(val_scaled),\n",
    "        series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "        val_scaled,\n",
    "        target_series = train_scaled,\n",
    "        returned = ['PREDICT_VALUES', 'MAPE_VAL', 'SLE_VAL'],\n",
    "    )\n",
    "    uTheil = UTheil()\n",
    "    u1_nhits = uTheil.calculateU1(val_scaled, pred_series[:len(val)])\n",
    "    u2_nhits = uTheil.calculateU2(val_scaled, pred_series[:len(val)])\n",
    "    print('Model: ', model)\n",
    "    print('U1: ', u1_nhits)\n",
    "    print('U2: ', u2_nhits)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando o Optuna para otimizar os parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    num_stacks = trial.suggest_int(\"num_stacks\", 1, 4)\n",
    "    num_blocks = trial.suggest_int(\"num_blocks\", 1, 4)\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 4)\n",
    "    layer_widths = trial.suggest_int(\"layer_widths\", 7, 11)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 100, 500)\n",
    "    dropout = trial.suggest_uniform(\"dropout\", 0, 0.2)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NHiTSModel(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        batch_size=2**batch_size,\n",
    "        num_stacks=num_stacks,\n",
    "        num_blocks=num_blocks,\n",
    "        num_layers=num_layers,\n",
    "        layer_widths=2**layer_widths,\n",
    "        dropout=dropout,\n",
    "        n_epochs=n_epochs,\n",
    "        optimizer_kwargs={'lr': lr},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NHiTSModel(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    num_stacks=study.best_trial.params['num_stacks'],\n",
    "    num_blocks=study.best_trial.params['num_blocks'],\n",
    "    num_layers=study.best_trial.params['num_layers'],\n",
    "    layer_widths=2**study.best_trial.params['layer_widths'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    optimizer_kwargs={'lr': study.best_trial.params['lr']},\n",
    "    pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pelo U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    num_stacks = trial.suggest_int(\"num_stacks\", 1, 4)\n",
    "    num_blocks = trial.suggest_int(\"num_blocks\", 1, 4)\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 4)\n",
    "    layer_widths = trial.suggest_int(\"layer_widths\", 7, 11)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 100, 500)\n",
    "    dropout = trial.suggest_uniform(\"dropout\", 0, 0.2)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NHiTSModel(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        batch_size=2**batch_size,\n",
    "        num_stacks=num_stacks,\n",
    "        num_blocks=num_blocks,\n",
    "        num_layers=num_layers,\n",
    "        layer_widths=2**layer_widths,\n",
    "        dropout=dropout,\n",
    "        n_epochs=n_epochs,\n",
    "        optimizer_kwargs={'lr': lr},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    mapes = uTheil.calculateU2(val_scaled, preds)\n",
    "    mape_val = np.mean(mapes)\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NHiTSModel(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    num_stacks=study.best_trial.params['num_stacks'],\n",
    "    num_blocks=study.best_trial.params['num_blocks'],\n",
    "    num_layers=study.best_trial.params['num_layers'],\n",
    "    layer_widths=2**study.best_trial.params['layer_widths'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    optimizer_kwargs={'lr': study.best_trial.params['lr']},\n",
    "    pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mesclando MAPE e U2 de Theil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    in_len = trial.suggest_int(\"in_len\", 12, 31)\n",
    "    out_len = trial.suggest_int(\"out_len\", 1, 33-in_len)\n",
    "\n",
    "    # Other hyperparameters\n",
    "    num_stacks = trial.suggest_int(\"num_stacks\", 1, 4)\n",
    "    num_blocks = trial.suggest_int(\"num_blocks\", 1, 4)\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 4)\n",
    "    layer_widths = trial.suggest_int(\"layer_widths\", 7, 11)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 3, 7)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 100, 500)\n",
    "    dropout = trial.suggest_uniform(\"dropout\", 0, 0.2)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "\n",
    "    # build the D-Linear\n",
    "    model = NHiTSModel(\n",
    "        input_chunk_length=in_len,\n",
    "        output_chunk_length=out_len,\n",
    "        batch_size=2**batch_size,\n",
    "        num_stacks=num_stacks,\n",
    "        num_blocks=num_blocks,\n",
    "        num_layers=num_layers,\n",
    "        layer_widths=2**layer_widths,\n",
    "        dropout=dropout,\n",
    "        n_epochs=n_epochs,\n",
    "        optimizer_kwargs={'lr': lr},\n",
    "        pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "        random_state = 0\n",
    "    )\n",
    "    try:\n",
    "        # train the model\n",
    "        model.fit(\n",
    "          series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    "        )\n",
    "    except:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "    preds = model.predict(series=train_scaled, n=len(val_scaled))\n",
    "    uTheil = UTheil()\n",
    "    u2_theil = uTheil.calculateU2(val_scaled, preds)\n",
    "    mapes = mape(val_scaled, preds)\n",
    "    mape_val = np.mean([mapes/100, u2_theil])\n",
    "\n",
    "    return mape_val if mape_val != np.nan else float(\"inf\")\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimize hyperparameters by minimizing the mape on the validation set\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NHiTSModel(\n",
    "    input_chunk_length=study.best_trial.params['in_len'],\n",
    "    output_chunk_length=study.best_trial.params['out_len'],\n",
    "    batch_size=2**study.best_trial.params['batch_size'],\n",
    "    num_stacks=study.best_trial.params['num_stacks'],\n",
    "    num_blocks=study.best_trial.params['num_blocks'],\n",
    "    num_layers=study.best_trial.params['num_layers'],\n",
    "    layer_widths=2**study.best_trial.params['layer_widths'],\n",
    "    dropout=study.best_trial.params['dropout'],\n",
    "    n_epochs=study.best_trial.params['n_epochs'],\n",
    "    optimizer_kwargs={'lr': study.best_trial.params['lr']},\n",
    "    pl_trainer_kwargs={\"accelerator\": \"gpu\", \"devices\": -1},\n",
    "    random_state = 0\n",
    ")\n",
    "print(model)\n",
    "# train the model\n",
    "model.fit(\n",
    "  series=[train_scaled, soybean_oil_scaled.slice(soybean_oil_scaled.start_time(), val.end_time())]\n",
    ")\n",
    "pred_series = eval_model(\n",
    "    model,\n",
    "    len(val_scaled),\n",
    "    series_national_scaled.slice(train.start_time(), val.end_time()),\n",
    "    val_scaled,\n",
    "    target_series = train_scaled,\n",
    "    returned = ['PREDICT_VALUES'],\n",
    ")\n",
    "pred_series = pred_series[0]\n",
    "uTheil = UTheil()\n",
    "print('U1: ', uTheil.calculateU1(val_scaled, pred_series[:len(val)]))\n",
    "print('U2: ', uTheil.calculateU2(val_scaled, pred_series[:len(val)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "EEF3JA5y1dUB",
    "HOj_XgQt7yXW",
    "ohMxnZ1cA5w6"
   ],
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "TCC",
   "language": "python",
   "name": "tcc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
