{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Instalação de bibliotecas"
      ],
      "metadata": {
        "id": "HPknRENn1W7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U darts"
      ],
      "metadata": {
        "id": "DpiNE7aY1aQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importação de bibliotecas"
      ],
      "metadata": {
        "id": "EEF3JA5y1dUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "import torch\n",
        "\n",
        "from darts import TimeSeries\n",
        "from darts.dataprocessing.transformers import Scaler\n",
        "from darts.models import DLinearModel, LinearRegressionModel\n",
        "from darts.models.filtering.moving_average_filter import MovingAverageFilter\n",
        "from darts.metrics import mape\n",
        "from darts.utils.statistics import check_seasonality, plot_acf, plot_residuals_analysis\n",
        "\n",
        "from scipy import signal"
      ],
      "metadata": {
        "id": "OZn1nyGr1g4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definição de Constantes e Funções Auxiliares"
      ],
      "metadata": {
        "id": "HOj_XgQt7yXW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definição de constantes"
      ],
      "metadata": {
        "id": "BmyzmVOUGr8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATE_FORMAT_STRING = '%d/%m/%Y'\n",
        "FIG_SIZE = (8,5)"
      ],
      "metadata": {
        "id": "doU20s6rGuCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Anexando funções a TimeSeries"
      ],
      "metadata": {
        "id": "PxqGm3nt9GlW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def TimeSeriesRatio(self):\n",
        "  ratio_series = self.pd_series().div(self.pd_series().shift(1))[1:]\n",
        "  ratio_dataframe = ratio_series.to_frame(name=f\"{self.columns[0]}_ratio\")\n",
        "  ratio_time_series = TimeSeries.from_dataframe(ratio_dataframe)\n",
        "  return ratio_time_series\n",
        "\n",
        "def TimeSeriesDetrend(self):\n",
        "  # Calcular o detrend dos dados da série\n",
        "  detrended_data = signal.detrend(self.univariate_values())\n",
        "\n",
        "  # Criar um novo TimeSeries com os dados detrendizados\n",
        "  return TimeSeries.from_dataframe(pd.DataFrame({'Data': self.time_index, f\"{self.columns[0]}_detrend\": detrended_data}), time_col='Data', value_cols=f\"{self.columns[0]}_detrend\")\n",
        "\n",
        "def TimeSeriesScalerFitAndInverseTransform(self, original):\n",
        "    scaler = Scaler()\n",
        "    scaler.fit(original)\n",
        "    return scaler.inverse_transform(self)\n",
        "\n",
        "def TimeSeriesInverseDetrend(self, original):\n",
        "    detrend_target = original.detrend()\n",
        "    trend_line = (original - detrend_target)\n",
        "    start_time = self.start_time()\n",
        "    end_time = self.end_time()\n",
        "    if self.time_index[-1].to_pydatetime() > trend_line.time_index[-1].to_pydatetime():\n",
        "        regressor = LinearRegressionModel(lags = 1)\n",
        "        regressor.fit(trend_line)\n",
        "        trend_line = trend_line.concatenate(regressor.predict(calculate_dates_diff(trend_line.end_time(), end_time, self.freq.freqstr) + 2))\n",
        "    return self + trend_line[start_time:end_time]\n",
        "\n",
        "def TimeSeriesFilter(self, filter = MovingAverageFilter(10)):\n",
        "  series_filtered = filter.filter(self)\n",
        "  series_residuals = (self-series_filtered)\n",
        "  return TimeSeries.from_dataframe(pd.DataFrame({'Data': self.time_index, f\"{self.columns[0]}_filtered\": series_filtered.univariate_values()}), time_col='Data', value_cols=f\"{self.columns[0]}_filtered\"), TimeSeries.from_dataframe(pd.DataFrame({'Data': self.time_index, f\"{self.columns[0]}_residuals\": series_residuals.univariate_values()}), time_col='Data', value_cols=f\"{self.columns[0]}_residuals\")\n",
        "\n",
        "TimeSeries.ratio = TimeSeriesRatio\n",
        "TimeSeries.detrend = TimeSeriesDetrend\n",
        "TimeSeries.fit_inverse_transform = TimeSeriesScalerFitAndInverseTransform\n",
        "TimeSeries.fit_inverse_detrend = TimeSeriesInverseDetrend\n",
        "TimeSeries.filter = TimeSeriesFilter"
      ],
      "metadata": {
        "id": "eP9YYH1u74YF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definição de Funções"
      ],
      "metadata": {
        "id": "MyIUAtlwTBgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_trend_line(series, title = None):\n",
        "  plt.figure(figsize=FIG_SIZE)\n",
        "  if title:\n",
        "    plt.title(title)\n",
        "  series.plot()\n",
        "  (series - series.detrend()).plot(label = 'trend line')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "x31aoXieNGtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_series(series, title = None):\n",
        "  plt.figure(figsize=FIG_SIZE)\n",
        "  if title:\n",
        "    plt.title(title)\n",
        "  if type(series) == TimeSeries:\n",
        "    series.plot()\n",
        "  elif type(series) == list:\n",
        "    for serie in series:\n",
        "      serie.plot()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "CpdcLRKjM-6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#squared_log_error\n",
        "def sle(y_true, y_pred):\n",
        "    y_true_num = []\n",
        "    y_pred_num = []\n",
        "\n",
        "    for i in y_true.values():\n",
        "        if math.isnan(i) == False:\n",
        "            y_true_num.append(float(i))\n",
        "\n",
        "    for i in y_pred.values():\n",
        "        if math.isnan(i) == False:\n",
        "            y_pred_num.append(float(i))\n",
        "\n",
        "    somatorio = 0\n",
        "    for i in range(0, len(y_true_num)):\n",
        "        x = (y_pred_num[i]/y_true_num[i])\n",
        "        somatorio += (np.log(abs(x))) ** 2\n",
        "    return somatorio"
      ],
      "metadata": {
        "id": "-R_DDuAnTV8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this function evaluates a model on a given validation set for n time-steps\n",
        "def eval_model(model, n, series, val_series, target_series = None, scaler = None, detrend = None, returned = [],historical = False, plot = True):\n",
        "    if target_series != None:\n",
        "        pred_series = model.predict(n=n, series = target_series)\n",
        "    else:\n",
        "        pred_series = model.predict(n=n)\n",
        "    if historical:\n",
        "      historical_series = model.historical_forecasts(target_series)\n",
        "    else:\n",
        "      historical_series = None\n",
        "    if scaler != None:\n",
        "        pred_series = pred_series.fit_inverse_transform(scaler)\n",
        "        if historical:\n",
        "          historical_series = historical_series.fit_inverse_transform(scaler)\n",
        "        target_series = target_series.fit_inverse_transform(scaler)\n",
        "    if detrend != None:\n",
        "        pred_series = pred_series.fit_inverse_detrend(detrend)\n",
        "        if historical:\n",
        "          historical_series = historical_series.fit_inverse_detrend(detrend)\n",
        "        target_series = target_series.fit_inverse_detrend(detrend)\n",
        "    try:\n",
        "      mape_val = mape(val_series, pred_series[:len(val_series)])\n",
        "    except:\n",
        "      mape_val = float('inf')\n",
        "    try:\n",
        "      sle_val = sle(val_series, pred_series[:len(val_series)])\n",
        "    except:\n",
        "      sle_val = float('inf')\n",
        "    if historical:\n",
        "      try:\n",
        "        mape_train = mape(target_series[-len(historical_series):], historical_series)\n",
        "      except:\n",
        "        mape_train = float('inf')\n",
        "      try:\n",
        "        sle_train = sle(target_series[-len(historical_series):], historical_series)\n",
        "      except:\n",
        "        sle_train = float('inf')\n",
        "    if plot:\n",
        "        plt.figure(figsize=FIG_SIZE)\n",
        "        series.plot(label='actual')\n",
        "        pred_series.plot(label='forecast')\n",
        "        if historical:\n",
        "          historical_series.plot(label='historical')\n",
        "          plt.title('MAPE: t{:.2f}%'.format(mape_train) + ' v{:.2f}%'.format(mape_val) + ' - SLE: t{:.2f}'.format(sle_train) + ' v{:.2f}'.format(sle_val))\n",
        "        else:\n",
        "          plt.title('MAPE: {:.2f}%'.format(mape_val) + ' - SLE: {:.2f}'.format(sle_val))\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "    try:\n",
        "      returned_f = []\n",
        "      for returned_l in returned:\n",
        "        if returned_l.upper() == 'MAPE_VAL':\n",
        "          returned_f.append(mape_val)\n",
        "        elif returned_l.upper() == 'SLE_VAL':\n",
        "          returned_f.append(sle_val)\n",
        "        elif returned_l.upper() == 'MAPE_TRAIN':\n",
        "          returned_f.append(mape_train)\n",
        "        elif returned_l.upper() == 'SLE_TRAIN':\n",
        "          returned_f.append(sle_train)\n",
        "        elif returned_l.upper() == 'PREDICT_VALUES':\n",
        "          returned_f.append(pred_series)\n",
        "        elif returned_l.upper() == 'HISTORICAL_VALUES':\n",
        "          returned_f.append(historical_series)\n",
        "        else:\n",
        "          returned_f.append(None)\n",
        "      return returned_f\n",
        "    except:\n",
        "      return None\n"
      ],
      "metadata": {
        "id": "HprayQmYShPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_dates_diff(start, end, freq = 'D'):\n",
        "  date_range = pd.date_range(start=start, end=end, freq=freq)\n",
        "  return len(date_range)"
      ],
      "metadata": {
        "id": "C5W8d6MhTxSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_pl_trainer_kwargs(**kwargs):\n",
        "\n",
        "  pl_trainer_kwargs = kwargs\n",
        "\n",
        "  if torch.cuda.is_available():\n",
        "    try:\n",
        "      pl_trainer_kwargs['accelerator']\n",
        "    except:\n",
        "      pl_trainer_kwargs['accelerator'] = \"gpu\"\n",
        "    try:\n",
        "      pl_trainer_kwargs['devices']\n",
        "    except:\n",
        "      pl_trainer_kwargs['devices'] = -1\n",
        "  else:\n",
        "      pl_trainer_kwargs['accelerator'] = \"cpu\"\n",
        "\n",
        "  if pl_trainer_kwargs['accelerator'] == \"cpu\":\n",
        "      try:\n",
        "        del pl_trainer_kwargs['devices']\n",
        "      except:\n",
        "        pass\n",
        "\n",
        "  return pl_trainer_kwargs"
      ],
      "metadata": {
        "id": "73Sl2pYHNGov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Criando o dataset"
      ],
      "metadata": {
        "id": "ohMxnZ1cA5w6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Leitura da Tabela de Dados"
      ],
      "metadata": {
        "id": "81-EOfJP2cLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel('./data/Biodiesel.xlsx', 'Dados')\n",
        "df"
      ],
      "metadata": {
        "id": "k4sgmX4z2euk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformando o Dataframe em uma serie temporal do darts\n",
        "series_national = TimeSeries.from_dataframe(df, 'Data',  'Brasil')\n",
        "series_national_tx = series_national.ratio()\n",
        "series_north = TimeSeries.from_dataframe(df, 'Data',  'Norte')\n",
        "series_south = TimeSeries.from_dataframe(df, 'Data',  'Sul')\n",
        "series_southeast = TimeSeries.from_dataframe(df, 'Data',  'Sudeste')\n",
        "series_midwest = TimeSeries.from_dataframe(df, 'Data',  'Centro-Oeste')\n",
        "series_northeast = TimeSeries.from_dataframe(df, 'Data',  'Nordeste')\n",
        "\n",
        "plot_series([\n",
        "    series_national,\n",
        "    series_national_tx,\n",
        "    series_north,\n",
        "    series_south,\n",
        "    series_southeast,\n",
        "    series_midwest,\n",
        "    series_northeast\n",
        "])"
      ],
      "metadata": {
        "id": "GAW6NDCw3Bd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tratamento dos dados - Série Original"
      ],
      "metadata": {
        "id": "QYnQCs-bIuSh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualização dos dados"
      ],
      "metadata": {
        "id": "hPxfpzo_OPa_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_series([\n",
        "    series_national,\n",
        "    series_national_tx,\n",
        "    series_north,\n",
        "    series_south,\n",
        "    series_southeast,\n",
        "    series_midwest,\n",
        "    series_northeast\n",
        "])"
      ],
      "metadata": {
        "id": "CdW4iqU8OUE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Divisão dos Conjuntos de Treino e Validação"
      ],
      "metadata": {
        "id": "Eqc-6hDQBDfZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_size_percent = 70\n",
        "train_size = int(len(series_national) * train_size_percent/100)\n",
        "split_date = series_national.time_index[train_size].strftime('%Y%m%d')\n",
        "print(f\"Treinamento: {series_national.time_index[0].strftime(DATE_FORMAT_STRING)} - {series_national.time_index[train_size - 1].strftime(DATE_FORMAT_STRING)}\")\n",
        "print(f\"Validação  : {series_national.time_index[train_size].strftime(DATE_FORMAT_STRING)} - {series_national.time_index[-1].strftime(DATE_FORMAT_STRING)}\")\n",
        "\n",
        "train_tx, val_tx = series_national_tx.split_before(pd.Timestamp(split_date))\n",
        "train, val = series_national.split_before(pd.Timestamp(split_date))\n",
        "train_north, val_north = series_north.split_before(pd.Timestamp(split_date))\n",
        "train_south, val_south = series_south.split_before(pd.Timestamp(split_date))\n",
        "train_southeast, val_southeast = series_southeast.split_before(pd.Timestamp(split_date))\n",
        "train_midwest, val_midwest = series_midwest.split_before(pd.Timestamp(split_date))\n",
        "train_northeast, val_northeast = series_northeast.split_before(pd.Timestamp(split_date))"
      ],
      "metadata": {
        "id": "TQBDn7HqC6_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aplicando StandardScaler (normalização de 0 a 1)"
      ],
      "metadata": {
        "id": "1CZ8KTPpIK2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = Scaler()\n",
        "train_tx_scaled = scaler.fit_transform(train_tx)\n",
        "val_tx_scaled = scaler.transform(val_tx)\n",
        "series_national_tx_scaled = scaler.transform(series_national_tx)\n",
        "train_scaled = scaler.fit_transform(train)\n",
        "val_scaled = scaler.transform(val)\n",
        "series_national_scaled = scaler.transform(series_national)\n",
        "train_north_scaled = scaler.fit_transform(train_north)\n",
        "val_north_scaled = scaler.transform(val_north)\n",
        "series_north_scaled = scaler.transform(series_north)\n",
        "train_south_scaled = scaler.fit_transform(train_south)\n",
        "val_south_scaled = scaler.transform(val_south)\n",
        "series_south_scaled = scaler.transform(series_south)\n",
        "train_southeast_scaled = scaler.fit_transform(train_southeast)\n",
        "val_southeast_scaled = scaler.transform(val_southeast)\n",
        "series_southeast_scaled = scaler.transform(series_southeast)\n",
        "train_midwest_scaled = scaler.fit_transform(train_midwest)\n",
        "val_midwest_scaled = scaler.transform(val_midwest)\n",
        "series_midwest_scaled = scaler.transform(series_midwest)\n",
        "train_northeast_scaled = scaler.fit_transform(train_northeast)\n",
        "val_northeast_scaled = scaler.transform(val_northeast)\n",
        "series_northeast_scaled = scaler.transform(series_northeast)\n",
        "\n",
        "plot_series([\n",
        "    series_national_scaled,\n",
        "    series_national_tx_scaled,\n",
        "    series_north_scaled,\n",
        "    series_south_scaled,\n",
        "    series_southeast_scaled,\n",
        "    series_midwest_scaled,\n",
        "    series_northeast_scaled\n",
        "])"
      ],
      "metadata": {
        "id": "j9Ml5XQAIHl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tratamento de Dados - Série sem tendência"
      ],
      "metadata": {
        "id": "WYFwv_EUI-xw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformando o Dataframe em uma serie temporal do darts\n",
        "series_national_detrend = series_national.detrend()\n",
        "series_national_tx_detrend = series_national_tx.detrend()\n",
        "series_north_detrend = series_north.detrend()\n",
        "series_south_detrend = series_south.detrend()\n",
        "series_southeast_detrend = series_southeast.detrend()\n",
        "series_midwest_detrend = series_midwest.detrend()\n",
        "series_northeast_detrend = series_northeast.detrend()"
      ],
      "metadata": {
        "id": "CrXRzgOeJEtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualização dos dados"
      ],
      "metadata": {
        "id": "D6tV4ec1MIyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_trend_line(series_national)\n",
        "plot_trend_line(series_national_tx)\n",
        "plot_trend_line(series_north)\n",
        "plot_trend_line(series_south)\n",
        "plot_trend_line(series_southeast)\n",
        "plot_trend_line(series_midwest)\n",
        "plot_trend_line(series_northeast)"
      ],
      "metadata": {
        "id": "7H5E4IQcMLEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_series([\n",
        "    series_national_tx_detrend,\n",
        "    series_national_detrend,\n",
        "    series_north_detrend,\n",
        "    series_south_detrend,\n",
        "    series_southeast_detrend,\n",
        "    series_midwest_detrend,\n",
        "    series_northeast_detrend\n",
        "])"
      ],
      "metadata": {
        "id": "MVPsrfobN-9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Divisão dos Conjuntos de Treino e Validação"
      ],
      "metadata": {
        "id": "Uov7v3JYPKIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_size_percent_detrend = 70\n",
        "train_size_detrend = int(len(series_national_detrend) * train_size_percent_detrend/100)\n",
        "split_date_detrend = series_national_detrend.time_index[train_size_detrend].strftime('%Y%m%d')\n",
        "print(f\"Treinamento: {series_national_detrend.time_index[0].strftime(DATE_FORMAT_STRING)} - {series_national_detrend.time_index[train_size - 1].strftime(DATE_FORMAT_STRING)}\")\n",
        "print(f\"Validação  : {series_national_detrend.time_index[train_size].strftime(DATE_FORMAT_STRING)} - {series_national_detrend.time_index[-1].strftime(DATE_FORMAT_STRING)}\")\n",
        "\n",
        "train_tx_detrend, val_tx_detrend = series_national_tx_detrend.split_before(pd.Timestamp(split_date_detrend))\n",
        "train_detrend, val_detrend = series_national_detrend.split_before(pd.Timestamp(split_date_detrend))\n",
        "train_north_detrend, val_north_detrend = series_north_detrend.split_before(pd.Timestamp(split_date_detrend))\n",
        "train_south_detrend, val_south_detrend = series_south_detrend.split_before(pd.Timestamp(split_date_detrend))\n",
        "train_southeast_detrend, val_southeast_detrend = series_southeast_detrend.split_before(pd.Timestamp(split_date_detrend))\n",
        "train_midwest_detrend, val_midwest_detrend = series_midwest_detrend.split_before(pd.Timestamp(split_date_detrend))\n",
        "train_northeast_detrend, val_northeast_detrend = series_northeast_detrend.split_before(pd.Timestamp(split_date_detrend))"
      ],
      "metadata": {
        "id": "2sNSivSZPQC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aplicando StandardScaler (normalização de 0 a 1)"
      ],
      "metadata": {
        "id": "aIErs0_wQbpe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = Scaler()\n",
        "train_tx_detrend_scaled = scaler.fit_transform(train_tx_detrend)\n",
        "val_tx_detrend_scaled = scaler.transform(val_tx_detrend)\n",
        "series_national_tx_detrend_scaled = scaler.transform(series_national_tx_detrend)\n",
        "train_detrend_scaled = scaler.fit_transform(train_detrend)\n",
        "val_detrend_scaled = scaler.transform(val_detrend)\n",
        "series_national_detrend_scaled = scaler.transform(series_national_detrend)\n",
        "train_north_detrend_scaled = scaler.fit_transform(train_north_detrend)\n",
        "val_north_detrend_scaled = scaler.transform(val_north_detrend)\n",
        "series_north_detrend_scaled = scaler.transform(series_north_detrend)\n",
        "train_south_detrend_scaled = scaler.fit_transform(train_south_detrend)\n",
        "val_south_detrend_scaled = scaler.transform(val_south_detrend)\n",
        "series_south_detrend_scaled = scaler.transform(series_south_detrend)\n",
        "train_southeast_detrend_scaled = scaler.fit_transform(train_southeast_detrend)\n",
        "val_southeast_detrend_scaled = scaler.transform(val_southeast_detrend)\n",
        "series_southeast_detrend_scaled = scaler.transform(series_southeast_detrend)\n",
        "train_midwest_detrend_scaled = scaler.fit_transform(train_midwest_detrend)\n",
        "val_midwest_detrend_scaled = scaler.transform(val_midwest_detrend)\n",
        "series_midwest_detrend_scaled = scaler.transform(series_midwest_detrend)\n",
        "train_northeast_detrend_scaled = scaler.fit_transform(train_northeast_detrend)\n",
        "val_northeast_detrend_scaled = scaler.transform(val_northeast_detrend)\n",
        "series_northeast_detrend_scaled = scaler.transform(series_northeast_detrend)\n",
        "\n",
        "plot_series([\n",
        "    series_national_detrend_scaled,\n",
        "    series_national_tx_detrend_scaled,\n",
        "    series_north_detrend_scaled,\n",
        "    series_south_detrend_scaled,\n",
        "    series_southeast_detrend_scaled,\n",
        "    series_midwest_detrend_scaled,\n",
        "    series_northeast_detrend_scaled\n",
        "])"
      ],
      "metadata": {
        "id": "PC1EuKGHQCjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Treinando o Modelo"
      ],
      "metadata": {
        "id": "y5YTqq0KNaSI"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}